log1 llm_sample -207.45  log1_2价格归一化:-207.4                                    log已清除
log2 根据batch_nums调整温度 batch>3  0.5* temp: -207.75, -208.35; 0.6*temp: -207.6  log已清除
log3 调整赋予的最低概率                     todo
log4 赋予最低概率,decay=0.95    -208.45                                             log已清除
log5 mask  一半: -207.3  -207.0(3.17 20:43) log5_1 mask 0.6:-206.8                                                     
log6 evalute_function惩罚力度设为最低0.01  -207.35                                   log已清除
log7 增加visit惩罚,c_v2=4 -209.0    log7_2 c_v2=5 -207.15   log7_3 c_v2=6 -207.2(3.17 20:42) log7_4 c_v2=7 -207.35      有效
log8 根据batch_nums调整温度并且mask一半 batch>5 1.5* temp:-209.05  log8_2 batch>5 0.6*temp:-207.15 log8_3 batch>5 0.7*temp: -207.4(3.17 20:45)
log9 利用新的prompt，根据batch_nums调整温度并且mask一半 batch>5 0.6* temp:    todo
log10 利用新的prompt -207.9                                                         log已清除
logbase  -206.7

Conclude
c_v2与mask效果差不多，c_v2在为5时效果较好   next step:将二者结合测试分数
调整mask比率还未进行测试，待进一步测试观察数据      next step:调整mask比率进行测试
根据batch_nums调整温度在batch_nums>5 0.6*temp效果较好   next step:测试0.8，0.9与temp恒为1比较
大模型采样价格使用原始值与归一化数值无明显效果差异，根据图像，调整温度并无太大效果      next step:调整窗口大小，例如3，4,测试观察分数

log1 mask 0.65:                                 todo
log2 c_v2=5与mask 0.5结合:                       todo
log3 调整windows size=4:                         todo

lognewbase -207.0
llm_sample
log1_1~3:使用价格原始值相除     -210.25 -207.3 -208.2
log2_1~3:使用价格归一化数值相乘 价格使用原始值相除，会使得当前benefit最高的反而变小，而api最优是一段时间内最优，及时利用这段时间 -210.5 -208.5 -207.95  
         效果不如使用初始价格相除，猜测是由于数值在0~800之间，而初始价格相除数值在0~100之间，解决方法，仍使用归一化数值，但对所有得分除一个参数div_num(例如10),来减小区间差距   log4
log3_1~3:cal_intensity 使用线性函数  由于e函数太过陡峭，以致导致出现局部最优，其余模型选到机会太少，根本没有机会去产生最优值，而选到的模型产生的自然是最优值 -207.9 -207.95 -209.2
         llm_sample_log3_1:314 第二个模型response明显已经很差，但由于之前一次过于好，因此评分仍高于其他很多，此-500可能是产生了无法识别的，但若是差的，则此时其仍占据概率最高，不合理
                               改进:增加历史衰减因子decay,根据his_num降低权重  log5
         经过二十轮才出现第一个response大于5的模型，而又经过10轮出现下一个response大于5，405行50轮才启动完毕，相对于1000自然很小，对于100轮启动太慢
         399-546:全部都选3,但是这段时间3号模型表现并不好，这就是在log3中所说的其他模型选择机会太少，甚至更为严重，没有选择其他模型，由此使用线性函数并未解决问题，因为这段时间模型3没有对最大最小值产生影响，改变为线性函数并没有效果，并且由于这段时间一直选择3，在686处又陷入了这个漩涡，而使用exp函数效果更好，下降迅速，可以及时从这个漩涡中拉出来。
         response的写入具有延迟，当evaluate出来得知效果好时,可能已经是10轮之前的draw_sample使用的模型产生的了,评估可以并行吗？
log4_1~3:使用价格归一化数值，exp函数，但对所得benefit_list除参数div_num(10)  -208.3 -207.45 -207.6      直接相除效果并不好,但归一化确实可以有效改善因为价格而引起的模型选择排序问题
         有没有更有效的减小数值差距方法(x-min/max-min)? log6
log5_1~3:使用价格原始值，exp函数，但增加历史衰减因子decay，根据his_num降低权重  -207.45 -207.2 -207.6
log6_1~3:使用价格归一化数值，exp函数，但对所得benefit_list使用(x-min/max-min)进行归一化 -207.35 -207.6

sample_iterator
log1_1~3:遗传算法选取一个tunable,使其随机选一个,改进方法:选择ratio=0.1的tunable使其随机选取para,以避免陷入局部最优不能跳出的问题

模型性能测试
log1_1~3 "DeepSeek-R1"                  zqwei -207.45 -208.45 -210.3
log2_1~3 "DeepSeek-V3"                  zy10  -207.5 -207.95 -208.0
log3_1~3 "Deepseek-R1-distill-qwen-7b"  zy20  -211.1 -211.55 -212.0
log4_1~3 "DeepSeek-R1-distill-qwen-32b" zqwei -207.1 -207.25 -208.4
log5_1~3 "GPT-4o-mini"                  zqwei -207.7 -207.75 -211.55
log6_1~3 "Claude-3.7-sonnet"            zy20  -207.15 -207.15 -207.3
log7_1~3 "Gemini-2.0-flash-001"         zy10  -207.3 -208.85 -211.7

log1_1~3 采用使用价格归一化的方法，运行200次，观察是否能找出Claude和32b -206.85 -207.05 -207.1
idea:一般到达100次时候便会出现所有模型差不多概率的情况，因为那些对问题没用的模型评分为负，但数值在-10以内，而有用的模型为正，但因为100次时增长很小或不增长，所以在10以内，差距小
log2_1~3 Claude 3.7  and ds 32b random select -206.95(C50:50) -208.9(C49:51)
log3_1~3 ds r1 原因分析
log5_1~3 zy20 使用价格归一化方法，运行200次，temperature设置为0.1 -207.45 -207.15 
log6_1~3 zqwei 使用价格归一化方法，运行200次，使用improvement代替child-par_score，temperature设置为0.1 -206.7 -206.9
log7_1~3 zqwei 同1_1~3 -207.5 -206.9 -207.45

problem:1_1~3在100次后出现概率无法分开现象，原因是当运行到后面时，par与child只差0~1之间，故benefit为正但贴近0，差的模型可能为负但也贴近0。
        但发现单独表现不好的模型如V3在1_1中也会产生好的结果。猜测是V3的知识库中确实存在好的结果，但V3本身没有推理能力，我们起点与V3中好结果的距离远，V3自己无法到达，而通过其他模型，相当于加速了这个路径，使得V3可以到达
idea:解决模型benefit差值小的问题，使用方法log5或者log6
     不解决benefit差值小的问题，观察如V3这样的表现是否是偶然现象，如果不是偶然现象，考虑是否保留

shannon
1_1: zqwei V3-new
1_2: zqwei V3-old
1_3: zqwei 7b           279
1_4:       4o-mini
1_5:       flash-001
1_6:       Mistral-Codestral-2501
1_7:       Qwen2.5-72B-Instruct
1_8:       DeepSeek-R1-Distill-Llama-70B
1_9: zqwei 32b          
