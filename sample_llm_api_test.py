from sample_llm_api import LLM
from sample_llm_api import EvaluateLLM

ds_byte_key = "Bearer f184bcd9-68b0-49be-8a3f-ea095ee71e14"
gpt_byte_key = "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"
claude_key = None
gemini_key = None
grok_key = None
rate = 7.2739

llm_list = [
    LLM(
        llm_name="DeepSeek-R1",
        api_key=ds_byte_key,
        model="ep-20250303202036-j6hfh",
        provider=None,
        input_price=4.0,
        output_price=16.0,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="DeepSeek-V3", 
        api_key=ds_byte_key, 
        model="ep-20250227102412-tfkv8", 
        provider=None, 
        input_price=2.0,
        output_price=8.0, 
        response_score=[], 
        score=0.0
    ),
    LLM(
        llm_name="Deepseek-R1-distill-qwen-7b",
        api_key=ds_byte_key,
        model="ep-20250305162451-qxgns",
        provider=None,
        input_price=0.6,
        output_price=2.4,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="DeepSeek-R1-distill-qwen-32b",
        api_key=ds_byte_key,
        model="ep-20250305162537-2sbpv",
        provider=None,
        input_price=1.5,
        output_price=6.0,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="GPT-4o",
        api_key=gpt_byte_key,
        model=None,
        provider="OpenAI",
        input_price=2.5 * rate,
        output_price=10 * rate,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="GPT-4o-mini",
        api_key=gpt_byte_key,
        model=None,
        provider="OpenAI",
        input_price=0.15 * rate,
        output_price=0.6 * rate,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="GPT-o1",
        api_key=gpt_byte_key,
        model=None,
        provider="OpenAI",
        input_price=15 * rate,
        output_price=60 * rate,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="GPT-o1-mini",
        api_key=gpt_byte_key,
        model=None,
        provider="OpenAI",
        input_price=1.1 * rate,
        output_price=4.4 * rate,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="GPT-o3-mini",
        api_key=gpt_byte_key,
        model=None,
        provider="OpenAI",
        input_price=1.1 * rate,
        output_price=4.4 * rate,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="GPT-o3-mini-high",
        api_key=gpt_byte_key,
        model=None,
        provider="OpenAI",
        input_price=1.1 * rate,
        output_price=4.4 * rate,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="Claude-3.7-sonnet",
        api_key=claude_key,
        model=None,
        provider="Anthropic",
        input_price=3 * rate,
        output_price=15 * rate,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="Gemini-2.0-flash-001",
        api_key=gemini_key,
        model=None,
        provider="Google AI Studio",
        input_price=0.1 * rate,
        output_price=0.4 * rate,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="Gemini-2.0-pro-exp-02-05",
        api_key=gemini_key,
        model=None,
        provider="Google AI Studio",
        input_price=0.0 * rate,
        output_price=0.0 * rate,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="Gemini-2.0-flash-thinking-exp",
        api_key=gemini_key,
        model=None,
        provider="Google AI Studio",
        input_price=0.0 * rate,
        output_price=0.0 * rate,
        response_score=[],
        score=0.0,
    ),
    LLM(
        llm_name="Grok-beta",
        api_key=grok_key,
        model=None,
        provider="xAI",
        input_price=5 * rate,
        output_price=15 * rate,
        response_score=[],
        score=0.0,
    ),
]
llm = EvaluateLLM(llm_list, 0.0, 5.0)
llm.call_llm(llm_list[0], 10.0)
p = llm.calculate_probability()
print(p)
