+ python -u funsearch_bin_packing_llm_api.py
launch 1 evaluate tasks
INFO:absl:Best score increased to -500.0
current thread_i 0
current thread_i 1
current thread_i 2
current thread_i 3
current thread_i 4current thread_i 
5
current thread_i 6
current thread_i 7
current thread_i 8
current thread_i 9
request...request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

request...
-----------------------

-----------------------request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

request...
-----------------------
-----------------------


import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

request...
-----------------------request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.


import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------


-----------------------
-----------------------
request...
----------------------------------------------


import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.


-----------------------
-------------------
    """Improved priority calculation considering spatial fit and future potential."""
    from tunable import tunable

    # Calculate basic fit metrics
    capacities = bins.copy()
    remaining = capacities - item
    valid = remaining >= 0
    
    # Calculate spatial efficiency metrics
    ratios = np.zeros_like(bins)
    ratios[valid] = item / capacities[valid]
    spatial_fit = 1 - ratios  # Higher values for better spatial fit
    
    # Calculate future potential metrics
    # Penalize bins that would leave too little space after placing the item
    min_remaining_space = tunable([0.1, 0.2, 0.3])  # Tunable parameter
    space_penalty = np.zeros_like(bins)
    space_penalty[valid] = np.maximum(0, 
        tunable([0.5, 1.0, 1.5]) * (  # Penalty weight
            (remaining[valid] < min_remaining_space) * 
            (1 - remaining[valid] / min_remaining_space)
        )
    )
    
    # Use a look-ahead mechanism to prefer bins that maintain better distribution
    # of remaining capacities for future items
    look_ahead_depth = tunable([1, 2, 3])  # Tunable parameter
    future_impact = np.zeros_like(bins)
    for i in range(look_ahead_depth):
        future_item = tunable([item * 0.8, item * 0.9, item])  # Simulate future item sizes
        future_remaining = remaining - future_item
        future_valid = future_remaining >= 0
        future_impact[valid] += np.where(future_valid, 
            1 / (future_remaining + 1e-6),  # Reward bins that can still accommodate future items
            0
        )
    
    # Combine metrics with tunable weights
    spatial_weight = tunable([0.3, 0.5, 0.7])  # Tunable parameter
    future_weight = tunable([0.2, 0.4, 0.6])  # Tunable parameter
    penalty_weight = tunable([0.1, 0.2, 0.3])  # Tunable parameter
    
    priorities = (
        spatial_weight * spatial_fit +
        future_weight * future_impact -
        penalty_weight * space_penalty
    )
    
    # Add exploration factor to avoid getting stuck in local optima
    exploration_prob = tunable([0.01, 0.05, 0.1])  # Tunable parameter
    if np.random.rand() < exploration_prob:
        priorities = priorities * tunable([0.5, 0.7, 0.9]) + np.random.randn(*priorities.shape) * 0.1
    
    return priorities

call llm times: 1
-------------------



current thread_ilaunch 64 evaluate tasks
 9
this best socre: -10000000000.0; best score: -10000000000.0; global score: -10000000000.0; space size: 19683; measure cnt: 64

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -10000000000.0; space size: 19683; measure cnt: 128

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -10000000000.0; space size: 19683; measure cnt: 192
sampler suggest should end sample, break
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
                item_history: np.ndarray = None,
                weights: dict = None) -> np.ndarray:
    """Improved priority function considering spatial fit and future potential."""
    if weights is None:
        weights = {'spatial': tunable([0.5, 0.6, 0.7]),
                  'future': tunable([0.5, 0.4, 0.3]),
                  'fragmentation': tunable([0.1, 0.2])}
    
    if item_history is None or len(item_history) == 0:
        # Use default statistics if no history is available
        mu = tunable([1.0, 0.5])
        sigma = tunable([0.5, 0.3])
    else:
        mu = np.mean(item_history)
        sigma = max(np.std(item_history), tunable([0.1, 0.2]))  # Avoid zero division
    
    remaining_capacity = bins - item
    valid_bins = remaining_capacity > 0
    priority = np.zeros_like(bins)
    
    # Spatial fit: prefers bins with minimal remaining space
    spatial_fit = -remaining_capacity
    spatial_fit[~valid_bins] = -np.inf
    
    # Future potential: probability that next item fits into remaining space
    future_potential = norm.cdf(remaining_capacity, loc=mu, scale=sigma)
    future_potential[~valid_bins] = 0.0
    
    # Combine spatial fit and future potential
    combined = weights['spatial'] * spatial_fit + weights['future'] * future_potential
    
    # Fragmentation penalty: penalize bins with very small remaining space
    fragmentation_threshold = tunable([0.1, 0.2])
    fragmentation_penalty = np.where(remaining_capacity < fragmentation_threshold,
                                    -weights['fragmentation'], 0.0)
    
    priority = combined + fragmentation_penalty
    priority[~valid_bins] = -np.inf
    
    return priority

call llm times: 2
-------------------


............
launch 64 evaluate tasks
current thread_i 3
this best socre: -10000000000.0; best score: -10000000000.0; global score: -10000000000.0; space size: 288; measure cnt: 64
..................................
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -10000000000.0; space size: 288; measure cnt: 128
......................................................................
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -10000000000.0; space size: 288; measure cnt: 192
sampler suggest should end sample, break
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
    """Improved priority function considering spatial fit and future packing potential."""
    remaining = bins - item
    valid = remaining > 0  # Only consider bins where the item fits
    
    # Spatial fit: How well the item fits into the bin
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    spatial_fit[valid] = 1.0 / (1.0 + np.exp(-tunable([0.5, 1.0]) * (bins[valid] - item)))
    
    # Future potential: Remaining space after adding the item
    future_potential = np.zeros_like(bins, dtype=np.float64)
    future_potential[valid] = tunable([1.0, 0.5]) * (remaining[valid] > tunable([item * 0.5, 0.1]))
    
    # Combine the scores with tunable weights
    spatial_weight = tunable([0.7, 0.5])
    future_weight = tunable([0.3, 0.5])
    priorities = spatial_weight * spatial_fit + future_weight * future_potential
    
    return priorities

call llm times: 3
-------------------


........................................................................................................................................................
current thread_i 2
launch 32 evaluate tasks
current thread_i 4
current thread_i 0
this best socre: -292.35; best score: -292.35; global score: -292.35; space size: 32; measure cnt: 32
sampler suggest should end sample, break
INFO:absl:Best score increased to -292.35
-------------------
    """Returns priority with which we want to add item to each bin, considering both spatial fit and future potential."""
    # Calculate remaining capacities after adding the item
    remaining = bins - item
    # Bins that cannot fit the item have 0 priority
    valid_bins = remaining > 0
    
    # Calculate spatial fit: normalized ratio of item to bin capacity
    ratios = np.zeros_like(bins, dtype=np.float64)
    ratios[valid_bins] = item / bins[valid_bins]
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    spatial_fit[valid_bins] = (ratios[valid_bins] - np.min(ratios[valid_bins])) / (np.max(ratios[valid_bins]) - np.min(ratios[valid_bins] + np.finfo(float).eps))
    
    # Calculate future potential: harmonic mean of remaining capacity and item size, normalized
    harmonic_mean = np.zeros_like(bins, dtype=np.float64)
    harmonic_mean[valid_bins] = (2 * remaining[valid_bins] * item) / (remaining[valid_bins] + item)
    future_potential = np.zeros_like(bins, dtype=np.float64)
    future_potential[valid_bins] = (harmonic_mean[valid_bins] - np.min(harmonic_mean[valid_bins])) / (np.max(harmonic_mean[valid_bins]) - np.min(harmonic_mean[valid_bins] + np.finfo(float).eps))
    
    # Combine spatial fit and future potential with tunable weights
    weight_spatial = tunable([0.5, 0.6, 0.7])
    weight_future = tunable([0.5, 0.4, 0.3])
    combined = weight_spatial * spatial_fit + weight_future * future_potential
    
    # Ensure priority is zero for invalid bins
    combined[~valid_bins] = 0
    
    return combined

call llm times: 4
-------------------


.......................................................................
launch 9 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -292.35; space size: 9; measure cnt: 9
sampler suggest should end sample, break
-------------------
    """Improved priority function considering spatial fit and future potential."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0
    
    # Spatial fit component: How well the item fits into the bin
    fit_ratio = item / (bins + tunable([1e-6]))  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-tunable([5, 10]) * (fit_ratio - 0.5)))
    
    # Future potential component: Penalize bins with too much or too little remaining space
    ideal_remaining = tunable([0.1, 0.2])  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - tunable([0.0, 0.1]) * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-tunable([5, 10]) * (remaining_scaled - ideal_remaining)))
    
    # Combine components with tunable weights
    weight_fit = tunable([0.5, 0.7, 0.9])
    weight_future = tunable([0.3, 0.5])
    weight_penalty = tunable([0.1, 0.2])
    
    # Penalize the number of bins used (tunable penalty strength)
    num_bins_penalty = weight_penalty * tunable([0.1, 0.5]) * len(bins)
    
    # Combine into priority score
    priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )
    
    # Ensure invalid bins have the lowest priority
    priority[~valid_bins] = -np.inf
    
    return priority

call llm times: 5
-------------------


..............
launch 64 evaluate tasks
current thread_i 5
current thread_i 8
this best socre: -211.75; best score: -211.75; global score: -211.75; space size: 384; measure cnt: 64
.........................
launch 64 evaluate tasks
this best socre: -211.75; best score: -211.75; global score: -211.75; space size: 384; measure cnt: 128
.....................................................
launch 64 evaluate tasks
this best socre: -211.75; best score: -211.75; global score: -211.75; space size: 384; measure cnt: 192
.................................................................................
launch 64 evaluate tasks
this best socre: -211.75; best score: -211.75; global score: -211.75; space size: 384; measure cnt: 256
sampler suggest should end sample, break
INFO:absl:Best score increased to -211.75
-------------------
    """Returns priority with which we want to add item to each bin.
    
    This version considers both spatial fit and future packing potential by:
    1. Penalizing bins where the item takes up too much capacity
    2. Rewarding bins with higher remaining capacity after adding the item
    3. Balancing between immediate fit and long-term efficiency
    
    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.
    
    Return:
        Array of same size as bins with priority score of each bin.
    """
    # Calculate remaining capacity for each bin
    remaining_capacity = bins - item
    remaining_capacity[remaining_capacity < 0] = 0  # Ensure non-negative
    
    # Spatial fit factor: How well the item fits into the bin
    fit_factor = item / (bins + tunable([1e-5, 1e-4]))  # Avoid division by zero
    
    # Utilization factor: Prefer bins that are neither too empty nor too full
    utilization_factor = remaining_capacity / bins
    utilization_factor = np.where(utilization_factor < tunable([0.2, 0.3]), 
                                 tunable([0.0, 0.1]), utilization_factor)
    
    # Future potential factor: How much capacity is left after adding the item
    future_factor = (remaining_capacity - item) / bins
    future_factor = np.maximum(future_factor, 0)  # Only consider positive future capacity
    
    # Combine factors with tunable weights
    weight_fit = tunable([0.4, 0.5])
    weight_utilization = tunable([0.3, 0.4])
    weight_future = tunable([0.2, 0.3])
    
    # Calculate priority as a weighted sum
    priority = (weight_fit * (1 - fit_factor) +
               weight_utilization * utilization_factor +
               weight_future * future_factor)
    
    # Penalize bins where adding the item would leave very little space
    space_after = remaining_capacity - item
    space_penalty = np.where(space_after < tunable([0.1, 0.2]), 
                            tunable([0.5, 0.7]), 0)
    priority -= space_penalty
    
    # Ensure bins with zero remaining capacity have zero priority
    priority[remaining_capacity == 0] = 0
    
    return priority

call llm times: 6
-------------------


..........
launch 64 evaluate tasks
this best socre: -403.3; best score: -403.3; global score: -211.75; space size: 256; measure cnt: 64
.............................
launch 64 evaluate tasks
this best socre: -403.3; best score: -403.3; global score: -211.75; space size: 256; measure cnt: 128
...............................................................................................................
launch 64 evaluate tasks
this best socre: -403.3; best score: -403.3; global score: -211.75; space size: 256; measure cnt: 192
.......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
launch 58 evaluate tasks
this best socre: -403.3; best score: -403.3; global score: -211.75; space size: 256; measure cnt: 250
sampler suggest should end sample, break
-------------------
    """Returns priority with which we want to add item to each bin.

    This version introduces a novel priority strategy that balances spatial fit
    with future packing potential, incorporating tunable parameters for
    customization.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    # Calculate remaining capacity after adding the item
    remaining_capacity = bins - item
    valid_bins = remaining_capacity > 0

    # Spatial fit component: Higher priority for better fit
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    spatial_fit[valid_bins] = 1.0 / (1.0 + np.exp(-(bins[valid_bins] - item) / (bins[valid_bins] + 1e-8)))

    # Sparsity penalty: Penalize bins that leave too much space
    max_allowed_sparsity = tunable([0.3, 0.5, 0.7])  # Tunable parameter
    sparsity = remaining_capacity / bins
    sparsity_penalty = np.zeros_like(bins, dtype=np.float64)
    sparsity_penalty[valid_bins] = np.exp(-(sparsity[valid_bins] - max_allowed_sparsity) ** 2 /
                                          (2 * (tunable([0.1, 0.2]) ** 2)))

    # Bin utilization bonus: Reward bins that are neither too empty nor too full
    utilization = 1.0 - sparsity
    utilization_bonus = np.exp(-(utilization - tunable([0.7, 0.8])) ** 2 /
                               (2 * (tunable([0.1, 0.15]) ** 2)))

    # Future potential component: Heuristic based on average item size
    average_item_size = tunable([1.0, 2.0])  # Hypothetical average size
    future_potential = np.exp(-(remaining_capacity - average_item_size) ** 2 /
                              (2 * (tunable([0.5, 1.0]) ** 2)))
    future_potential[remaining_capacity < 0] = 0

    # Combine components with tunable weights
    weight_spatial = tunable([0.4, 0.6])
    weight_sparsity = tunable([0.3, 0.5])
    weight_utilization = tunable([0.2, 0.4])
    weight_future = tunable([0.1, 0.2])

    priorities = (
        weight_spatial * spatial_fit +
        weight_sparsity * sparsity_penalty +
        weight_utilization * utilization_bonus +
        weight_future * future_potential
    )

    # Ensure invalid bins have zero priority
    priorities[~valid_bins] = 0.0

    return priorities

call llm times: 7
-------------------


.
launch 64 evaluate tasks
this best socre: -217.95; best score: -217.95; global score: -211.75; space size: 1536; measure cnt: 64
......
launch 64 evaluate tasks
this best socre: -217.95; best score: -217.95; global score: -211.75; space size: 1536; measure cnt: 128
.....
launch 64 evaluate tasks
this best socre: -216.9; best score: -216.9; global score: -211.75; space size: 1536; measure cnt: 192
...........................................
launch 64 evaluate tasks
this best socre: -216.9; best score: -216.9; global score: -211.75; space size: 1536; measure cnt: 256
....................................
launch 64 evaluate tasks
current thread_i 9
this best socre: -216.85; best score: -216.85; global score: -211.75; space size: 1536; measure cnt: 320
......................................
launch 64 evaluate tasks
this best socre: -215.95; best score: -215.95; global score: -211.75; space size: 1536; measure cnt: 384
................................................
launch 64 evaluate tasks
this best socre: -215.95; best score: -215.95; global score: -211.75; space size: 1536; measure cnt: 448
....................................................
launch 64 evaluate tasks
current thread_i 7
this best socre: -215.95; best score: -215.95; global score: -211.75; space size: 1536; measure cnt: 512
..............................................................................................
launch 64 evaluate tasks
this best socre: -215.95; best score: -215.95; global score: -211.75; space size: 1536; measure cnt: 576
sampler suggest should end sample, break
-------------------
    """Returns priority with which we want to add item to each bin, using an improved strategy.
    
    The priority is calculated based on three components:
    1. Immediate fit: How well the item fits into the bin.
    2. Remaining space after placement: The space left in the bin after placing the item.
    3. Utilization rate: The current fill level of the bin.
    
    Args:
        item: Size of the item to be added to the bin.
        bins: Array of capacities for each bin.
        
    Returns:
        Array of same size as bins with priority scores for each bin.
    """
    # Calculate remaining capacities for each bin
    remaining = bins - item
    
    # Ensure remaining capacities are positive to avoid invalid fits
    valid_bins = remaining > 0
    
    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf
    
    # Calculate the three components for valid bins
    if np.any(valid_bins):
        # 1. Immediate Fit Component
        # Penalize very tight fits using a quadratic function
        fill_ratio = item / bins[valid_bins]
        immediate_fit = np.exp(-tunable([2.0, 3.0]) * (fill_ratio - tunable([0.5, 0.6]))**2)
        
        # 2. Remaining Space Component
        # Reward remaining space up to a certain threshold using a logarithmic function
        max_remaining = tunable([0.5, 0.6]) * bins[valid_bins]
        remaining_space = np.minimum(remaining[valid_bins], max_remaining)
        remaining_fit = np.log(remaining_space + 1)  # Adding 1 to avoid log(0)
        
        # 3. Utilization Rate Component
        # Reward higher utilization without overfilling
        utilization = bins[valid_bins] - remaining[valid_bins]
        utilization_rate = utilization / bins[valid_bins]
        utilization_fit = np.exp(-tunable([2.0, 3.0]) * (utilization_rate - tunable([0.8, 0.9]))**2)
        
        # Combine the components with tunable weights
        weight_immediate = tunable([0.4, 0.5])
        weight_remaining = tunable([0.3, 0.4])
        weight_utilization = tunable([0.3, 0.3])
        
        total_priority = (
            weight_immediate * immediate_fit +
            weight_remaining * remaining_fit +
            weight_utilization * utilization_fit
        )
        
        priorities[valid_bins] = total_priority
    
    return priorities

call llm times: 8
-------------------


...........
launch 64 evaluate tasks
this best socre: -304.65; best score: -304.65; global score: -211.75; space size: 256; measure cnt: 64
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -304.65; global score: -211.75; space size: 256; measure cnt: 64
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -304.65; global score: -211.75; space size: 256; measure cnt: 64
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -304.65; global score: -211.75; space size: 256; measure cnt: 64
sampler suggest should end sample, break
-------------------
    """Returns priority with which we want to add item to each bin.

    This version improves upon priority_v0 by considering both the spatial fit of the item
    in the bin and the future potential for packing additional items. It introduces tunable
    parameters to allow strategic innovation and optimization.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    # Avoid division by zero and ensure item fits in the bin
    valid = (bins > 0) & (item <= bins)
    
    # Initialize priorities to zero
    priorities = np.zeros_like(bins, dtype=np.float64)
    
    # Compute for valid bins
    if np.any(valid):
        ratio = item / bins[valid]
        
        # Spatial fit component: Higher when the item is a larger proportion of the bin's remaining capacity
        # The fit is scaled to prevent very large values when the ratio is small
        spatial_fit = 1.0 / (ratio + 1e-8)  # Adding a small epsilon to avoid division by zero
        
        # Future potential component: Higher when remaining capacity after adding the item is above a tunable threshold
        remaining_after = bins[valid] - item
        threshold = tunable([0.2, 0.5, 0.8])  # Tunable parameter for minimum remaining capacity
        future_potential = np.maximum(0, remaining_after - threshold)
        
        # Combine components with tunable weights
        spatial_weight = tunable([0.5, 0.7, 0.9])  # Tunable parameter for spatial fit weight
        future_weight = tunable([0.5, 0.3, 0.1])   # Tunable parameter for future potential weight
        
        total_priority = spatial_weight * spatial_fit + future_weight * future_potential
        
        # Apply a normalization to ensure priorities are on a similar scale
        # This helps in maintaining a balance between the components
        total_priority = total_priority / (spatial_weight + future_weight)
        
        priorities[valid] = total_priority
    
    return priorities

call llm times: 9
-------------------


.......................................................................................................................
launch 27 evaluate tasks
this best socre: -500.0; best score: -500.0; global score: -211.75; space size: 27; measure cnt: 27
sampler suggest should end sample, break
request...request...
-----------------------request...

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    ratios = item / bins
    log_ratios = np.log(ratios)
    priorities = -log_ratios
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit and future potential."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0
    
    # Spatial fit component: How well the item fits into the bin
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.5)))
    
    # Future potential component: Penalize bins with too much or too little remaining space
    ideal_remaining = 0.1  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Combine components with tunable weights
    weight_fit = 0.7
    weight_future = 0.5
    weight_penalty = 0.1
    
    # Penalize the number of bins used (tunable penalty strength)
    num_bins_penalty = weight_penalty * 0.5 * len(bins)
    
    # Combine into priority score
    priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )
    
    # Ensure invalid bins have the lowest priority
    priority[~valid_bins] = -np.inf
    
    return priority


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
request...
-----------------------


-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit and future packing potential."""
    remaining = bins - item
    valid = remaining > 0  # Only consider bins where the item fits
    
    # Spatial fit: How well the item fits into the bin
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    spatial_fit[valid] = 1.0 / (1.0 + np.exp(-0.5 * (bins[valid] - item)))
    
    # Future potential: Remaining space after adding the item
    future_potential = np.zeros_like(bins, dtype=np.float64)
    future_potential[valid] = 1.0 * (remaining[valid] > 0.1)
    
    # Combine the scores with tunable weights
    spatial_weight = 0.7
    future_weight = 0.3
    priorities = spatial_weight * spatial_fit + future_weight * future_potential
    
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit and future potential."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0
    
    # Spatial fit component: How well the item fits into the bin
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.5)))
    
    # Future potential component: Penalize bins with too much or too little remaining space
    ideal_remaining = 0.1  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Combine components with tunable weights
    weight_fit = 0.7
    weight_future = 0.5
    weight_penalty = 0.1
    
    # Penalize the number of bins used (tunable penalty strength)
    num_bins_penalty = weight_penalty * 0.5 * len(bins)
    
    # Combine into priority score
    priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )
    
    # Ensure invalid bins have the lowest priority
    priority[~valid_bins] = -np.inf
    
    return priority


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...request...
-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Returns priority with which we want to add item to each bin.

    This version improves upon priority_v0 by considering both the spatial fit of the item
    in the bin and the future potential for packing additional items. It introduces tunable
    parameters to allow strategic innovation and optimization.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    # Avoid division by zero and ensure item fits in the bin
    valid = (bins > 0) & (item <= bins)
    
    # Initialize priorities to zero
    priorities = np.zeros_like(bins, dtype=np.float64)
    
    # Compute for valid bins
    if np.any(valid):
        ratio = item / bins[valid]
        
        # Spatial fit component: Higher when the item is a larger proportion of the bin's remaining capacity
        # The fit is scaled to prevent very large values when the ratio is small
        spatial_fit = 1.0 / (ratio + 1e-8)  # Adding a small epsilon to avoid division by zero
        
        # Future potential component: Higher when remaining capacity after adding the item is above a tunable threshold
        remaining_after = bins[valid] - item
        threshold = 0.5  # Tunable parameter for minimum remaining capacity
        future_potential = np.maximum(0, remaining_after - threshold)
        
        # Combine components with tunable weights
        spatial_weight = 0.9  # Tunable parameter for spatial fit weight
        future_weight = 0.1   # Tunable parameter for future potential weight
        
        total_priority = spatial_weight * spatial_fit + future_weight * future_potential
        
        # Apply a normalization to ensure priorities are on a similar scale
        # This helps in maintaining a balance between the components
        total_priority = total_priority / (spatial_weight + future_weight)
        
        priorities[valid] = total_priority
    
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit and future potential."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0
    
    # Spatial fit component: How well the item fits into the bin
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.5)))
    
    # Future potential component: Penalize bins with too much or too little remaining space
    ideal_remaining = 0.1  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Combine components with tunable weights
    weight_fit = 0.7
    weight_future = 0.5
    weight_penalty = 0.1
    
    # Penalize the number of bins used (tunable penalty strength)
    num_bins_penalty = weight_penalty * 0.5 * len(bins)
    
    # Combine into priority score
    priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )
    
    # Ensure invalid bins have the lowest priority
    priority[~valid_bins] = -np.inf
    
    return priority


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Returns priority with which we want to add item to each bin.

    This version introduces a novel priority strategy that balances spatial fit
    with future packing potential, incorporating tunable parameters for
    customization.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    # Calculate remaining capacity after adding the item
    remaining_capacity = bins - item
    valid_bins = remaining_capacity > 0

    # Spatial fit component: Higher priority for better fit
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    spatial_fit[valid_bins] = 1.0 / (1.0 + np.exp(-(bins[valid_bins] - item) / (bins[valid_bins] + 1e-8)))

    # Sparsity penalty: Penalize bins that leave too much space
    max_allowed_sparsity = 0.5  # Tunable parameter
    sparsity = remaining_capacity / bins
    sparsity_penalty = np.zeros_like(bins, dtype=np.float64)
    sparsity_penalty[valid_bins] = np.exp(-(sparsity[valid_bins] - max_allowed_sparsity) ** 2 /
                                          (2 * (0.2 ** 2)))

    # Bin utilization bonus: Reward bins that are neither too empty nor too full
    utilization = 1.0 - sparsity
    utilization_bonus = np.exp(-(utilization - 0.8) ** 2 /
                               (2 * (0.15 ** 2)))

    # Future potential component: Heuristic based on average item size
    average_item_size = 2.0  # Hypothetical average size
    future_potential = np.exp(-(remaining_capacity - average_item_size) ** 2 /
                              (2 * (0.5 ** 2)))
    future_potential[remaining_capacity < 0] = 0

    # Combine components with tunable weights
    weight_spatial = 0.6
    weight_sparsity = 0.5
    weight_utilization = 0.2
    weight_future = 0.1

    priorities = (
        weight_spatial * spatial_fit +
        weight_sparsity * sparsity_penalty +
        weight_utilization * utilization_bonus +
        weight_future * future_potential
    )

    # Ensure invalid bins have zero priority
    priorities[~valid_bins] = 0.0

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit and future potential."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0
    
    # Spatial fit component: How well the item fits into the bin
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.5)))
    
    # Future potential component: Penalize bins with too much or too little remaining space
    ideal_remaining = 0.1  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Combine components with tunable weights
    weight_fit = 0.7
    weight_future = 0.5
    weight_penalty = 0.1
    
    # Penalize the number of bins used (tunable penalty strength)
    num_bins_penalty = weight_penalty * 0.5 * len(bins)
    
    # Combine into priority score
    priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )
    
    # Ensure invalid bins have the lowest priority
    priority[~valid_bins] = -np.inf
    
    return priority


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Returns priority with which we want to add item to each bin.

    This version introduces a novel priority strategy that balances spatial fit
    with future packing potential, incorporating tunable parameters for
    customization.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    # Calculate remaining capacity after adding the item
    remaining_capacity = bins - item
    valid_bins = remaining_capacity > 0

    # Spatial fit component: Higher priority for better fit
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    spatial_fit[valid_bins] = 1.0 / (1.0 + np.exp(-(bins[valid_bins] - item) / (bins[valid_bins] + 1e-8)))

    # Sparsity penalty: Penalize bins that leave too much space
    max_allowed_sparsity = 0.5  # Tunable parameter
    sparsity = remaining_capacity / bins
    sparsity_penalty = np.zeros_like(bins, dtype=np.float64)
    sparsity_penalty[valid_bins] = np.exp(-(sparsity[valid_bins] - max_allowed_sparsity) ** 2 /
                                          (2 * (0.2 ** 2)))

    # Bin utilization bonus: Reward bins that are neither too empty nor too full
    utilization = 1.0 - sparsity
    utilization_bonus = np.exp(-(utilization - 0.8) ** 2 /
                               (2 * (0.15 ** 2)))

    # Future potential component: Heuristic based on average item size
    average_item_size = 2.0  # Hypothetical average size
    future_potential = np.exp(-(remaining_capacity - average_item_size) ** 2 /
                              (2 * (0.5 ** 2)))
    future_potential[remaining_capacity < 0] = 0

    # Combine components with tunable weights
    weight_spatial = 0.6
    weight_sparsity = 0.5
    weight_utilization = 0.2
    weight_future = 0.1

    priorities = (
        weight_spatial * spatial_fit +
        weight_sparsity * sparsity_penalty +
        weight_utilization * utilization_bonus +
        weight_future * future_potential
    )

    # Ensure invalid bins have zero priority
    priorities[~valid_bins] = 0.0

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit and future potential."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0
    
    # Spatial fit component: How well the item fits into the bin
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.5)))
    
    # Future potential component: Penalize bins with too much or too little remaining space
    ideal_remaining = 0.1  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Combine components with tunable weights
    weight_fit = 0.7
    weight_future = 0.5
    weight_penalty = 0.1
    
    # Penalize the number of bins used (tunable penalty strength)
    num_bins_penalty = weight_penalty * 0.5 * len(bins)
    
    # Combine into priority score
    priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )
    
    # Ensure invalid bins have the lowest priority
    priority[~valid_bins] = -np.inf
    
    return priority


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

-----------------------

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Returns priority with which we want to add item to each bin, using an improved strategy.
    
    The priority is calculated based on three components:
    1. Immediate fit: How well the item fits into the bin.
    2. Remaining space after placement: The space left in the bin after placing the item.
    3. Utilization rate: The current fill level of the bin.
    
    Args:
        item: Size of the item to be added to the bin.
        bins: Array of capacities for each bin.
        
    Returns:
        Array of same size as bins with priority scores for each bin.
    """
    # Calculate remaining capacities for each bin
    remaining = bins - item
    
    # Ensure remaining capacities are positive to avoid invalid fits
    valid_bins = remaining > 0
    
    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf
    
    # Calculate the three components for valid bins
    if np.any(valid_bins):
        # 1. Immediate Fit Component
        # Penalize very tight fits using a quadratic function
        fill_ratio = item / bins[valid_bins]
        immediate_fit = np.exp(-3.0 * (fill_ratio - 0.6)**2)
        
        # 2. Remaining Space Component
        # Reward remaining space up to a certain threshold using a logarithmic function
        max_remaining = 0.6 * bins[valid_bins]
        remaining_space = np.minimum(remaining[valid_bins], max_remaining)
        remaining_fit = np.log(remaining_space + 1)  # Adding 1 to avoid log(0)
        
        # 3. Utilization Rate Component
        # Reward higher utilization without overfilling
        utilization = bins[valid_bins] - remaining[valid_bins]
        utilization_rate = utilization / bins[valid_bins]
        utilization_fit = np.exp(-2.0 * (utilization_rate - 0.8)**2)
        
        # Combine the components with tunable weights
        weight_immediate = 0.4
        weight_remaining = 0.3
        weight_utilization = 0.3
        
        total_priority = (
            weight_immediate * immediate_fit +
            weight_remaining * remaining_fit +
            weight_utilization * utilization_fit
        )
        
        priorities[valid_bins] = total_priority
    
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit and future potential."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0
    
    # Spatial fit component: How well the item fits into the bin
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.5)))
    
    # Future potential component: Penalize bins with too much or too little remaining space
    ideal_remaining = 0.1  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Combine components with tunable weights
    weight_fit = 0.7
    weight_future = 0.5
    weight_penalty = 0.1
    
    # Penalize the number of bins used (tunable penalty strength)
    num_bins_penalty = weight_penalty * 0.5 * len(bins)
    
    # Combine into priority score
    priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )
    
    # Ensure invalid bins have the lowest priority
    priority[~valid_bins] = -np.inf
    
    return priority


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Returns priority with which we want to add item to each bin.

    This version introduces a novel priority strategy that balances spatial fit
    with future packing potential, incorporating tunable parameters for
    customization.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    # Calculate remaining capacity after adding the item
    remaining_capacity = bins - item
    valid_bins = remaining_capacity > 0

    # Spatial fit component: Higher priority for better fit
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    spatial_fit[valid_bins] = 1.0 / (1.0 + np.exp(-(bins[valid_bins] - item) / (bins[valid_bins] + 1e-8)))

    # Sparsity penalty: Penalize bins that leave too much space
    max_allowed_sparsity = 0.5  # Tunable parameter
    sparsity = remaining_capacity / bins
    sparsity_penalty = np.zeros_like(bins, dtype=np.float64)
    sparsity_penalty[valid_bins] = np.exp(-(sparsity[valid_bins] - max_allowed_sparsity) ** 2 /
                                          (2 * (0.2 ** 2)))

    # Bin utilization bonus: Reward bins that are neither too empty nor too full
    utilization = 1.0 - sparsity
    utilization_bonus = np.exp(-(utilization - 0.8) ** 2 /
                               (2 * (0.15 ** 2)))

    # Future potential component: Heuristic based on average item size
    average_item_size = 2.0  # Hypothetical average size
    future_potential = np.exp(-(remaining_capacity - average_item_size) ** 2 /
                              (2 * (0.5 ** 2)))
    future_potential[remaining_capacity < 0] = 0

    # Combine components with tunable weights
    weight_spatial = 0.6
    weight_sparsity = 0.5
    weight_utilization = 0.2
    weight_future = 0.1

    priorities = (
        weight_spatial * spatial_fit +
        weight_sparsity * sparsity_penalty +
        weight_utilization * utilization_bonus +
        weight_future * future_potential
    )

    # Ensure invalid bins have zero priority
    priorities[~valid_bins] = 0.0

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit and future potential."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0
    
    # Spatial fit component: How well the item fits into the bin
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.5)))
    
    # Future potential component: Penalize bins with too much or too little remaining space
    ideal_remaining = 0.1  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Combine components with tunable weights
    weight_fit = 0.7
    weight_future = 0.5
    weight_penalty = 0.1
    
    # Penalize the number of bins used (tunable penalty strength)
    num_bins_penalty = weight_penalty * 0.5 * len(bins)
    
    # Combine into priority score
    priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )
    
    # Ensure invalid bins have the lowest priority
    priority[~valid_bins] = -np.inf
    
    return priority


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining > 0
    
    # Spatial fit component: How well the item fits into the bin
    # Using a weighted combination of fill ratio and space utilization
    fill_ratio = item / (bins + 1e-6)
    space_utilization = 1 - (remaining / (bins + 1e-6))
    
    # Future potential component: How well the bin can accommodate future items
    # Consider both remaining space and fragmentation
    ideal_remaining = tunable([0.1, 0.2, 0.3])  # Ideal remaining space
    remaining_scaled = remaining / np.max(bins)
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Diversity score: Encourage spreading items across different bins
    # Prevents over-packing a few bins while leaving others mostly empty
    diversity_score = 1 / (1 + np.exp(-tunable([0.5, 1.0, 1.5]) * (len(bins) - np.count_nonzero(valid))))
    
    # Combine components with tunable weights
    weight_spatial = tunable([0.6, 0.7, 0.8])
    weight_future = tunable([0.3, 0.4, 0.5])
    weight_diversity = tunable([0.1, 0.2, 0.3])
    
    spatial_fit = weight_spatial * (fill_ratio + space_utilization) / 2
    total_priority = (
        spatial_fit +
        weight_future * future_potential +
        weight_diversity * diversity_score
    )
    
    # Penalize bins that are too full or too empty
    # Prevents bins from becoming either too fragmented or too sparse
    fullness_penalty = tunable([0.1, 0.2, 0.3]) * np.exp(-tunable([1.0, 2.0, 3.0]) * np.abs(fill_ratio - 0.5))
    total_priority += fullness_penalty
    
    # Ensure invalid bins have the lowest priority
    total_priority[~valid] = -np.inf
    
    return total_priority

call llm times: 10
-------------------


...
current thread_i 0
launch 64 evaluate tasks
current thread_i 6
current thread_i 8
this best socre: -210.85; best score: -210.85; global score: -210.85; space size: 2187; measure cnt: 64
..................
launch 64 evaluate tasks
this best socre: -210.65; best score: -210.65; global score: -210.65; space size: 2187; measure cnt: 128
.............
launch 64 evaluate tasks
current thread_i 5
current thread_i 1
current thread_i 9
this best socre: -210.65; best score: -210.65; global score: -210.65; space size: 2187; measure cnt: 192
................
launch 64 evaluate tasks
this best socre: -210.65; best score: -210.65; global score: -210.65; space size: 2187; measure cnt: 256
.............
launch 64 evaluate tasks
current thread_i 7
this best socre: -210.65; best score: -210.65; global score: -210.65; space size: 2187; measure cnt: 320
sampler suggest should end sample, break
INFO:absl:Best score increased to -210.65
-------------------
    """Returns priority with which we want to add item to each bin, considering both fit and future capacity."""
    priorities = np.zeros_like(bins, dtype=float)
    
    # Tunable parameters
    min_remaining_threshold = tunable([0.2, 0.3, 0.4])
    penalty_weight = tunable([0.1, 0.2, 0.3])
    alpha = tunable([0.6, 0.7, 0.8])
    beta = tunable([0.4, 0.3, 0.2])
    
    for i, bin_cap in enumerate(bins):
        if item > bin_cap:
            priorities[i] = -np.inf  # Item cannot fit, assign lowest priority
            continue
        
        fit_ratio = item / bin_cap
        remaining = bin_cap - item
        remaining_ratio = remaining / bin_cap
        
        # Apply penalty if remaining space is too low
        if remaining_ratio < min_remaining_threshold:
            penalty = penalty_weight
        else:
            penalty = 0.0
        
        # Calculate priority as a weighted sum, subtracting penalty
        priority = alpha * fit_ratio + beta * remaining_ratio - penalty
        priorities[i] = priority
    
    return priorities

call llm times: 11
-------------------


................................................
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -210.65; space size: 81; measure cnt: 64
....................................................................................................................................................................................................................................................................................
launch 17 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -210.65; space size: 81; measure cnt: 81
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing that considers:
    
    1. Spatial fit: How well the item fits into the bin
    2. Future potential: How the choice affects future packing efficiency
    3. Large item handling: Special consideration for large items that are harder to pack
    
    Returns priority scores where higher values indicate better candidates for packing.
    """
    # Calculate remaining capacity if item is placed in each bin
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0
    
    # Spatial fit component: How well the item fits into the bin
    # Using a sigmoid function to create a smooth priority curve
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-tunable([5, 10]) * (fit_ratio - tunable([0.3, 0.5, 0.7]))))
    
    # Future potential component: Penalize bins that are too full or too empty
    # We want to leave enough space for future items while avoiding excessive fragmentation
    ideal_remaining = tunable([0.1, 0.2, 0.3])  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - tunable([0.05, 0.1, 0.15]) * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    
    # Use a quadratic function to penalize deviations from ideal remaining space
    future_potential = -np.abs(remaining_scaled - ideal_remaining) ** tunable([1.5, 2, 2.5])
    
    # Large item handling component: Prioritize bins that can accommodate large items
    # without leaving too much unused space
    large_item_threshold = tunable([0.7, 0.8, 0.9]) * np.max(bins)
    large_item_penalty = np.where(item > large_item_threshold, 
                                 tunable([-0.5, -1, -1.5]), 
                                 0)
    
    # Combine components with tunable weights
    weight_fit = tunable([0.6, 0.7, 0.8])
    weight_future = tunable([0.4, 0.5, 0.6])
    weight_large_item = tunable([0.1, 0.2, 0.3])
    
    # Calculate final priority score
    priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential +
        weight_large_item * large_item_penalty
    )
    
    # Ensure invalid bins have the lowest priority
    priority[~valid_bins] = -np.inf
    
    return priority

call llm times: 12
-------------------



launch 64 evaluate tasks
current thread_i 4
current thread_i 2
this best socre: -211.9; best score: -211.9; global score: -210.65; space size: 39366; measure cnt: 64

launch 64 evaluate tasks
this best socre: -211.9; best score: -211.9; global score: -210.65; space size: 39366; measure cnt: 128

launch 64 evaluate tasks
this best socre: -211.9; best score: -211.9; global score: -210.65; space size: 39366; measure cnt: 192

launch 64 evaluate tasks
this best socre: -211.85; best score: -211.85; global score: -210.65; space size: 39366; measure cnt: 256

launch 64 evaluate tasks
this best socre: -211.85; best score: -211.85; global score: -210.65; space size: 39366; measure cnt: 320

launch 64 evaluate tasks
this best socre: -211.85; best score: -211.85; global score: -210.65; space size: 39366; measure cnt: 384

launch 64 evaluate tasks
this best socre: -211.85; best score: -211.85; global score: -210.65; space size: 39366; measure cnt: 448
sampler suggest should end sample, break
-------------------
    """Improved priority function for online bin-packing.

    This version introduces a novel strategy that dynamically balances spatial fit,
    future potential, and bin utilization while exposing tunable parameters for
    strategic optimization.

    Args:
        item: Size of the item to be placed.
        bins: Array of remaining capacities for each bin.

    Returns:
        Array of priority scores for each bin.
    """
    # Calculate remaining capacity after placing the item
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-tunable([5, 10]) * (fit_ratio - tunable([0.5, 0.7]))))

    # Future potential component: Penalize bins that are too full or too empty
    ideal_remaining = tunable([0.1, 0.2]) * bins  # Ideal remaining space as a percentage of bin capacity
    remaining_after = remaining_capacity - tunable([0.05, 0.1]) * item  # Account for fragmentation
    remaining_scaled = remaining_after / (np.max(bins) + 1e-6)  # Normalize by max bin capacity
    future_potential = 1 / (1 + np.exp(-tunable([10, 20]) * (remaining_scaled - ideal_remaining)))

    # Bin utilization penalty: Discourage using too many bins
    num_bins_penalty = tunable([0.1, 0.2]) * 0.5 * len(bins)

    # Combine components with tunable weights
    weight_fit = tunable([0.6, 0.8])
    weight_future = tunable([0.4, 0.6])
    
    total_priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )

    # Normalize priorities to maintain balance
    total_priority = total_priority / (weight_fit + weight_future)

    # Ensure invalid bins have the lowest priority
    total_priority[~valid_bins] = -np.inf

    return total_priority

call llm times: 13
-------------------


...........
launch 64 evaluate tasks
this best socre: -212.0; best score: -212.0; global score: -210.65; space size: 256; measure cnt: 64
..........................................................
launch 64 evaluate tasks
this best socre: -212.0; best score: -212.0; global score: -210.65; space size: 256; measure cnt: 128
......................................................................................................
launch 64 evaluate tasks
this best socre: -212.0; best score: -212.0; global score: -210.65; space size: 256; measure cnt: 192
...................................................................................................................................................................................................................................................................................................................................................................................................................
launch 54 evaluate tasks
this best socre: -212.0; best score: -212.0; global score: -210.65; space size: 256; measure cnt: 246
sampler suggest should end sample, break
-------------------
    """Returns priority with which we want to add item to each bin, 
    considering both spatial fit and future packing potential.
    
    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.
        
    Return:
        Array of same size as bins with priority score of each bin.
    """
    # Identify bins that can fit the item
    can_fit = bins >= item
    # Initialize priority array with -inf for bins that cannot fit the item
    priorities = np.full_like(bins, -np.inf, dtype=np.float64)
    
    if np.any(can_fit):
        # Calculate spatial fit component
        ratio = item / bins[can_fit]
        spatial_fit = ratio * (1 - ratio)
        
        # Calculate future potential component
        remaining_ratio = (bins[can_fit] - item) / bins[can_fit]
        decay_rate = tunable([0.1, 0.5, 1.0])  # Tunable decay rate
        future_potential = remaining_ratio * np.exp(-decay_rate * remaining_ratio)
        
        # Combine components with tunable weights
        weight_spatial = tunable([0.5, 0.7, 0.9])  # Tunable weight for spatial fit
        weight_future = tunable([0.5, 0.3, 0.1])    # Tunable weight for future potential
        
        combined_priority = weight_spatial * spatial_fit + weight_future * future_potential
        priorities[can_fit] = combined_priority
    
    return priorities

call llm times: 14
-------------------


..............................................................................................................
launch 27 evaluate tasks
this best socre: -289.7; best score: -289.7; global score: -210.65; space size: 27; measure cnt: 27
sampler suggest should end sample, break
-------------------
    """Improved priority function for online bin-packing.

    This version introduces a novel strategy that considers both spatial fit and future packing potential,
    with tunable parameters for customization.

    Args:
        item: Size of the item to be added.
        bins: Array of current bin capacities.

    Returns:
        Array of priority scores for each bin.
    """
    import numpy as np
    from tunable import tunable

    # Calculate remaining capacity after placing the item
    remaining_capacity = bins - item
    valid_bins = remaining_capacity > 0

    # Calculate spatial fit with fragmentation awareness
    fit_ratio = item / (bins + 1e-8)  # Avoid division by zero
    # Penalize fits that leave too much or too little space
    ideal_fit = tunable([0.6, 0.7, 0.8])
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - ideal_fit)))

    # Calculate future potential based on dynamic average item size
    # Assume we have access to the average item size up to now
    average_item_size = tunable([1.0, 2.0, 3.0])  # Example tunable parameter
    ideal_remaining = tunable([0.1, 0.2, 0.3])  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - average_item_size  # Account for future items
    # Scale remaining space relative to bin capacity
    remaining_scaled = remaining_after / (bins + 1e-8)
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))

    # Calculate utilization gradient
    utilization = bins - remaining_capacity
    utilization_ratio = utilization / bins
    # Reward bins that are neither too empty nor too full
    utilization_bonus = np.exp(-((utilization_ratio - 0.7) ** 2) / (2 * (0.15 ** 2)))

    # Combine components with tunable weights
    weight_spatial = tunable([0.5, 0.6, 0.7])
    weight_future = tunable([0.3, 0.4, 0.5])
    weight_utilization = tunable([0.2, 0.3, 0.4])

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus
    )

    # Ensure invalid bins have zero priority
    priorities[~valid_bins] = 0.0

    return priorities

call llm times: 15
-------------------


..
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -210.65; space size: 729; measure cnt: 64
..........
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -210.65; space size: 729; measure cnt: 128
............
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -210.65; space size: 729; measure cnt: 192
sampler suggest should end sample, break
-------------------
    """Improved priority function considering spatial fit, future potential, and distribution awareness."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    fit_ratio = item / (remaining_capacity + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-tunable([5, 10]) * (fit_ratio - tunable([0.5, 0.7]))))
    spatial_fit[~valid_bins] = 0

    # Future potential component: Penalize bins with too little or too much remaining space
    ideal_remaining = tunable([0.1, 0.2])  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - tunable([0.1, 0.2]) * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-tunable([10, 20]) * (remaining_scaled - ideal_remaining)))
    future_potential[remaining_after < 0] = 0

    # Bin utilization bonus: Reward bins that are moderately filled
    utilization = 1.0 - (remaining_capacity / bins)
    utilization_bonus = np.exp(-tunable([0.1, 0.2]) * (utilization - tunable([0.7, 0.8])) ** 2)

    # Fragmentation penalty: Penalize bins that leave too little usable space
    fragmentation_penalty = np.zeros_like(bins, dtype=np.float64)
    fragmentation_threshold = tunable([0.1, 0.2])  # Minimum acceptable remaining space
    fragmentation_penalty[remaining_capacity < fragmentation_threshold] = tunable([0.5, 0.8])

    # Distribution awareness component: Penalize bins with remaining capacity too high compared to others
    mean_remaining = np.mean(remaining_capacity[valid_bins])
    std_remaining = np.std(remaining_capacity[valid_bins])
    distribution_penalty = np.exp(-tunable([0.5, 1.0]) * ((remaining_capacity - mean_remaining) / (std_remaining + 1e-6)) ** 2)
    distribution_penalty[~valid_bins] = 0

    # Combine components with tunable weights
    weight_spatial = tunable([0.6, 0.7])
    weight_future = tunable([0.3, 0.4])
    weight_utilization = tunable([0.2, 0.3])
    weight_fragmentation = tunable([0.1, 0.2])
    weight_distribution = tunable([0.1, 0.2])

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus -
        weight_fragmentation * fragmentation_penalty -
        weight_distribution * distribution_penalty
    )

    # Ensure invalid bins have the lowest priority
    priorities[~valid_bins] = -np.inf

    return priorities

call llm times: 16
-------------------



launch 64 evaluate tasks
this best socre: -220.35; best score: -220.35; global score: -210.65; space size: 32768; measure cnt: 64
..................................................................
launch 64 evaluate tasks
this best socre: -220.35; best score: -220.35; global score: -210.65; space size: 32768; measure cnt: 128
.........................
launch 64 evaluate tasks
this best socre: -220.35; best score: -220.35; global score: -210.65; space size: 32768; measure cnt: 192
...
launch 64 evaluate tasks
this best socre: -220.35; best score: -220.35; global score: -210.65; space size: 32768; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-tunable([5, 10]) * (fit_ratio - tunable([0.5, 0.6]))))

        # Future potential component
        ideal_remaining = tunable([0.1, 0.2]) * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - tunable([0.1, 0.2]) * item
        future_potential = 1 / (1 + np.exp(-tunable([10, 20]) * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-tunable([0.5, 1.0]) * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-tunable([2, 5]) * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = tunable([0.4, 0.6])
        weight_future = tunable([0.3, 0.5])
        weight_similarity = tunable([0.1, 0.3])
        weight_diversity = tunable([0.1, 0.2])
        penalty = tunable([0.05, 0.15]) * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 17
-------------------


.
launch 64 evaluate tasks
this best socre: -210.35; best score: -210.35; global score: -210.35; space size: 4096; measure cnt: 64
................
launch 64 evaluate tasks
this best socre: -210.35; best score: -210.35; global score: -210.35; space size: 4096; measure cnt: 128
...................
launch 64 evaluate tasks
this best socre: -210.35; best score: -210.35; global score: -210.35; space size: 4096; measure cnt: 192
...............................................
launch 64 evaluate tasks
this best socre: -210.35; best score: -210.35; global score: -210.35; space size: 4096; measure cnt: 256
sampler suggest should end sample, break
INFO:absl:Best score increased to -210.35
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining > 0
    
    # Spatial fit component: How well the item fits into the bin
    # Using a weighted combination of fill ratio and space utilization
    fill_ratio = item / (bins + 1e-6)
    space_utilization = 1 - (remaining / (bins + 1e-6))
    
    # Future potential component: How well the bin can accommodate future items
    # Consider both remaining space and fragmentation
    ideal_remaining = 0.1  # Ideal remaining space
    remaining_scaled = remaining / np.max(bins)
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Diversity score: Encourage spreading items across different bins
    # Prevents over-packing a few bins while leaving others mostly empty
    diversity_score = 1 / (1 + np.exp(-1.5 * (len(bins) - np.count_nonzero(valid))))
    
    # Combine components with tunable weights
    weight_spatial = 0.7
    weight_future = 0.5
    weight_diversity = 0.1
    
    spatial_fit = weight_spatial * (fill_ratio + space_utilization) / 2
    total_priority = (
        spatial_fit +
        weight_future * future_potential +
        weight_diversity * diversity_score
    )
    
    # Penalize bins that are too full or too empty
    # Prevents bins from becoming either too fragmented or too sparse
    fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
    total_priority += fullness_penalty
    
    # Ensure invalid bins have the lowest priority
    total_priority[~valid] = -np.inf
    
    return total_priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.1
        weight_diversity = 0.2
        penalty = 0.05 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining > 0
    
    # Spatial fit component: How well the item fits into the bin
    # Using a weighted combination of fill ratio and space utilization
    fill_ratio = item / (bins + 1e-6)
    space_utilization = 1 - (remaining / (bins + 1e-6))
    
    # Future potential component: How well the bin can accommodate future items
    # Consider both remaining space and fragmentation
    ideal_remaining = 0.1  # Ideal remaining space
    remaining_scaled = remaining / np.max(bins)
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Diversity score: Encourage spreading items across different bins
    # Prevents over-packing a few bins while leaving others mostly empty
    diversity_score = 1 / (1 + np.exp(-1.5 * (len(bins) - np.count_nonzero(valid))))
    
    # Combine components with tunable weights
    weight_spatial = 0.7
    weight_future = 0.5
    weight_diversity = 0.1
    
    spatial_fit = weight_spatial * (fill_ratio + space_utilization) / 2
    total_priority = (
        spatial_fit +
        weight_future * future_potential +
        weight_diversity * diversity_score
    )
    
    # Penalize bins that are too full or too empty
    # Prevents bins from becoming either too fragmented or too sparse
    fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
    total_priority += fullness_penalty
    
    # Ensure invalid bins have the lowest priority
    total_priority[~valid] = -np.inf
    
    return total_priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.1
        weight_diversity = 0.2
        penalty = 0.05 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

request...
-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining > 0
    
    # Spatial fit component: How well the item fits into the bin
    # Using a weighted combination of fill ratio and space utilization
    fill_ratio = item / (bins + 1e-6)
    space_utilization = 1 - (remaining / (bins + 1e-6))
    
    # Future potential component: How well the bin can accommodate future items
    # Consider both remaining space and fragmentation
    ideal_remaining = 0.1  # Ideal remaining space
    remaining_scaled = remaining / np.max(bins)
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Diversity score: Encourage spreading items across different bins
    # Prevents over-packing a few bins while leaving others mostly empty
    diversity_score = 1 / (1 + np.exp(-1.5 * (len(bins) - np.count_nonzero(valid))))
    
    # Combine components with tunable weights
    weight_spatial = 0.7
    weight_future = 0.5
    weight_diversity = 0.1
    
    spatial_fit = weight_spatial * (fill_ratio + space_utilization) / 2
    total_priority = (
        spatial_fit +
        weight_future * future_potential +
        weight_diversity * diversity_score
    )
    
    # Penalize bins that are too full or too empty
    # Prevents bins from becoming either too fragmented or too sparse
    fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
    total_priority += fullness_penalty
    
    # Ensure invalid bins have the lowest priority
    total_priority[~valid] = -np.inf
    
    return total_priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.1
        weight_diversity = 0.2
        penalty = 0.05 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining > 0
    
    # Spatial fit component: How well the item fits into the bin
    # Using a weighted combination of fill ratio and space utilization
    fill_ratio = item / (bins + 1e-6)
    space_utilization = 1 - (remaining / (bins + 1e-6))
    
    # Future potential component: How well the bin can accommodate future items
    # Consider both remaining space and fragmentation
    ideal_remaining = 0.1  # Ideal remaining space
    remaining_scaled = remaining / np.max(bins)
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Diversity score: Encourage spreading items across different bins
    # Prevents over-packing a few bins while leaving others mostly empty
    diversity_score = 1 / (1 + np.exp(-1.5 * (len(bins) - np.count_nonzero(valid))))
    
    # Combine components with tunable weights
    weight_spatial = 0.7
    weight_future = 0.5
    weight_diversity = 0.1
    
    spatial_fit = weight_spatial * (fill_ratio + space_utilization) / 2
    total_priority = (
        spatial_fit +
        weight_future * future_potential +
        weight_diversity * diversity_score
    )
    
    # Penalize bins that are too full or too empty
    # Prevents bins from becoming either too fragmented or too sparse
    fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
    total_priority += fullness_penalty
    
    # Ensure invalid bins have the lowest priority
    total_priority[~valid] = -np.inf
    
    return total_priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.1
        weight_diversity = 0.2
        penalty = 0.05 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

-----------------------
request...
-----------------------request...

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining > 0
    
    # Spatial fit component: How well the item fits into the bin
    # Using a weighted combination of fill ratio and space utilization
    fill_ratio = item / (bins + 1e-6)
    space_utilization = 1 - (remaining / (bins + 1e-6))
    
    # Future potential component: How well the bin can accommodate future items
    # Consider both remaining space and fragmentation
    ideal_remaining = 0.1  # Ideal remaining space
    remaining_scaled = remaining / np.max(bins)
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Diversity score: Encourage spreading items across different bins
    # Prevents over-packing a few bins while leaving others mostly empty
    diversity_score = 1 / (1 + np.exp(-1.5 * (len(bins) - np.count_nonzero(valid))))
    
    # Combine components with tunable weights
    weight_spatial = 0.7
    weight_future = 0.5
    weight_diversity = 0.1
    
    spatial_fit = weight_spatial * (fill_ratio + space_utilization) / 2
    total_priority = (
        spatial_fit +
        weight_future * future_potential +
        weight_diversity * diversity_score
    )
    
    # Penalize bins that are too full or too empty
    # Prevents bins from becoming either too fragmented or too sparse
    fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
    total_priority += fullness_penalty
    
    # Ensure invalid bins have the lowest priority
    total_priority[~valid] = -np.inf
    
    return total_priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.1
        weight_diversity = 0.2
        penalty = 0.05 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining > 0
    
    # Spatial fit component: How well the item fits into the bin
    # Using a weighted combination of fill ratio and space utilization
    fill_ratio = item / (bins + 1e-6)
    space_utilization = 1 - (remaining / (bins + 1e-6))
    
    # Future potential component: How well the bin can accommodate future items
    # Consider both remaining space and fragmentation
    ideal_remaining = 0.1  # Ideal remaining space
    remaining_scaled = remaining / np.max(bins)
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Diversity score: Encourage spreading items across different bins
    # Prevents over-packing a few bins while leaving others mostly empty
    diversity_score = 1 / (1 + np.exp(-1.5 * (len(bins) - np.count_nonzero(valid))))
    
    # Combine components with tunable weights
    weight_spatial = 0.7
    weight_future = 0.5
    weight_diversity = 0.1
    
    spatial_fit = weight_spatial * (fill_ratio + space_utilization) / 2
    total_priority = (
        spatial_fit +
        weight_future * future_potential +
        weight_diversity * diversity_score
    )
    
    # Penalize bins that are too full or too empty
    # Prevents bins from becoming either too fragmented or too sparse
    fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
    total_priority += fullness_penalty
    
    # Ensure invalid bins have the lowest priority
    total_priority[~valid] = -np.inf
    
    return total_priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.1
        weight_diversity = 0.2
        penalty = 0.05 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit and future potential."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0
    
    # Spatial fit component: How well the item fits into the bin
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.5)))
    
    # Future potential component: Penalize bins with too much or too little remaining space
    ideal_remaining = 0.1  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Combine components with tunable weights
    weight_fit = 0.7
    weight_future = 0.5
    weight_penalty = 0.1
    
    # Penalize the number of bins used (tunable penalty strength)
    num_bins_penalty = weight_penalty * 0.5 * len(bins)
    
    # Combine into priority score
    priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )
    
    # Ensure invalid bins have the lowest priority
    priority[~valid_bins] = -np.inf
    
    return priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.1
        weight_diversity = 0.2
        penalty = 0.05 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
request...------------------------------------------

    """Improved priority function considering spatial fit, future potential, and bin utilization."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    fit_ratio = item / (bins + 1e-8)  # Avoid division by zero
    spatial_fit[valid_bins] = 1.0 / (1.0 + np.exp(-(fit_ratio[valid_bins] - 0.5) * tunable([5, 10, 15])))

    # Future potential component: Reward bins with remaining space close to ideal
    ideal_remaining = tunable([0.1, 0.2, 0.3]) * bins  # Ideal remaining space as a fraction of bin capacity
    remaining_scaled = remaining_capacity / (np.max(bins) + 1e-8)  # Normalize by max bin capacity
    future_potential = np.zeros_like(bins, dtype=np.float64)
    future_potential[valid_bins] = np.exp(-(remaining_scaled[valid_bins] - ideal_remaining[valid_bins]) ** 2 /
                                         (2 * (tunable([0.1, 0.2, 0.3]) ** 2)))

    # Bin utilization bonus: Reward bins that are neither too empty nor too full
    utilization = 1.0 - remaining_scaled
    utilization_bonus = np.exp(-(utilization - tunable([0.8, 0.85, 0.9])) ** 2 /
                               (2 * (tunable([0.1, 0.15, 0.2]) ** 2)))

    # Penalty for too much or too little remaining space
    space_penalty = np.exp(-(np.abs(remaining_scaled - tunable([0.1, 0.2, 0.3])) - tunable([0.05, 0.1, 0.15])) ** 2 /
                           (2 * (tunable([0.05, 0.1, 0.15]) ** 2)))
    space_penalty[valid_bins] = 1.0 - space_penalty[valid_bins]

    # Combine components with tunable weights
    weight_spatial = tunable([0.4, 0.5, 0.6])
    weight_future = tunable([0.3, 0.4, 0.5])
    weight_utilization = tunable([0.2, 0.3, 0.4])
    weight_penalty = tunable([0.1, 0.2, 0.3])

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus +
        weight_penalty * space_penalty
    )

    # Ensure invalid bins have zero priority
    priorities[~valid_bins] = 0.0

    return priorities

call llm times: 18
-------------------



import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing that considers:
    
    1. Spatial fit: How well the item fits into the bin
    2. Future potential: How the choice affects future packing efficiency
    3. Large item handling: Special consideration for large items that are harder to pack
    
    Returns priority scores where higher values indicate better candidates for packing.
    """
    # Calculate remaining capacity if item is placed in each bin
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0
    
    # Spatial fit component: How well the item fits into the bin
    # Using a sigmoid function to create a smooth priority curve
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.3)))
    
    # Future potential component: Penalize bins that are too full or too empty
    # We want to leave enough space for future items while avoiding excessive fragmentation
    ideal_remaining = 0.1  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.15 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    
    # Use a quadratic function to penalize deviations from ideal remaining space
    future_potential = -np.abs(remaining_scaled - ideal_remaining) ** 2
    
    # Large item handling component: Prioritize bins that can accommodate large items
    # without leaving too much unused space
    large_item_threshold = 0.7 * np.max(bins)
    large_item_penalty = np.where(item > large_item_threshold, 
                                 -0.5, 
                                 0)
    
    # Combine components with tunable weights
    weight_fit = 0.7
    weight_future = 0.6
    weight_large_item = 0.2
    
    # Calculate final priority score
    priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential +
        weight_large_item * large_item_penalty
    )
    
    # Ensure invalid bins have the lowest priority
    priority[~valid_bins] = -np.inf
    
    return priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.1
        weight_diversity = 0.2
        penalty = 0.05 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.


-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function for online bin-packing.

    This version introduces a novel strategy that dynamically balances spatial fit,
    future potential, and bin utilization while exposing tunable parameters for
    strategic optimization.

    Args:
        item: Size of the item to be placed.
        bins: Array of remaining capacities for each bin.

    Returns:
        Array of priority scores for each bin.
    """
    # Calculate remaining capacity after placing the item
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.5)))

    # Future potential component: Penalize bins that are too full or too empty
    ideal_remaining = 0.1 * bins  # Ideal remaining space as a percentage of bin capacity
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / (np.max(bins) + 1e-6)  # Normalize by max bin capacity
    future_potential = 1 / (1 + np.exp(-20 * (remaining_scaled - ideal_remaining)))

    # Bin utilization penalty: Discourage using too many bins
    num_bins_penalty = 0.2 * 0.5 * len(bins)

    # Combine components with tunable weights
    weight_fit = 0.6
    weight_future = 0.4
    
    total_priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )

    # Normalize priorities to maintain balance
    total_priority = total_priority / (weight_fit + weight_future)

    # Ensure invalid bins have the lowest priority
    total_priority[~valid_bins] = -np.inf

    return total_priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.1
        weight_diversity = 0.2
        penalty = 0.05 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
-----------------------

-----------------------

launch 64 evaluate tasks
this best socre: -210.35; best score: -210.35; global score: -210.35; space size: 531441; measure cnt: 64

launch 64 evaluate tasks
this best socre: -210.35; best score: -210.35; global score: -210.35; space size: 531441; measure cnt: 128

launch 64 evaluate tasks
this best socre: -210.35; best score: -210.35; global score: -210.35; space size: 531441; measure cnt: 192

launch 64 evaluate tasks
this best socre: -210.25; best score: -210.25; global score: -210.25; space size: 531441; measure cnt: 256

launch 64 evaluate tasks
current thread_i 7
this best socre: -210.25; best score: -210.25; global score: -210.25; space size: 531441; measure cnt: 320

launch 64 evaluate tasks
this best socre: -210.0; best score: -210.0; global score: -210.0; space size: 531441; measure cnt: 384

launch 64 evaluate tasks
this best socre: -210.0; best score: -210.0; global score: -210.0; space size: 531441; measure cnt: 448

launch 64 evaluate tasks
this best socre: -210.0; best score: -210.0; global score: -210.0; space size: 531441; measure cnt: 512

launch 64 evaluate tasks
current thread_i 9
this best socre: -210.0; best score: -210.0; global score: -210.0; space size: 531441; measure cnt: 576
sampler suggest should end sample, break
INFO:absl:Best score increased to -210.0
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-tunable([10, 15, 20]) * (fit_ratio - tunable([0.5, 0.6, 0.7]))))

        # Future potential component: Balance remaining space for future items
        ideal_remaining = tunable([0.1, 0.2, 0.3]) * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - tunable([0.1, 0.2, 0.3]) * item
        future_potential_weight = tunable([0.4, 0.5, 0.6])
        future_potential = 1 / (1 + np.exp(-tunable([10, 15, 20]) * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization penalty: Discourage creating too many bins
        num_bins_penalty = tunable([0.05, 0.1, 0.15]) * len(bins)

        # Bin similarity component: Prefer bins with similar remaining capacities
        similarity_weight = tunable([0.1, 0.2, 0.3])
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-tunable([5, 10, 15]) * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component: Encourage diversity in remaining capacities
        diversity_weight = tunable([0.1, 0.2, 0.3])
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-tunable([5, 10, 15]) * (1 - np.var(scaled_remaining))))

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 19
-------------------



launch 64 evaluate tasks
this best socre: -209.8; best score: -209.8; global score: -209.8; space size: 531441; measure cnt: 64
..................................................................
launch 64 evaluate tasks
current thread_i 1
current thread_i 0
this best socre: -209.8; best score: -209.8; global score: -209.8; space size: 531441; measure cnt: 128
..................................................................................................................................
launch 64 evaluate tasks
this best socre: -209.8; best score: -209.8; global score: -209.8; space size: 531441; measure cnt: 192
.........................................................................................................................
launch 64 evaluate tasks
current thread_i 2
this best socre: -209.8; best score: -209.8; global score: -209.8; space size: 531441; measure cnt: 256
sampler suggest should end sample, break
INFO:absl:Best score increased to -209.8
-------------------
    """Advanced priority function for online bin-packing that considers:
    
    1. Spatial fit: How well the item fits into the bin
    2. Future potential: How the choice affects future packing efficiency
    3. Bin similarity: How well the bin matches the expected distribution
    4. Diversity: Encourages balanced bin usage
    
    Returns priority scores where higher values indicate better candidates for packing.
    """
    if len(bins) == 0:
        return np.array([])
        
    # Calculate remaining capacity if item is placed in each bin
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0
    
    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)  # Avoid division by zero
        spatial_fit = 1 / (1 + np.exp(-tunable([5, 10]) * (fit_ratio - tunable([0.3, 0.5]))))
        
        # Future potential component
        ideal_remaining = tunable([0.1, 0.2]) * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - tunable([0.1, 0.2]) * item
        future_potential = 1 / (1 + np.exp(-tunable([5, 10]) * ((remaining_after - ideal_remaining) / bins[valid_bins])))
        
        # Bin similarity component
        avg_bin_load = np.mean(bins - remaining_capacity)
        similarity_score = np.exp(-tunable([0.5, 1.0]) * np.abs(fit_ratio - avg_bin_load / bins[valid_bins]))
        
        # Diversity component
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity_score = 1 / (1 + np.exp(-tunable([5, 10]) * (1 - np.var(remaining_scaled))))
        
        # Dynamic weight adjustment based on item size
        weight_spatial = tunable([0.6, 0.7]) if item > tunable([0.5, 0.7]) * np.max(bins) else tunable([0.4, 0.5])
        weight_future = tunable([0.3, 0.4])
        weight_similarity = tunable([0.1, 0.2])
        weight_diversity = tunable([0.2, 0.3])
        
        # Calculate total priority with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity_score +
            weight_diversity * diversity_score -
            tunable([0.05, 0.1]) * len(bins)
        )
        
        priorities[valid_bins] = total_priority
    
    return priorities

call llm times: 20
-------------------



launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -209.8; space size: 16384; measure cnt: 64

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -209.8; space size: 16384; measure cnt: 128
.
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -209.8; space size: 16384; measure cnt: 192
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: How well the item fits into the bin
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-tunable([10, 15]) * (fit_ratio - tunable([0.6, 0.7]))))

        # Future potential component: Likelihood of fitting future items
        future_item_estimate = tunable([0.8, 1.2]) * item  # Heuristic based on current item size
        ideal_remaining = tunable([0.1, 0.2]) * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - tunable([0.1, 0.2]) * item
        future_potential = 1 / (1 + np.exp(-tunable([10, 15]) * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin utilization history component: Bins that have been consistently filled well
        utilization_history = bins[valid_bins] - remaining_capacity[valid_bins]
        utilization_score = utilization_history / bins[valid_bins]
        utilization_score = 1 / (1 + np.exp(-tunable([5, 10]) * (utilization_score - tunable([0.7, 0.8]))))

        # Combine components with tunable weights
        weight_spatial = tunable([0.5, 0.6, 0.7])
        weight_future = tunable([0.3, 0.4])
        weight_history = tunable([0.1, 0.2])
        penalty = tunable([0.05, 0.1]) * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_history * utilization_score -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 21
-------------------



launch 64 evaluate tasks
current thread_i 6
current thread_i 4
this best socre: -211.65; best score: -211.65; global score: -209.8; space size: 6144; measure cnt: 64
...
launch 64 evaluate tasks
current thread_i 8
this best socre: -210.45; best score: -210.45; global score: -209.8; space size: 6144; measure cnt: 128
............
launch 64 evaluate tasks
this best socre: -210.45; best score: -210.45; global score: -209.8; space size: 6144; measure cnt: 192
.......
launch 64 evaluate tasks
this best socre: -210.45; best score: -210.45; global score: -209.8; space size: 6144; measure cnt: 256
.....
launch 64 evaluate tasks
this best socre: -210.45; best score: -210.45; global score: -209.8; space size: 6144; measure cnt: 320
sampler suggest should end sample, break
-------------------
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining > 0
    
    # Spatial fit component: How well the item fits into the bin
    fill_ratio = item / (bins + 1e-6)
    space_utilization = 1 - (remaining / (bins + 1e-6))
    spatial_fit = (fill_ratio + space_utilization) / 2
    
    # Future potential component: How well the bin can accommodate future items
    ideal_remaining = tunable([0.1, 0.2])  # Ideal remaining space as a fraction of bin capacity
    remaining_scaled = remaining / np.max(bins)
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Bin similarity component: Encourage even distribution of remaining space
    avg_remaining = np.mean(remaining_scaled[valid])
    similarity_score = np.exp(-tunable([1.0, 1.5]) * np.abs(remaining_scaled - avg_remaining))
    
    # Diversity component: Penalize high variance in remaining capacities
    diversity_weight = tunable([0.1, 0.2])
    diversity_score = 1 / (1 + np.exp(-tunable([5.0, 10.0]) * (1 - np.var(remaining_scaled))))
    
    # Combine components with tunable weights
    weight_spatial = tunable([0.6, 0.7])
    weight_future = tunable([0.3, 0.4])
    weight_similarity = tunable([0.1, 0.2])
    weight_diversity = tunable([0.05, 0.1])
    
    total_priority = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_similarity * similarity_score +
        weight_diversity * diversity_score
    )
    
    # Penalize bins that are too full or too empty
    fullness_penalty = tunable([0.1, 0.2]) * np.exp(-tunable([1.0, 2.0]) * np.abs(fill_ratio - 0.5))
    total_priority += fullness_penalty
    
    # Ensure invalid bins have the lowest priority
    total_priority[~valid] = -np.inf
    
    return total_priority

call llm times: 22
-------------------


..
launch 64 evaluate tasks
this best socre: -211.8; best score: -211.8; global score: -209.8; space size: 1024; measure cnt: 64
.......
launch 64 evaluate tasks
current thread_i 5
this best socre: -211.5; best score: -211.5; global score: -209.8; space size: 1024; measure cnt: 128
..................
launch 64 evaluate tasks
this best socre: -211.5; best score: -211.5; global score: -209.8; space size: 1024; measure cnt: 192
....................
launch 64 evaluate tasks
this best socre: -211.5; best score: -211.5; global score: -209.8; space size: 1024; measure cnt: 256
................................
launch 64 evaluate tasks
this best socre: -211.5; best score: -211.5; global score: -209.8; space size: 1024; measure cnt: 320
sampler suggest should end sample, break
-------------------
    """Improved priority function considering spatial fit, future potential, bin similarity, diversity, and fragmentation."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fill_ratio = item / (bins[valid_bins] + 1e-6)
        ideal_fill = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-10 * (fill_ratio - ideal_fill)))

        # Future potential component
        ideal_remaining = tunable([0.1, 0.2, 0.3]) * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (using average bin load as a proxy)
        avg_load = bins - remaining_capacity
        similarity = np.exp(-tunable([0.5, 1.0, 1.5]) * np.abs(fill_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Diversity component
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-tunable([5, 10, 15]) * (1 - np.var(remaining_scaled))))

        # Fragmentation penalty
        fragmentation = tunable([0.1, 0.2, 0.3]) * np.exp(-tunable([1.0, 2.0, 3.0]) * remaining_after / bins[valid_bins])
        penalty = tunable([0.05, 0.1, 0.15]) * len(bins)

        # Combine components with tunable weights
        weight_spatial = tunable([0.5, 0.6, 0.7])
        weight_future = tunable([0.3, 0.4, 0.5])
        weight_similarity = tunable([0.2, 0.3, 0.4])
        weight_diversity = tunable([0.1, 0.2, 0.3])

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            fragmentation -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 23
-------------------



launch 64 evaluate tasks
this best socre: -211.6; best score: -211.6; global score: -209.8; space size: 177147; measure cnt: 64

launch 64 evaluate tasks
this best socre: -211.6; best score: -211.6; global score: -209.8; space size: 177147; measure cnt: 128

launch 64 evaluate tasks
this best socre: -211.6; best score: -211.6; global score: -209.8; space size: 177147; measure cnt: 192

launch 64 evaluate tasks
this best socre: -211.6; best score: -211.6; global score: -209.8; space size: 177147; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf

    if np.any(valid):
        # Spatial fit component
        fit_ratio = item / (bins[valid] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-tunable([10, 15]) * (fit_ratio - tunable([0.6, 0.7]))))

        # Future potential component
        avg_remaining = np.mean(remaining[valid])
        ideal_remaining = tunable([0.2, 0.3]) * bins[valid]
        future_potential = 1 / (1 + np.exp(-tunable([10, 15]) * ((remaining[valid] - ideal_remaining) / bins[valid])))

        # Bin similarity component
        avg_load = np.mean(bins - remaining)
        similarity = np.exp(-tunable([1.0, 1.5]) * np.abs(fit_ratio - avg_load / bins[valid]))

        # Diversity component
        remaining_scaled = remaining[valid] / np.max(bins)
        diversity = 1 / (1 + np.exp(-tunable([5, 10]) * (1 - np.var(remaining_scaled))))

        # Dynamic weights based on current bin state
        weight_spatial = tunable([0.6, 0.7])
        weight_future = tunable([0.3, 0.4])
        weight_similarity = tunable([0.1, 0.2])
        weight_diversity = tunable([0.2, 0.3])

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity
        )

        # Penalty for bins that are too full or too empty
        fullness_penalty = tunable([0.1, 0.2]) * np.exp(-tunable([1.0, 1.5]) * np.abs(fit_ratio - 0.5))
        total_priority += fullness_penalty

        priorities[valid] = total_priority

    return priorities

call llm times: 24
-------------------


...
launch 64 evaluate tasks
this best socre: -210.55; best score: -210.55; global score: -209.8; space size: 4096; measure cnt: 64
...........
launch 64 evaluate tasks
this best socre: -210.55; best score: -210.55; global score: -209.8; space size: 4096; measure cnt: 128
..................
launch 64 evaluate tasks
this best socre: -210.55; best score: -210.55; global score: -209.8; space size: 4096; measure cnt: 192
......................
launch 64 evaluate tasks
this best socre: -210.55; best score: -210.55; global score: -209.8; space size: 4096; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Improved priority function for online bin-packing considering spatial fit, future potential, bin similarity, and dynamic load balancing."""
    remaining = bins - item
    valid = remaining >= 0
    
    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf
    
    if np.any(valid):
        # Spatial fit component
        fill_ratio = item / (bins[valid] + 1e-6)
        space_utilization = 1 - (remaining[valid] / (bins[valid] + 1e-6))
        spatial_fit = (fill_ratio + space_utilization) / 2
        
        # Future potential component
        ideal_remaining = tunable([0.1, 0.2]) * bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining[valid] - ideal_remaining) / bins[valid])))
        
        # Bin similarity component
        avg_remaining = np.mean(remaining[valid])
        similarity_score = np.exp(-1.0 * np.abs(remaining[valid] - avg_remaining) / (np.max(bins) + 1e-6))
        
        # Diversity score component
        diversity_weight = tunable([0.1, 0.2])
        diversity_score = 1 / (1 + np.exp(-1.5 * (len(bins) - np.count_nonzero(valid))))
        
        # Dynamic load balancing component
        current_loads = bins - remaining
        avg_load = np.mean(current_loads)
        load_diff = np.abs(current_loads[valid] - avg_load)
        load_balance = 1 / (1 + np.exp(-5 * (avg_load - load_diff)))
        
        # Combine components with tunable weights
        weight_spatial = tunable([0.6, 0.7])
        weight_future = tunable([0.3, 0.4])
        weight_similarity = tunable([0.1, 0.2])
        weight_diversity = tunable([0.1, 0.15])
        weight_balance = tunable([0.1, 0.2])
        
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity_score +
            weight_diversity * diversity_score +
            weight_balance * load_balance
        )
        
        # Apply penalties for bins that are too full or too empty
        fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
        total_priority += fullness_penalty
        
        priorities[valid] = total_priority
    
    return priorities

call llm times: 25
-------------------


.................
launch 64 evaluate tasks
this best socre: -216.6; best score: -216.6; global score: -209.8; space size: 128; measure cnt: 64
..............................................................................................................................................................................................................................................................................
launch 60 evaluate tasks
this best socre: -216.6; best score: -216.6; global score: -209.8; space size: 128; measure cnt: 124
....................................................................................................................
launch 2 evaluate tasks
this best socre: -216.6; best score: -216.6; global score: -209.8; space size: 128; measure cnt: 126
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -216.6; global score: -209.8; space size: 128; measure cnt: 126
sampler suggest should end sample, break
-------------------
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining >= 0
    
    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf

    if np.any(valid):
        # Spatial fit component
        fill_ratio = item / (bins[valid] + 1e-6)
        space_utilization = 1 - (remaining[valid] / (bins[valid] + 1e-6))
        
        # Introduce balance term to prefer moderate fill ratios
        balance = np.exp(-5 * (fill_ratio - 0.5)**2)
        
        spatial_fit = (
            tunable([0.5, 0.6, 0.7]) * fill_ratio +
            tunable([0.3, 0.4, 0.5]) * space_utilization +
            tunable([0.1, 0.2, 0.3]) * balance
        )
        
        # Future potential component
        ideal_remaining = tunable([0.1, 0.2, 0.3]) * bins[valid]
        remaining_scaled = (remaining[valid] - ideal_remaining) / bins[valid]
        
        future_potential = 1 / (1 + np.exp(-tunable([10, 15, 20]) * remaining_scaled))
        
        # Bin similarity component
        avg_load = np.mean(bins - remaining)
        similarity = np.exp(-tunable([1.0, 1.5, 2.0]) * 
                           np.abs(bins[valid] - avg_load) / (np.max(bins) + 1e-6))
        
        # Diversity component
        remaining_all = bins - item
        remaining_all[~valid] = bins[~valid]
        diversity = 1 / (1 + np.exp(-tunable([5, 10, 15]) * 
                                    (1 - np.var(remaining_all / np.max(bins)))))
        
        # Combine components with tunable weights
        weight_spatial = tunable([0.6, 0.7, 0.8])
        weight_future = tunable([0.2, 0.3, 0.4])
        weight_similarity = tunable([0.1, 0.15, 0.2])
        weight_diversity = tunable([0.05, 0.1, 0.15])
        
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity
        )
        
        # Apply penalties for bins that are too full or too empty
        fullness_penalty = tunable([0.1, 0.15, 0.2]) * np.exp(
            -tunable([1.0, 1.5, 2.0]) * np.abs(fill_ratio - 0.5)
        )
        total_priority += fullness_penalty
        
        priorities[valid] = total_priority

    return priorities

call llm times: 26
-------------------



launch 64 evaluate tasks
this best socre: -211.35; best score: -211.35; global score: -209.8; space size: 1594323; measure cnt: 64

launch 64 evaluate tasks
this best socre: -211.35; best score: -211.35; global score: -209.8; space size: 1594323; measure cnt: 128

launch 64 evaluate tasks
this best socre: -211.35; best score: -211.35; global score: -209.8; space size: 1594323; measure cnt: 192

launch 64 evaluate tasks
current thread_i 3
errrrrrr launch_llm Can not find core code.
this best socre: -211.35; best score: -211.35; global score: -209.8; space size: 1594323; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Improved priority function with dynamic weights and adaptive parameters."""
    remaining = bins - item
    valid = remaining >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf

    if np.any(valid):
        # Spatial fit component
        fit_ratio = item / (bins[valid] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - tunable([0.6, 0.7, 0.8]))))

        # Future potential component
        avg_remaining = np.mean(remaining[valid])
        ideal_remaining = tunable([0.1, 0.2]) * bins[valid]  # Adaptive ideal remaining space
        remaining_scaled = (remaining[valid] - ideal_remaining) / bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - tunable([-0.2, 0.0, 0.2]))))

        # Bin similarity component
        avg_load = np.mean(bins[valid] - remaining[valid])
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load / bins[valid]))

        # Diversity component
        remaining_scaled_div = remaining[valid] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled_div))))

        # Dynamic weights based on current state
        avg_fill = np.mean((bins[valid] - remaining[valid]) / bins[valid])
        weight_spatial = tunable([0.6, 0.7]) * (1 - avg_fill)
        weight_future = tunable([0.3, 0.4]) * avg_fill
        weight_similarity = tunable([0.1, 0.2])
        weight_diversity = tunable([0.2, 0.3])

        # Penalty for imbalanced bins
        max_rem = np.max(remaining[valid])
        min_rem = np.min(remaining[valid])
        imbalance_penalty = tunable([0.05, 0.1]) * (max_rem - min_rem) / np.mean(bins)

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            imbalance_penalty
        )

        priorities[valid] = total_priority

    return priorities

call llm times: 27
-------------------


...
launch 64 evaluate tasks
this best socre: -211.85; best score: -211.85; global score: -209.8; space size: 576; measure cnt: 64
..........
launch 64 evaluate tasks
this best socre: -211.85; best score: -211.85; global score: -209.8; space size: 576; measure cnt: 128
.....................
launch 64 evaluate tasks
this best socre: -211.85; best score: -211.85; global score: -209.8; space size: 576; measure cnt: 192
................................
launch 64 evaluate tasks
this best socre: -211.85; best score: -211.85; global score: -209.8; space size: 576; measure cnt: 256
sampler suggest should end sample, break
request...
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, and bin utilization."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    fit_ratio = item / (bins + 1e-8)  # Avoid division by zero
    spatial_fit[valid_bins] = 1.0 / (1.0 + np.exp(-(fit_ratio[valid_bins] - 0.5) * 10))

    # Future potential component: Reward bins with remaining space close to ideal
    ideal_remaining = 0.3 * bins  # Ideal remaining space as a fraction of bin capacity
    remaining_scaled = remaining_capacity / (np.max(bins) + 1e-8)  # Normalize by max bin capacity
    future_potential = np.zeros_like(bins, dtype=np.float64)
    future_potential[valid_bins] = np.exp(-(remaining_scaled[valid_bins] - ideal_remaining[valid_bins]) ** 2 /
                                         (2 * (0.1 ** 2)))

    # Bin utilization bonus: Reward bins that are neither too empty nor too full
    utilization = 1.0 - remaining_scaled
    utilization_bonus = np.exp(-(utilization - 0.9) ** 2 /
                               (2 * (0.1 ** 2)))

    # Penalty for too much or too little remaining space
    space_penalty = np.exp(-(np.abs(remaining_scaled - 0.3) - 0.15) ** 2 /
                           (2 * (0.1 ** 2)))
    space_penalty[valid_bins] = 1.0 - space_penalty[valid_bins]

    # Combine components with tunable weights
    weight_spatial = 0.5
    weight_future = 0.3
    weight_utilization = 0.4
    weight_penalty = 0.3

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus +
        weight_penalty * space_penalty
    )

    # Ensure invalid bins have zero priority
    priorities[~valid_bins] = 0.0

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.6
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Balance remaining space for future items
        ideal_remaining = 0.3 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization penalty: Discourage creating too many bins
        num_bins_penalty = 0.15 * len(bins)

        # Bin similarity component: Prefer bins with similar remaining capacities
        similarity_weight = 0.2
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-15 * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component: Encourage diversity in remaining capacities
        diversity_weight = 0.2
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
-----------------------


import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, and bin utilization."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    fit_ratio = item / (bins + 1e-8)  # Avoid division by zero
    spatial_fit[valid_bins] = 1.0 / (1.0 + np.exp(-(fit_ratio[valid_bins] - 0.5) * 10))

    # Future potential component: Reward bins with remaining space close to ideal
    ideal_remaining = 0.3 * bins  # Ideal remaining space as a fraction of bin capacity
    remaining_scaled = remaining_capacity / (np.max(bins) + 1e-8)  # Normalize by max bin capacity
    future_potential = np.zeros_like(bins, dtype=np.float64)
    future_potential[valid_bins] = np.exp(-(remaining_scaled[valid_bins] - ideal_remaining[valid_bins]) ** 2 /
                                         (2 * (0.1 ** 2)))

    # Bin utilization bonus: Reward bins that are neither too empty nor too full
    utilization = 1.0 - remaining_scaled
    utilization_bonus = np.exp(-(utilization - 0.9) ** 2 /
                               (2 * (0.1 ** 2)))

    # Penalty for too much or too little remaining space
    space_penalty = np.exp(-(np.abs(remaining_scaled - 0.3) - 0.15) ** 2 /
                           (2 * (0.1 ** 2)))
    space_penalty[valid_bins] = 1.0 - space_penalty[valid_bins]

    # Combine components with tunable weights
    weight_spatial = 0.5
    weight_future = 0.3
    weight_utilization = 0.4
    weight_penalty = 0.3

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus +
        weight_penalty * space_penalty
    )

    # Ensure invalid bins have zero priority
    priorities[~valid_bins] = 0.0

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.6
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Balance remaining space for future items
        ideal_remaining = 0.3 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization penalty: Discourage creating too many bins
        num_bins_penalty = 0.15 * len(bins)

        # Bin similarity component: Prefer bins with similar remaining capacities
        similarity_weight = 0.2
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-15 * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component: Encourage diversity in remaining capacities
        diversity_weight = 0.2
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
-----------------------

-----------------------
request...
-----------------------request...

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, and bin utilization."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    fit_ratio = item / (bins + 1e-8)  # Avoid division by zero
    spatial_fit[valid_bins] = 1.0 / (1.0 + np.exp(-(fit_ratio[valid_bins] - 0.5) * 10))

    # Future potential component: Reward bins with remaining space close to ideal
    ideal_remaining = 0.3 * bins  # Ideal remaining space as a fraction of bin capacity
    remaining_scaled = remaining_capacity / (np.max(bins) + 1e-8)  # Normalize by max bin capacity
    future_potential = np.zeros_like(bins, dtype=np.float64)
    future_potential[valid_bins] = np.exp(-(remaining_scaled[valid_bins] - ideal_remaining[valid_bins]) ** 2 /
                                         (2 * (0.1 ** 2)))

    # Bin utilization bonus: Reward bins that are neither too empty nor too full
    utilization = 1.0 - remaining_scaled
    utilization_bonus = np.exp(-(utilization - 0.9) ** 2 /
                               (2 * (0.1 ** 2)))

    # Penalty for too much or too little remaining space
    space_penalty = np.exp(-(np.abs(remaining_scaled - 0.3) - 0.15) ** 2 /
                           (2 * (0.1 ** 2)))
    space_penalty[valid_bins] = 1.0 - space_penalty[valid_bins]

    # Combine components with tunable weights
    weight_spatial = 0.5
    weight_future = 0.3
    weight_utilization = 0.4
    weight_penalty = 0.3

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus +
        weight_penalty * space_penalty
    )

    # Ensure invalid bins have zero priority
    priorities[~valid_bins] = 0.0

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.6
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Balance remaining space for future items
        ideal_remaining = 0.3 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization penalty: Discourage creating too many bins
        num_bins_penalty = 0.15 * len(bins)

        # Bin similarity component: Prefer bins with similar remaining capacities
        similarity_weight = 0.2
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-15 * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component: Encourage diversity in remaining capacities
        diversity_weight = 0.2
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, and bin utilization."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    fit_ratio = item / (bins + 1e-8)  # Avoid division by zero
    spatial_fit[valid_bins] = 1.0 / (1.0 + np.exp(-(fit_ratio[valid_bins] - 0.5) * 10))

    # Future potential component: Reward bins with remaining space close to ideal
    ideal_remaining = 0.3 * bins  # Ideal remaining space as a fraction of bin capacity
    remaining_scaled = remaining_capacity / (np.max(bins) + 1e-8)  # Normalize by max bin capacity
    future_potential = np.zeros_like(bins, dtype=np.float64)
    future_potential[valid_bins] = np.exp(-(remaining_scaled[valid_bins] - ideal_remaining[valid_bins]) ** 2 /
                                         (2 * (0.1 ** 2)))

    # Bin utilization bonus: Reward bins that are neither too empty nor too full
    utilization = 1.0 - remaining_scaled
    utilization_bonus = np.exp(-(utilization - 0.9) ** 2 /
                               (2 * (0.1 ** 2)))

    # Penalty for too much or too little remaining space
    space_penalty = np.exp(-(np.abs(remaining_scaled - 0.3) - 0.15) ** 2 /
                           (2 * (0.1 ** 2)))
    space_penalty[valid_bins] = 1.0 - space_penalty[valid_bins]

    # Combine components with tunable weights
    weight_spatial = 0.5
    weight_future = 0.3
    weight_utilization = 0.4
    weight_penalty = 0.3

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus +
        weight_penalty * space_penalty
    )

    # Ensure invalid bins have zero priority
    priorities[~valid_bins] = 0.0

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.6
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Balance remaining space for future items
        ideal_remaining = 0.3 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization penalty: Discourage creating too many bins
        num_bins_penalty = 0.15 * len(bins)

        # Bin similarity component: Prefer bins with similar remaining capacities
        similarity_weight = 0.2
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-15 * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component: Encourage diversity in remaining capacities
        diversity_weight = 0.2
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
-----------------------


import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, and bin utilization."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    fit_ratio = item / (bins + 1e-8)  # Avoid division by zero
    spatial_fit[valid_bins] = 1.0 / (1.0 + np.exp(-(fit_ratio[valid_bins] - 0.5) * 10))

    # Future potential component: Reward bins with remaining space close to ideal
    ideal_remaining = 0.3 * bins  # Ideal remaining space as a fraction of bin capacity
    remaining_scaled = remaining_capacity / (np.max(bins) + 1e-8)  # Normalize by max bin capacity
    future_potential = np.zeros_like(bins, dtype=np.float64)
    future_potential[valid_bins] = np.exp(-(remaining_scaled[valid_bins] - ideal_remaining[valid_bins]) ** 2 /
                                         (2 * (0.1 ** 2)))

    # Bin utilization bonus: Reward bins that are neither too empty nor too full
    utilization = 1.0 - remaining_scaled
    utilization_bonus = np.exp(-(utilization - 0.9) ** 2 /
                               (2 * (0.1 ** 2)))

    # Penalty for too much or too little remaining space
    space_penalty = np.exp(-(np.abs(remaining_scaled - 0.3) - 0.15) ** 2 /
                           (2 * (0.1 ** 2)))
    space_penalty[valid_bins] = 1.0 - space_penalty[valid_bins]

    # Combine components with tunable weights
    weight_spatial = 0.5
    weight_future = 0.3
    weight_utilization = 0.4
    weight_penalty = 0.3

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus +
        weight_penalty * space_penalty
    )

    # Ensure invalid bins have zero priority
    priorities[~valid_bins] = 0.0

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.6
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Balance remaining space for future items
        ideal_remaining = 0.3 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization penalty: Discourage creating too many bins
        num_bins_penalty = 0.15 * len(bins)

        # Bin similarity component: Prefer bins with similar remaining capacities
        similarity_weight = 0.2
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-15 * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component: Encourage diversity in remaining capacities
        diversity_weight = 0.2
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf

    if np.any(valid):
        # Spatial fit component
        fit_ratio = item / (bins[valid] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        avg_remaining = np.mean(remaining[valid])
        ideal_remaining = 0.2 * bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining[valid] - ideal_remaining) / bins[valid])))

        # Bin similarity component
        avg_load = np.mean(bins - remaining)
        similarity = np.exp(-1.5 * np.abs(fit_ratio - avg_load / bins[valid]))

        # Diversity component
        remaining_scaled = remaining[valid] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Dynamic weights based on current bin state
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.2
        weight_diversity = 0.3

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity
        )

        # Penalty for bins that are too full or too empty
        fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fit_ratio - 0.5))
        total_priority += fullness_penalty

        priorities[valid] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.6
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Balance remaining space for future items
        ideal_remaining = 0.3 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization penalty: Discourage creating too many bins
        num_bins_penalty = 0.15 * len(bins)

        # Bin similarity component: Prefer bins with similar remaining capacities
        similarity_weight = 0.2
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-15 * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component: Encourage diversity in remaining capacities
        diversity_weight = 0.2
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: How well the item fits into the bin
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Likelihood of fitting future items
        future_item_estimate = 0.8 * item  # Heuristic based on current item size
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.1 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin utilization history component: Bins that have been consistently filled well
        utilization_history = bins[valid_bins] - remaining_capacity[valid_bins]
        utilization_score = utilization_history / bins[valid_bins]
        utilization_score = 1 / (1 + np.exp(-10 * (utilization_score - 0.8)))

        # Combine components with tunable weights
        weight_spatial = 0.7
        weight_future = 0.4
        weight_history = 0.2
        penalty = 0.1 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_history * utilization_score -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.6
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Balance remaining space for future items
        ideal_remaining = 0.3 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization penalty: Discourage creating too many bins
        num_bins_penalty = 0.15 * len(bins)

        # Bin similarity component: Prefer bins with similar remaining capacities
        similarity_weight = 0.2
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-15 * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component: Encourage diversity in remaining capacities
        diversity_weight = 0.2
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------
request...
import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: How well the item fits into the bin
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Likelihood of fitting future items
        future_item_estimate = 0.8 * item  # Heuristic based on current item size
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.1 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin utilization history component: Bins that have been consistently filled well
        utilization_history = bins[valid_bins] - remaining_capacity[valid_bins]
        utilization_score = utilization_history / bins[valid_bins]
        utilization_score = 1 / (1 + np.exp(-10 * (utilization_score - 0.8)))

        # Combine components with tunable weights
        weight_spatial = 0.7
        weight_future = 0.4
        weight_history = 0.2
        penalty = 0.1 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_history * utilization_score -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.6
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Balance remaining space for future items
        ideal_remaining = 0.3 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization penalty: Discourage creating too many bins
        num_bins_penalty = 0.15 * len(bins)

        # Bin similarity component: Prefer bins with similar remaining capacities
        similarity_weight = 0.2
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-15 * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component: Encourage diversity in remaining capacities
        diversity_weight = 0.2
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.


-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: How well the item fits into the bin
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Likelihood of fitting future items
        future_item_estimate = 0.8 * item  # Heuristic based on current item size
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.1 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin utilization history component: Bins that have been consistently filled well
        utilization_history = bins[valid_bins] - remaining_capacity[valid_bins]
        utilization_score = utilization_history / bins[valid_bins]
        utilization_score = 1 / (1 + np.exp(-10 * (utilization_score - 0.8)))

        # Combine components with tunable weights
        weight_spatial = 0.7
        weight_future = 0.4
        weight_history = 0.2
        penalty = 0.1 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_history * utilization_score -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.6
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Balance remaining space for future items
        ideal_remaining = 0.3 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization penalty: Discourage creating too many bins
        num_bins_penalty = 0.15 * len(bins)

        # Bin similarity component: Prefer bins with similar remaining capacities
        similarity_weight = 0.2
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-15 * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component: Encourage diversity in remaining capacities
        diversity_weight = 0.2
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
-----------------------

-----------------------
-------------------
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - tunable([0.5, 0.6, 0.7]))))

        # Future potential component
        future_item_estimate = tunable([0.7, 0.8, 0.9]) * item  # Heuristic based on current item size
        ideal_remaining = tunable([0.2, 0.3, 0.4]) * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - tunable([0.1, 0.2]) * item
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization history component
        utilization_history = bins[valid_bins] - remaining_capacity[valid_bins]
        utilization_score = utilization_history / bins[valid_bins]
        utilization_score = 1 / (1 + np.exp(-10 * (utilization_score - tunable([0.7, 0.8, 0.9]))))

        # Bin similarity component
        similarity_weight = tunable([0.2, 0.3])
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-15 * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component
        diversity_weight = tunable([0.2, 0.3])
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            tunable([0.1, 0.2]) * utilization_score -
            similarity_weight * similarity -
            diversity_weight * diversity -
            tunable([0.1, 0.15]) * len(bins)
        )

        # Optional: Normalize priorities to a 0-1 scale
        if np.any(total_priority):
            total_priority = (total_priority - np.min(total_priority)) / (np.max(total_priority) - np.min(total_priority) + 1e-6)

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 28
-------------------



current thread_i 6
launch 64 evaluate tasks
current thread_i 4
this best socre: -211.85; best score: -211.85; global score: -209.8; space size: 23328; measure cnt: 64
.....
launch 64 evaluate tasks
current thread_i 2
current thread_i 7
this best socre: -211.85; best score: -211.85; global score: -209.8; space size: 23328; measure cnt: 128
..........
current thread_i 1
launch 64 evaluate tasks
current thread_i 5
current thread_i 0
this best socre: -211.85; best score: -211.85; global score: -209.8; space size: 23328; measure cnt: 192
...
launch 64 evaluate tasks
current thread_i 8
this best socre: -211.85; best score: -211.85; global score: -209.8; space size: 23328; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with hybrid strategies"""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        
        # Temporal fit component (future potential)
        ideal_remaining = tunable([0.2, 0.3, 0.4]) * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - tunable([0.1, 0.15]) * item
        
        # Hybrid spatial-temporal score
        spatial_temporal_score = (
            1 / (1 + np.exp(-tunable([10, 15, 20]) * (fit_ratio - tunable([0.5, 0.6, 0.7])))) +
            1 / (1 + np.exp(-tunable([10, 15, 20]) * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))
        )
        
        # Bin diversity component
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity_score = 1 / (1 + np.exp(-tunable([10, 15, 20]) * (1 - np.var(scaled_remaining))))
        
        # Combine components with tunable weights
        total_priority = (
            tunable([0.4, 0.5, 0.6]) * spatial_temporal_score +
            tunable([0.3, 0.4, 0.5]) * diversity_score -
            tunable([0.1, 0.15, 0.2]) * len(bins)
        )
        
        # Normalize priorities
        total_priority = total_priority / (tunable([0.4, 0.5, 0.6]) + tunable([0.3, 0.4, 0.5]) + tunable([0.1, 0.15, 0.2]))
        
        priorities[valid_bins] = total_priority

    return priorities

call llm times: 29
-------------------



launch 64 evaluate tasks
this best socre: -217.5; best score: -217.5; global score: -209.8; space size: 354294; measure cnt: 64

launch 64 evaluate tasks
this best socre: -217.5; best score: -217.5; global score: -209.8; space size: 354294; measure cnt: 128

launch 64 evaluate tasks
this best socre: -217.5; best score: -217.5; global score: -209.8; space size: 354294; measure cnt: 192

launch 64 evaluate tasks
this best socre: -217.5; best score: -217.5; global score: -209.8; space size: 354294; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with adaptive strategies."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_weight_base = tunable([0.6, 0.7, 0.8])
        spatial_slope = tunable([15, 20, 25])
        spatial_midpoint = tunable([0.5, 0.6, 0.7])
        spatial_fit = 1 / (1 + np.exp(-spatial_slope * (fit_ratio - spatial_midpoint)))
        spatial_weight = spatial_weight_base * (1 + np.exp(-10 * np.abs(fit_ratio - 0.5)))

        # Future potential component
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        ideal_remaining = tunable([0.2, 0.3, 0.4]) * bins[valid_bins]
        future_slope = tunable([10, 15, 20])
        future_potential = 1 / (1 + np.exp(-future_slope * ((remaining_capacity[valid_bins] - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Dynamic weight adjustment based on system state
        system_load = np.mean(bins)
        if system_load > tunable([0.7, 0.8]):
            future_weight = tunable([0.5, 0.6, 0.7])
        else:
            future_weight = tunable([0.3, 0.4, 0.5])
        
        # Bin similarity component
        similarity_weight = tunable([0.1, 0.2, 0.3])
        similarity_slope = tunable([10, 15, 20])
        similarity = 1 / (1 + np.exp(-similarity_slope * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component
        diversity_weight = tunable([0.1, 0.2, 0.3])
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components with dynamic weights
        total_priority = (
            spatial_weight * spatial_fit +
            future_weight * future_potential -
            similarity_weight * similarity -
            diversity_weight * diversity
        )

        # Apply normalization if needed
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 30
-------------------



launch 64 evaluate tasks
this best socre: -211.75; best score: -211.75; global score: -209.8; space size: 118098; measure cnt: 64
...............................................................................................................................................
launch 5 evaluate tasks
this best socre: -211.75; best score: -211.75; global score: -209.8; space size: 118098; measure cnt: 69
.........................................................................
launch 1 evaluate tasks
this best socre: -211.75; best score: -211.75; global score: -209.8; space size: 118098; measure cnt: 70
..................................................................................................................................................................
launch 7 evaluate tasks
this best socre: -211.75; best score: -211.75; global score: -209.8; space size: 118098; measure cnt: 77
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-tunable([15, 20, 25]) * (fit_ratio - tunable([0.5, 0.6, 0.7]))))

        # Future potential component: Balance remaining space for future items
        ideal_remaining_ratio = tunable([0.3, 0.4, 0.5])
        ideal_remaining = ideal_remaining_ratio * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - tunable([0.1, 0.2, 0.3]) * item
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-tunable([10, 15, 20]) * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization history component: Reward bins with higher utilization
        utilization_history = bins[valid_bins] - remaining_capacity[valid_bins]
        utilization_score_weight = tunable([0.2, 0.3, 0.4])
        utilization_score = utilization_history / bins[valid_bins]
        utilization_score = 1 / (1 + np.exp(-tunable([10, 15, 20]) * (utilization_score - tunable([0.7, 0.8, 0.9]))))

        # Bin similarity and diversity component
        similarity_weight = tunable([0.15, 0.2, 0.25])
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        std_remaining = np.std(remaining_capacity[valid_bins])
        normalized_remaining = (remaining_capacity[valid_bins] - avg_remaining) / (std_remaining + 1e-6)
        similarity = 1 / (1 + np.exp(-tunable([15, 20, 25]) * np.abs(normalized_remaining)))

        diversity_weight = tunable([0.15, 0.2, 0.25])
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-tunable([10, 15, 20]) * (1 - np.var(scaled_remaining))))

        # Penalty for number of bins
        num_bins_penalty = tunable([0.1, 0.15, 0.2]) * len(bins)

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_score_weight * utilization_score -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities to a reasonable range
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + utilization_score_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 31
-------------------



launch 64 evaluate tasks
this best socre: -210.4; best score: -210.4; global score: -209.8; space size: 14348907; measure cnt: 64

launch 64 evaluate tasks
this best socre: -210.4; best score: -210.4; global score: -209.8; space size: 14348907; measure cnt: 128

launch 64 evaluate tasks
current thread_i 9
this best socre: -210.4; best score: -210.4; global score: -209.8; space size: 14348907; measure cnt: 192

launch 64 evaluate tasks
this best socre: -210.2; best score: -210.2; global score: -209.8; space size: 14348907; measure cnt: 256

launch 64 evaluate tasks
this best socre: -210.2; best score: -210.2; global score: -209.8; space size: 14348907; measure cnt: 320

launch 64 evaluate tasks
this best socre: -209.2; best score: -209.2; global score: -209.2; space size: 14348907; measure cnt: 384

launch 64 evaluate tasks
this best socre: -209.2; best score: -209.2; global score: -209.2; space size: 14348907; measure cnt: 448

launch 64 evaluate tasks
this best socre: -209.2; best score: -209.2; global score: -209.2; space size: 14348907; measure cnt: 512

launch 64 evaluate tasks
this best socre: -209.2; best score: -209.2; global score: -209.2; space size: 14348907; measure cnt: 576
sampler suggest should end sample, break
INFO:absl:Best score increased to -209.2
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - tunable([0.5, 0.6, 0.7]))))

        # Future potential component: Balance remaining space for future items
        ideal_remaining = tunable([0.2, 0.3, 0.4]) * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - tunable([0.1, 0.2, 0.3]) * item
        future_potential_weight = tunable([0.4, 0.5, 0.6])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization component: Reward bins that are well utilized but not too full
        utilization = 1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-6))
        utilization_weight = tunable([0.3, 0.4, 0.5])
        utilization_bonus = np.exp(-np.abs(utilization - tunable([0.7, 0.8, 0.9])) ** 2 / (2 * (tunable([0.1, 0.15, 0.2]) ** 2)))

        # Penalty for creating too many bins
        num_bins_penalty = tunable([0.1, 0.15, 0.2]) * len(bins)

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_weight * utilization_bonus -
            num_bins_penalty
        )

        # Normalize priorities to a reasonable range
        total_priority = (total_priority - np.min(total_priority)) / (np.max(total_priority) - np.min(total_priority) + 1e-8)

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 32
-------------------



launch 64 evaluate tasks
this best socre: -212.6; best score: -212.6; global score: -209.2; space size: 19683; measure cnt: 64
.
launch 64 evaluate tasks
this best socre: -212.6; best score: -212.6; global score: -209.2; space size: 19683; measure cnt: 128

launch 64 evaluate tasks
this best socre: -212.6; best score: -212.6; global score: -209.2; space size: 19683; measure cnt: 192
.
launch 64 evaluate tasks
this best socre: -212.6; best score: -212.6; global score: -209.2; space size: 19683; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Prefer bins where the item occupies a significant portion
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        spatial_fit = 1 / (1 + np.exp(-tunable([15, 20]) * (fit_ratio - tunable([0.6, 0.7]))))

        # Future potential component: Consider future item likelihood based on past statistics
        item_stats = {
            'avg': tunable([0.5, 0.6]),
            'std': tunable([0.1, 0.2]),
            'min': tunable([0.1, 0.2]),
            'max': tunable([0.9, 1.0])
        }
        remaining_scaled = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        future_likelihood = np.exp(-((remaining_scaled - item_stats['avg']) ** 2) / (2 * (item_stats['std'] ** 2)))
        future_potential_weight = tunable([0.4, 0.5])
        future_potential = future_likelihood

        # Bin similarity and diversity components
        similarity_weight = tunable([0.2, 0.3])
        diversity_weight = tunable([0.2, 0.3])
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        std_remaining = np.std(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-tunable([15, 20]) * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (std_remaining + 1e-6))))
        diversity = 1 / (1 + np.exp(-tunable([10, 15]) * (1 - np.var(remaining_scaled))))

        # Adaptive weights based on current bin state
        current_utilization = 1 - (np.mean(remaining_capacity) / (np.max(bins) + 1e-6))
        weight_spatial = spatial_fit_weight * (1 - current_utilization)
        weight_future = future_potential_weight * (1 + current_utilization)
        weight_similarity = similarity_weight * (1 + len(bins) / tunable([10, 20]))
        weight_diversity = diversity_weight * (1 + len(bins) / tunable([10, 20]))

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential -
            weight_similarity * similarity -
            weight_diversity * diversity
        )

        # Normalize priorities
        total_priority = total_priority / (weight_spatial + weight_future + weight_similarity + weight_diversity)

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 33
-------------------



launch 64 evaluate tasks
this best socre: -271.65; best score: -271.65; global score: -209.2; space size: 24576; measure cnt: 64
..................................................................................................................................................................................................................................................................................
launch 13 evaluate tasks
this best socre: -264.1; best score: -264.1; global score: -209.2; space size: 24576; measure cnt: 77
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -264.1; global score: -209.2; space size: 24576; measure cnt: 77
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -264.1; global score: -209.2; space size: 24576; measure cnt: 77
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -264.1; global score: -209.2; space size: 24576; measure cnt: 77
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.5, 0.6, 0.7])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.3, 0.4, 0.5])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.3, 0.4, 0.5])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = tunable([0.2, 0.3, 0.4])
        utilization_threshold_low = tunable([0.1, 0.2, 0.3])
        utilization_threshold_high = tunable([0.8, 0.9, 1.0])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.1, -0.2, -0.3])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.15, -0.2]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 34
-------------------



launch 64 evaluate tasks
this best socre: -208.1; best score: -208.1; global score: -208.1; space size: 59049; measure cnt: 64
...
launch 64 evaluate tasks
this best socre: -208.1; best score: -208.1; global score: -208.1; space size: 59049; measure cnt: 128
.......
launch 64 evaluate tasks
this best socre: -208.1; best score: -208.1; global score: -208.1; space size: 59049; measure cnt: 192
.....
launch 64 evaluate tasks
this best socre: -208.1; best score: -208.1; global score: -208.1; space size: 59049; measure cnt: 256
sampler suggest should end sample, break
INFO:absl:Best score increased to -208.1
-------------------
    """Advanced priority function for online bin-packing with dynamic component weighting and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        ideal_fit = tunable([0.6, 0.7])
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - ideal_fit)))

        # Future potential component: Balance remaining space for future items
        expected_avg_item = tunable([0.3, 0.4, 0.5]) * np.mean(bins)
        remaining_after = remaining_capacity[valid_bins] - tunable([0.1, 0.2]) * item
        future_potential_weight = tunable([0.4, 0.5, 0.6])
        ideal_remaining = tunable([0.2, 0.3, 0.4]) * bins[valid_bins]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization component: Reward bins that are moderately full
        utilization_weight = tunable([0.3, 0.4, 0.5])
        utilization = 1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-6))
        utilization_bonus = 1 / (1 + np.exp(-10 * (utilization - tunable([0.7, 0.8]))))

        # Bin lifespan component: Reward older bins
        lifespan_weight = tunable([0.1, 0.2, 0.3])
        # Assuming bins have a 'lifespan' attribute indicating how long they've been open
        bin_lifespans = np.array([b.lifespan for b in bins[valid_bins]])
        lifespan_bonus = 1 / (1 + np.exp(-5 * (bin_lifespans - tunable([10, 20]))))

        # Diversity component: Penalize bins with similar remaining capacities
        diversity_weight = tunable([0.1, 0.2, 0.3])
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity_penalty = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_weight * utilization_bonus +
            lifespan_weight * lifespan_bonus -
            diversity_weight * diversity_penalty
        )

        # Normalize priorities
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + utilization_weight + lifespan_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 35
-------------------



launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 34992; measure cnt: 64

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 34992; measure cnt: 128
.
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 34992; measure cnt: 192
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = tunable([0.7, 0.8, 0.9])
        spatial_fit = 1 / (1 + np.exp(-tunable([15, 20]) * (fit_ratio - tunable([0.6, 0.7]))))

        # Future potential component: Estimate based on current item and average
        future_item_estimate = tunable([item, 0.8 * item, 1.2 * item])
        remaining_after = remaining_capacity[valid_bins] - tunable([0.1, 0.2]) * item
        ideal_remaining = tunable([0.2, 0.3, 0.4]) * bins[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-tunable([10, 15]) * ((remaining_after - future_item_estimate) / (bins[valid_bins] + 1e-6))))

        # Bin utilization history component: Prefer well-utilized bins
        utilization_history = (bins[valid_bins] - remaining_capacity[valid_bins]) / bins[valid_bins]
        utilization_weight = tunable([0.2, 0.3])
        utilization_score = 1 / (1 + np.exp(-tunable([10, 15]) * (utilization_history - tunable([0.8, 0.9]))))

        # Bin similarity component: Prefer bins with similar remaining capacities
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity_weight = tunable([0.15, 0.2])
        similarity = 1 / (1 + np.exp(-tunable([15, 20]) * (1 - np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component: Encourage diverse remaining capacities
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity_weight = tunable([0.15, 0.2])
        diversity = 1 / (1 + np.exp(-tunable([10, 15]) * (1 - np.var(scaled_remaining))))

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_weight * utilization_score -
            similarity_weight * similarity -
            diversity_weight * diversity -
            tunable([0.1, 0.15, 0.2]) * len(bins)
        )

        # Normalize priorities to a 0-1 scale
        if np.any(total_priority):
            total_priority = (total_priority - np.min(total_priority)) / (np.max(total_priority) - np.min(total_priority) + 1e-6)

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 36
-------------------



launch 64 evaluate tasks
this best socre: -211.95; best score: -211.95; global score: -208.1; space size: 497664; measure cnt: 64

launch 64 evaluate tasks
this best socre: -211.45; best score: -211.45; global score: -208.1; space size: 497664; measure cnt: 128
.
launch 64 evaluate tasks
this best socre: -211.45; best score: -211.45; global score: -208.1; space size: 497664; measure cnt: 192

launch 64 evaluate tasks
this best socre: -211.45; best score: -211.45; global score: -208.1; space size: 497664; measure cnt: 256

launch 64 evaluate tasks
this best socre: -211.45; best score: -211.45; global score: -208.1; space size: 497664; measure cnt: 320
sampler suggest should end sample, break
request...request...

request...
-----------------------request...-----------------------request...

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with hybrid strategies"""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        
        # Temporal fit component (future potential)
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.15 * item
        
        # Hybrid spatial-temporal score
        spatial_temporal_score = (
            1 / (1 + np.exp(-10 * (fit_ratio - 0.5))) +
            1 / (1 + np.exp(-15 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))
        )
        
        # Bin diversity component
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity_score = 1 / (1 + np.exp(-15 * (1 - np.var(scaled_remaining))))
        
        # Combine components with tunable weights
        total_priority = (
            0.4 * spatial_temporal_score +
            0.5 * diversity_score -
            0.1 * len(bins)
        )
        
        # Normalize priorities
        total_priority = total_priority / (0.5 + 0.3 + 0.1)
        
        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.


-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.6
        spatial_fit = 1 / (1 + np.exp(-20 * (fit_ratio - 0.5)))

        # Future potential component: Balance remaining space for future items
        ideal_remaining_ratio = 0.5
        ideal_remaining = ideal_remaining_ratio * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.1 * item
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-15 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization history component: Reward bins with higher utilization
        utilization_history = bins[valid_bins] - remaining_capacity[valid_bins]
        utilization_score_weight = 0.3
        utilization_score = utilization_history / bins[valid_bins]
        utilization_score = 1 / (1 + np.exp(-15 * (utilization_score - 0.7)))

        # Bin similarity and diversity component
        similarity_weight = 0.2
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        std_remaining = np.std(remaining_capacity[valid_bins])
        normalized_remaining = (remaining_capacity[valid_bins] - avg_remaining) / (std_remaining + 1e-6)
        similarity = 1 / (1 + np.exp(-15 * np.abs(normalized_remaining)))

        diversity_weight = 0.25
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-15 * (1 - np.var(scaled_remaining))))

        # Penalty for number of bins
        num_bins_penalty = 0.1 * len(bins)

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_score_weight * utilization_score -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities to a reasonable range
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + utilization_score_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

-----------------------

----------------------------------------------
import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, and distribution awareness."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    fit_ratio = item / (remaining_capacity + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.7)))
    spatial_fit[~valid_bins] = 0

    # Future potential component: Penalize bins with too little or too much remaining space
    ideal_remaining = 0.2  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-20 * (remaining_scaled - ideal_remaining)))
    future_potential[remaining_after < 0] = 0

    # Bin utilization bonus: Reward bins that are moderately filled
    utilization = 1.0 - (remaining_capacity / bins)
    utilization_bonus = np.exp(-0.2 * (utilization - 0.7) ** 2)

    # Fragmentation penalty: Penalize bins that leave too little usable space
    fragmentation_penalty = np.zeros_like(bins, dtype=np.float64)
    fragmentation_threshold = 0.1  # Minimum acceptable remaining space
    fragmentation_penalty[remaining_capacity < fragmentation_threshold] = 0.8

    # Distribution awareness component: Penalize bins with remaining capacity too high compared to others
    mean_remaining = np.mean(remaining_capacity[valid_bins])
    std_remaining = np.std(remaining_capacity[valid_bins])
    distribution_penalty = np.exp(-1.0 * ((remaining_capacity - mean_remaining) / (std_remaining + 1e-6)) ** 2)
    distribution_penalty[~valid_bins] = 0

    # Combine components with tunable weights
    weight_spatial = 0.7
    weight_future = 0.4
    weight_utilization = 0.3
    weight_fragmentation = 0.1
    weight_distribution = 0.2

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus -
        weight_fragmentation * fragmentation_penalty -
        weight_distribution * distribution_penalty
    )

    # Ensure invalid bins have the lowest priority
    priorities[~valid_bins] = -np.inf

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------



import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.6
        spatial_fit = 1 / (1 + np.exp(-20 * (fit_ratio - 0.5)))

        # Future potential component: Balance remaining space for future items
        ideal_remaining_ratio = 0.5
        ideal_remaining = ideal_remaining_ratio * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.1 * item
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-15 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Bin utilization history component: Reward bins with higher utilization
        utilization_history = bins[valid_bins] - remaining_capacity[valid_bins]
        utilization_score_weight = 0.3
        utilization_score = utilization_history / bins[valid_bins]
        utilization_score = 1 / (1 + np.exp(-15 * (utilization_score - 0.7)))

        # Bin similarity and diversity component
        similarity_weight = 0.2
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        std_remaining = np.std(remaining_capacity[valid_bins])
        normalized_remaining = (remaining_capacity[valid_bins] - avg_remaining) / (std_remaining + 1e-6)
        similarity = 1 / (1 + np.exp(-15 * np.abs(normalized_remaining)))

        diversity_weight = 0.25
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-15 * (1 - np.var(scaled_remaining))))

        # Penalty for number of bins
        num_bins_penalty = 0.1 * len(bins)

        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_score_weight * utilization_score -
            similarity_weight * similarity -
            diversity_weight * diversity -
            num_bins_penalty
        )

        # Normalize priorities to a reasonable range
        total_priority = total_priority / (spatial_fit_weight + future_potential_weight + utilization_score_weight + similarity_weight + diversity_weight)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.


import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining > 0
    
    # Spatial fit component: How well the item fits into the bin
    fill_ratio = item / (bins + 1e-6)
    space_utilization = 1 - (remaining / (bins + 1e-6))
    spatial_fit = (fill_ratio + space_utilization) / 2
    
    # Future potential component: How well the bin can accommodate future items
    ideal_remaining = 0.2  # Ideal remaining space as a fraction of bin capacity
    remaining_scaled = remaining / np.max(bins)
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Bin similarity component: Encourage even distribution of remaining space
    avg_remaining = np.mean(remaining_scaled[valid])
    similarity_score = np.exp(-1.5 * np.abs(remaining_scaled - avg_remaining))
    
    # Diversity component: Penalize high variance in remaining capacities
    diversity_weight = 0.2
    diversity_score = 1 / (1 + np.exp(-5.0 * (1 - np.var(remaining_scaled))))
    
    # Combine components with tunable weights
    weight_spatial = 0.6
    weight_future = 0.3
    weight_similarity = 0.1
    weight_diversity = 0.05
    
    total_priority = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_similarity * similarity_score +
        weight_diversity * diversity_score
    )
    
    # Penalize bins that are too full or too empty
    fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
    total_priority += fullness_penalty
    
    # Ensure invalid bins have the lowest priority
    total_priority[~valid] = -np.inf
    
    return total_priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
-----------------------

-----------------------
request...
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.1
        weight_diversity = 0.2
        penalty = 0.05 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining > 0
    
    # Spatial fit component: How well the item fits into the bin
    fill_ratio = item / (bins + 1e-6)
    space_utilization = 1 - (remaining / (bins + 1e-6))
    spatial_fit = (fill_ratio + space_utilization) / 2
    
    # Future potential component: How well the bin can accommodate future items
    ideal_remaining = 0.2  # Ideal remaining space as a fraction of bin capacity
    remaining_scaled = remaining / np.max(bins)
    future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - ideal_remaining)))
    
    # Bin similarity component: Encourage even distribution of remaining space
    avg_remaining = np.mean(remaining_scaled[valid])
    similarity_score = np.exp(-1.5 * np.abs(remaining_scaled - avg_remaining))
    
    # Diversity component: Penalize high variance in remaining capacities
    diversity_weight = 0.2
    diversity_score = 1 / (1 + np.exp(-5.0 * (1 - np.var(remaining_scaled))))
    
    # Combine components with tunable weights
    weight_spatial = 0.6
    weight_future = 0.3
    weight_similarity = 0.1
    weight_diversity = 0.05
    
    total_priority = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_similarity * similarity_score +
        weight_diversity * diversity_score
    )
    
    # Penalize bins that are too full or too empty
    fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
    total_priority += fullness_penalty
    
    # Ensure invalid bins have the lowest priority
    total_priority[~valid] = -np.inf
    
    return total_priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Returns priority with which we want to add item to each bin.

    This version introduces a novel priority strategy that balances spatial fit
    with future packing potential, incorporating tunable parameters for
    customization.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    # Calculate remaining capacity after adding the item
    remaining_capacity = bins - item
    valid_bins = remaining_capacity > 0

    # Spatial fit component: Higher priority for better fit
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    spatial_fit[valid_bins] = 1.0 / (1.0 + np.exp(-(bins[valid_bins] - item) / (bins[valid_bins] + 1e-8)))

    # Sparsity penalty: Penalize bins that leave too much space
    max_allowed_sparsity = 0.5  # Tunable parameter
    sparsity = remaining_capacity / bins
    sparsity_penalty = np.zeros_like(bins, dtype=np.float64)
    sparsity_penalty[valid_bins] = np.exp(-(sparsity[valid_bins] - max_allowed_sparsity) ** 2 /
                                          (2 * (0.2 ** 2)))

    # Bin utilization bonus: Reward bins that are neither too empty nor too full
    utilization = 1.0 - sparsity
    utilization_bonus = np.exp(-(utilization - 0.8) ** 2 /
                               (2 * (0.15 ** 2)))

    # Future potential component: Heuristic based on average item size
    average_item_size = 2.0  # Hypothetical average size
    future_potential = np.exp(-(remaining_capacity - average_item_size) ** 2 /
                              (2 * (0.5 ** 2)))
    future_potential[remaining_capacity < 0] = 0

    # Combine components with tunable weights
    weight_spatial = 0.6
    weight_sparsity = 0.5
    weight_utilization = 0.2
    weight_future = 0.1

    priorities = (
        weight_spatial * spatial_fit +
        weight_sparsity * sparsity_penalty +
        weight_utilization * utilization_bonus +
        weight_future * future_potential
    )

    # Ensure invalid bins have zero priority
    priorities[~valid_bins] = 0.0

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function for online bin-packing considering spatial fit, future potential, bin similarity, and dynamic load balancing."""
    remaining = bins - item
    valid = remaining >= 0
    
    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf
    
    if np.any(valid):
        # Spatial fit component
        fill_ratio = item / (bins[valid] + 1e-6)
        space_utilization = 1 - (remaining[valid] / (bins[valid] + 1e-6))
        spatial_fit = (fill_ratio + space_utilization) / 2
        
        # Future potential component
        ideal_remaining = 0.2 * bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining[valid] - ideal_remaining) / bins[valid])))
        
        # Bin similarity component
        avg_remaining = np.mean(remaining[valid])
        similarity_score = np.exp(-1.0 * np.abs(remaining[valid] - avg_remaining) / (np.max(bins) + 1e-6))
        
        # Diversity score component
        diversity_weight = 0.2
        diversity_score = 1 / (1 + np.exp(-1.5 * (len(bins) - np.count_nonzero(valid))))
        
        # Dynamic load balancing component
        current_loads = bins - remaining
        avg_load = np.mean(current_loads)
        load_diff = np.abs(current_loads[valid] - avg_load)
        load_balance = 1 / (1 + np.exp(-5 * (avg_load - load_diff)))
        
        # Combine components with tunable weights
        weight_spatial = 0.7
        weight_future = 0.4
        weight_similarity = 0.2
        weight_diversity = 0.15
        weight_balance = 0.2
        
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity_score +
            weight_diversity * diversity_score +
            weight_balance * load_balance
        )
        
        # Apply penalties for bins that are too full or too empty
        fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
        total_priority += fullness_penalty
        
        priorities[valid] = total_priority
    
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        spatial_fit_slope = tunable([8, 10, 12])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.3, 0.4, 0.5])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = tunable([0.2, 0.3, 0.4])
        utilization_threshold_low = tunable([0.1, 0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.1, -0.2, -0.3])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 37
-------------------



current thread_i 0
launch 64 evaluate tasks
current thread_i 9
this best socre: -209.5; best score: -209.5; global score: -208.1; space size: 59049; measure cnt: 64
..............................................................................................................................
launch 64 evaluate tasks
current thread_i 4
current thread_i 2
this best socre: -209.5; best score: -209.5; global score: -208.1; space size: 59049; measure cnt: 128
................................................................................
launch 64 evaluate tasks
this best socre: -209.25; best score: -209.25; global score: -208.1; space size: 59049; measure cnt: 192
.......
launch 64 evaluate tasks
current thread_i 5
current thread_i 8
this best socre: -209.25; best score: -209.25; global score: -208.1; space size: 59049; measure cnt: 256
.......
launch 64 evaluate tasks
current thread_i 6
this best socre: -209.25; best score: -209.25; global score: -208.1; space size: 59049; measure cnt: 320
.....
launch 64 evaluate tasks
this best socre: -209.25; best score: -209.25; global score: -208.1; space size: 59049; measure cnt: 384
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Get tunable parameters
        ideal_remaining_fraction = tunable([0.3, 0.4, 0.5])
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        future_potential_weight = tunable([0.3, 0.4, 0.5])
        utilization_bonus_weight = tunable([0.2, 0.3, 0.4])
        distribution_impact_weight = tunable([-0.1, -0.2, -0.3])
        
        # Spatial fit component: How well the item fits into the bin
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit = 1 / (1 + np.exp(-tunable([10, 15, 20]) * (fit_ratio - tunable([0.6, 0.7, 0.8]))))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential = 1 / (1 + np.exp(-tunable([5, 10, 15]) * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating similar remaining capacities
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -tunable([0.1, 0.2, 0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 38
-------------------



launch 64 evaluate tasks
this best socre: -213.35; best score: -213.35; global score: -208.1; space size: 177147; measure cnt: 64

launch 64 evaluate tasks
this best socre: -210.3; best score: -210.3; global score: -208.1; space size: 177147; measure cnt: 128
....................................................................................................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -210.3; best score: -210.3; global score: -208.1; space size: 177147; measure cnt: 192
.......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -210.3; best score: -210.3; global score: -208.1; space size: 177147; measure cnt: 256
...................................................................................................................................................................................................................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -210.3; best score: -210.3; global score: -208.1; space size: 177147; measure cnt: 320
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.5, 0.6, 0.7])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential_slope = tunable([10, 15, 20])
        future_potential = 1 / (1 + np.exp(-future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 39
-------------------



launch 64 evaluate tasks
this best socre: -210.75; best score: -210.75; global score: -208.1; space size: 177147; measure cnt: 64
....
launch 64 evaluate tasks
this best socre: -210.75; best score: -210.75; global score: -208.1; space size: 177147; measure cnt: 128
....................
launch 64 evaluate tasks
current thread_i 7
this best socre: -210.75; best score: -210.75; global score: -208.1; space size: 177147; measure cnt: 192
.......
launch 64 evaluate tasks
this best socre: -210.75; best score: -210.75; global score: -208.1; space size: 177147; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Fragmentation penalty: Penalize bins that leave too little usable space
        fragmentation_penalty_weight = tunable([-0.1, -0.2, -0.3])
        fragmentation_threshold = tunable([0.1, 0.2, 0.3])
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            fragmentation_penalty_weight * fragmentation_penalty +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 40
-------------------



launch 64 evaluate tasks
this best socre: -209.5; best score: -209.5; global score: -208.1; space size: 531441; measure cnt: 64

launch 64 evaluate tasks
this best socre: -208.35; best score: -208.35; global score: -208.1; space size: 531441; measure cnt: 128

launch 64 evaluate tasks
this best socre: -208.35; best score: -208.35; global score: -208.1; space size: 531441; measure cnt: 192

launch 64 evaluate tasks
this best socre: -208.35; best score: -208.35; global score: -208.1; space size: 531441; measure cnt: 256
.
launch 64 evaluate tasks
current thread_i 1
this best socre: -208.35; best score: -208.35; global score: -208.1; space size: 531441; measure cnt: 320
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategies."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Reward bins where the item fits well
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.7, 0.6, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.4, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins with balanced utilization
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.15, 0.25])
        utilization_threshold_high = tunable([0.8, 0.75, 0.85])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining space
        distribution_impact_weight = tunable([-0.3, -0.25, -0.35])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic weighting based on current bin state
        avg_fill = np.mean(1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8)))
        weight_spatial = tunable([0.6, 0.7, 0.8]) * (1.0 - avg_fill)
        weight_future = tunable([0.5, 0.6, 0.7]) * avg_fill
        weight_utilization = tunable([0.4, 0.5, 0.6])
        weight_distribution = tunable([-0.3, -0.25, -0.35])

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.15, -0.25]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 41
-------------------



launch 64 evaluate tasks
this best socre: -210.55; best score: -210.55; global score: -208.1; space size: 4782969; measure cnt: 64

launch 64 evaluate tasks
this best socre: -210.55; best score: -210.55; global score: -208.1; space size: 4782969; measure cnt: 128

launch 64 evaluate tasks
this best socre: -210.2; best score: -210.2; global score: -208.1; space size: 4782969; measure cnt: 192

launch 64 evaluate tasks
this best socre: -209.7; best score: -209.7; global score: -208.1; space size: 4782969; measure cnt: 256

launch 64 evaluate tasks
this best socre: -209.7; best score: -209.7; global score: -208.1; space size: 4782969; measure cnt: 320

launch 64 evaluate tasks
this best socre: -208.65; best score: -208.65; global score: -208.1; space size: 4782969; measure cnt: 384

launch 64 evaluate tasks
this best socre: -208.65; best score: -208.65; global score: -208.1; space size: 4782969; measure cnt: 448

launch 64 evaluate tasks
this best socre: -208.65; best score: -208.65; global score: -208.1; space size: 4782969; measure cnt: 512

launch 64 evaluate tasks
this best socre: -208.65; best score: -208.65; global score: -208.1; space size: 4782969; measure cnt: 576
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategies and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for bins where the item fits well
        fill_ratio = item / (bins[valid_bins] + 1e-8)
        space_utilization = 1 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8))
        spatial_fit = (fill_ratio + space_utilization) / 2
        
        # Future potential component: Reward bins that leave ideal space for future items
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_capacity[valid_bins] - ideal_remaining) / (bins[valid_bins] + 1e-8))))
        
        # Bin utilization bonus: Reward bins that are well-utilized (not too full or too empty)
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.8, 0.9])
        utilization = 1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )
        
        # Distribution impact component: Penalize creating bins that are too similar to others
        distribution_impact_weight = tunable([-0.3, -0.2, -0.4])
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance
        
        # Dynamic load balancing component: Penalize bins that would create imbalance
        load_balance_weight = tunable([-0.2, -0.3, -0.1])
        current_loads = bins - remaining_capacity
        avg_load = np.mean(current_loads)
        load_diff = np.abs(current_loads[valid_bins] - avg_load)
        load_balance = 1 / (1 + np.exp(-5 * (avg_load - load_diff)))
        
        # Size-based scaling: Give preference to larger items
        size_scaling_weight = tunable([0.1, 0.15, 0.2])
        size_scaling = np.exp(-size_scaling_weight * (item / np.max(bins)))
        
        # Combine components with tunable weights
        weight_spatial = tunable([0.6, 0.7, 0.8])
        weight_future = tunable([0.5, 0.6, 0.7])
        
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact +
            load_balance_weight * load_balance +
            size_scaling
        )
        
        # Apply penalties for bins that are too full or too empty
        fullness_penalty_weight = tunable([0.2, 0.3])
        fullness_penalty = fullness_penalty_weight * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
        total_priority += fullness_penalty
        
        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority
        
        priorities[valid_bins] = total_priority

    return priorities

call llm times: 42
-------------------



launch 64 evaluate tasks
this best socre: -219.0; best score: -219.0; global score: -208.1; space size: 17496; measure cnt: 64

launch 64 evaluate tasks
this best socre: -219.0; best score: -219.0; global score: -208.1; space size: 17496; measure cnt: 128

launch 64 evaluate tasks
this best socre: -219.0; best score: -219.0; global score: -208.1; space size: 17496; measure cnt: 192

launch 64 evaluate tasks
this best socre: -219.0; best score: -219.0; global score: -208.1; space size: 17496; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategies and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Calculate item characteristics
        if len(item_history) == 0:
            avg_item_size = item
            max_item_size = item
        else:
            avg_item_size = np.mean(item_history)
            max_item_size = np.max(item_history)
        
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.5, 0.6, 0.7])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential component
        ideal_remaining_fraction = tunable([0.3, 0.4, 0.5])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins] + tunable([0.0, 0.1, 0.2]) * avg_item_size
        remaining_after = remaining_capacity[valid_bins]
        future_potential_slope = tunable([10, 15, 20])
        future_potential = 1 / (1 + np.exp(-future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))
        
        # Bin utilization bonus
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )
        
        # Bin diversity component
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        diversity_impact = new_variance - current_variance
        diversity_penalty = tunable([0.3, 0.4, 0.5]) * diversity_impact
        
        # Item size distribution component
        size_distribution_bonus = tunable([0.0, 0.1, 0.2])
        if item > max_item_size * 0.8:
            size_distribution_bonus = tunable([0.1, 0.2, 0.3])
        
        # Combine components with tunable weights
        total_priority = (
            tunable([0.5, 0.6, 0.7]) * spatial_fit +
            tunable([0.4, 0.5, 0.6]) * future_potential +
            tunable([0.3, 0.4, 0.5]) * utilization_bonus +
            tunable([0.2, 0.3, 0.4]) * size_distribution_bonus -
            tunable([0.1, 0.2, 0.3]) * diversity_penalty
        )
        
        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty
        
        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority
        
        priorities[valid_bins] = total_priority

    return priorities

call llm times: 43
-------------------



launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 129140163; measure cnt: 64

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 129140163; measure cnt: 128

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 129140163; measure cnt: 192
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.7, 0.8, 0.9])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential_slope = tunable([10, 15, 20])
        future_potential = 1 / (1 + np.exp(-future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Utilization bonus component: Reward bins with utilization within a target range
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Diversity impact component: Penalize creating bins with similar remaining capacities
        diversity_impact_weight = tunable([-0.2, -0.3, -0.4])
        avg_remaining = np.mean(remaining_after)
        std_remaining = np.std(remaining_after)
        normalized_remaining = (remaining_after - avg_remaining) / (std_remaining + 1e-8)
        diversity_impact_slope = tunable([10, 15, 20])
        similarity_score = 1 / (1 + np.exp(-diversity_impact_slope * np.abs(normalized_remaining)))
        diversity_impact = similarity_score * diversity_impact_weight

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            diversity_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities to a reasonable range
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 44
-------------------



launch 64 evaluate tasks
this best socre: -210.8; best score: -210.8; global score: -208.1; space size: 531441; measure cnt: 64
........
launch 64 evaluate tasks
this best socre: -210.8; best score: -210.8; global score: -208.1; space size: 531441; measure cnt: 128
...........
launch 64 evaluate tasks
this best socre: -210.8; best score: -210.8; global score: -208.1; space size: 531441; measure cnt: 192
.......
launch 64 evaluate tasks
this best socre: -210.8; best score: -210.8; global score: -208.1; space size: 531441; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_slope = tunable([10, 20, 30])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component
        ideal_remaining_fraction = tunable([0.2, 0.5, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_slope = tunable([10, 20, 30])
        future_midpoint = tunable([0.1, 0.2, 0.3])
        future_potential = 1 / (1 + np.exp(-future_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8) - future_midpoint)))

        # Utilization bonus component
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        util_slope = tunable([10, 20, 30])
        util_midpoint = tunable([0.5, 0.6, 0.7])
        utilization_bonus = 1 / (1 + np.exp(-util_slope * (utilization - util_midpoint)))

        # Distribution impact component (using entropy)
        def compute_entropy(capacities):
            if len(capacities) == 0:
                return 0.0
            capacities = capacities / np.sum(capacities)
            capacities = np.clip(capacities, 1e-10, 1.0)
            return -np.sum(capacities * np.log(capacities))

        entropy_before = compute_entropy(remaining_capacity[valid_bins])
        distribution_impact = np.zeros_like(remaining_after)
        for i in range(len(remaining_after)):
            new_remaining = remaining_capacity.copy()
            new_remaining[i] = remaining_after[i]
            valid_new_remaining = new_remaining[valid_bins]
            entropy_after_i = compute_entropy(valid_new_remaining)
            distribution_impact[i] = entropy_after_i - entropy_before

        # Combine components with tunable weights
        weight_spatial = tunable([0.6, 0.7, 0.8])
        weight_future = tunable([0.3, 0.4, 0.5])
        weight_util = tunable([0.1, 0.2, 0.3])
        weight_dist = tunable([0.1, 0.2, 0.3])

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_util * utilization_bonus +
            weight_dist * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 45
-------------------



launch 64 evaluate tasks
this best socre: -239.95; best score: -239.95; global score: -208.1; space size: 531441; measure cnt: 64
.......
launch 64 evaluate tasks
this best socre: -239.95; best score: -239.95; global score: -208.1; space size: 531441; measure cnt: 128
..................
launch 64 evaluate tasks
this best socre: -239.95; best score: -239.95; global score: -208.1; space size: 531441; measure cnt: 192
....................................
launch 64 evaluate tasks
this best socre: -239.95; best score: -239.95; global score: -208.1; space size: 531441; measure cnt: 256
sampler suggest should end sample, break
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 20
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Fragmentation penalty: Penalize bins that leave too little usable space
        fragmentation_penalty_weight = -0.1
        fragmentation_threshold = 0.1
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.4
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            fragmentation_penalty_weight * fragmentation_penalty +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 20
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Fragmentation penalty: Penalize bins that leave too little usable space
        fragmentation_penalty_weight = -0.1
        fragmentation_threshold = 0.1
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.4
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            fragmentation_penalty_weight * fragmentation_penalty +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 20
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Fragmentation penalty: Penalize bins that leave too little usable space
        fragmentation_penalty_weight = -0.1
        fragmentation_threshold = 0.1
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.4
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            fragmentation_penalty_weight * fragmentation_penalty +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategies."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Reward bins where the item fits well
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.7
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins with balanced utilization
        utilization_bonus_weight = 0.6
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining space
        distribution_impact_weight = -0.25
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic weighting based on current bin state
        avg_fill = np.mean(1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8)))
        weight_spatial = 0.6 * (1.0 - avg_fill)
        weight_future = 0.7 * avg_fill
        weight_utilization = 0.6
        weight_distribution = -0.25

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.25 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 20
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Fragmentation penalty: Penalize bins that leave too little usable space
        fragmentation_penalty_weight = -0.1
        fragmentation_threshold = 0.1
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.4
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            fragmentation_penalty_weight * fragmentation_penalty +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategies."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Reward bins where the item fits well
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.7
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins with balanced utilization
        utilization_bonus_weight = 0.6
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining space
        distribution_impact_weight = -0.25
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic weighting based on current bin state
        avg_fill = np.mean(1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8)))
        weight_spatial = 0.6 * (1.0 - avg_fill)
        weight_future = 0.7 * avg_fill
        weight_utilization = 0.6
        weight_distribution = -0.25

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.25 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategies."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Reward bins where the item fits well
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.7
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins with balanced utilization
        utilization_bonus_weight = 0.6
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining space
        distribution_impact_weight = -0.25
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic weighting based on current bin state
        avg_fill = np.mean(1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8)))
        weight_spatial = 0.6 * (1.0 - avg_fill)
        weight_future = 0.7 * avg_fill
        weight_utilization = 0.6
        weight_distribution = -0.25

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.25 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

request...-----------------------

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 20
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Fragmentation penalty: Penalize bins that leave too little usable space
        fragmentation_penalty_weight = -0.1
        fragmentation_threshold = 0.1
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.4
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            fragmentation_penalty_weight * fragmentation_penalty +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf

    if np.any(valid):
        # Spatial fit component
        fit_ratio = item / (bins[valid] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        avg_remaining = np.mean(remaining[valid])
        ideal_remaining = 0.2 * bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining[valid] - ideal_remaining) / bins[valid])))

        # Bin similarity component
        avg_load = np.mean(bins - remaining)
        similarity = np.exp(-1.5 * np.abs(fit_ratio - avg_load / bins[valid]))

        # Diversity component
        remaining_scaled = remaining[valid] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Dynamic weights based on current bin state
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.2
        weight_diversity = 0.3

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity
        )

        # Penalty for bins that are too full or too empty
        fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fit_ratio - 0.5))
        total_priority += fullness_penalty

        priorities[valid] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Novel approach: Consider both fit ratio and remaining space diversity
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        
        # Use logistic function to create an S-shaped priority curve
        spatial_fit = 1 / (1 + np.exp(
            -spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)
        ))

        # Future potential component: Reward bins with remaining space that matches ideal distribution
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        # Novel approach: Consider both lower and upper bounds for ideal remaining space
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        
        # Use logistic function to create smooth transition between good and bad remaining space
        future_potential = 1 / (1 + np.exp(
            -10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Bin utilization bonus: Reward bins that are well-utilized without being too full
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Novel approach: Diversity bonus for maintaining diverse bin sizes
        diversity_bonus_weight = tunable([0.3, 0.4, 0.5])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        diversity_score = 1.0 / (1.0 + np.exp(
            -10.0 * (np.abs(scaled_remaining - np.mean(scaled_remaining)) / (np.std(scaled_remaining) + 1e-8))
        ))
        diversity_bonus = diversity_score * diversity_bonus_weight

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            diversity_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 46
-------------------


current thread_i 6

launch 64 evaluate tasks
current thread_i 4
this best socre: -215.95; best score: -215.95; global score: -208.1; space size: 59049; measure cnt: 64
...............................................................................................
launch 64 evaluate tasks
current thread_i 8
current thread_i 9
this best socre: -215.95; best score: -215.95; global score: -208.1; space size: 59049; measure cnt: 128
...........................
launch 64 evaluate tasks
current thread_i 2
current thread_i 5
current thread_i 1
current thread_i 0
this best socre: -211.45; best score: -211.45; global score: -208.1; space size: 59049; measure cnt: 192
...............................................................................................................................................................................
launch 7 evaluate tasks
this best socre: -211.45; best score: -211.45; global score: -208.1; space size: 59049; measure cnt: 199
.................................................................................................................
launch 6 evaluate tasks
this best socre: -211.45; best score: -211.45; global score: -208.1; space size: 59049; measure cnt: 205
..............................................................................................................................................
launch 7 evaluate tasks
this best socre: -211.45; best score: -211.45; global score: -208.1; space size: 59049; measure cnt: 212
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters"""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial-temporal fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Novel spatial-temporal fit calculation
        spatial_weight = tunable([0.5, 0.6, 0.7])
        temporal_weight = tunable([0.2, 0.3, 0.4])
        
        # Immediate spatial fit
        spatial_fit = 1 / (1 + np.exp(-tunable([10, 15, 20]) * 
                                      (fit_ratio - tunable([0.6, 0.7, 0.8]))))
        
        # Future temporal fit estimate
        future_fill_prob = tunable([0.8, 0.9, 0.95])
        expected_remaining = remaining_capacity[valid_bins] * future_fill_prob
        temporal_fit = 1 / (1 + np.exp(-tunable([5, 10, 15]) *
                                       (expected_remaining - tunable([0.3, 0.4, 0.5]) * bins[valid_bins])))
        
        # Combine spatial and temporal fit
        spatiotemporal_fit = (spatial_weight * spatial_fit +
                              temporal_weight * temporal_fit)

        # Bin diversity score
        diversity_bonus_weight = tunable([0.2, 0.3, 0.4])
        bin_usage_freq = np.zeros_like(bins, dtype=np.float64)
        bin_usage_freq[valid_bins] = 1.0 / (np.log(len(bins)) + np.bincount(np.argsort(bins)))
        diversity_bonus = diversity_bonus_weight * bin_usage_freq[valid_bins]

        # Adaptive utilization bonus
        utilization_weight = tunable([0.3, 0.4, 0.5])
        utilization = 1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8))
        utilization_threshold = tunable([0.25, 0.3, 0.35])
        utilization_bonus = utilization_weight * np.where(
            utilization >= utilization_threshold,
            1.0,
            0.0
        )

        # Distribution impact penalty
        distribution_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = distribution_weight * (new_variance - current_variance)

        # Combine all components
        total_priority = (
            spatiotemporal_fit +
            diversity_bonus +
            utilization_bonus +
            distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 47
-------------------



launch 64 evaluate tasks
this best socre: -244.55; best score: -244.55; global score: -208.1; space size: 531441; measure cnt: 64
..........................................................................
launch 1 evaluate tasks
this best socre: -244.55; best score: -244.55; global score: -208.1; space size: 531441; measure cnt: 65
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -244.55; global score: -208.1; space size: 531441; measure cnt: 65
..........................................................................................................................................................................................................................................................................................................
launch 5 evaluate tasks
this best socre: -241.75; best score: -241.75; global score: -208.1; space size: 531441; measure cnt: 70
.................................................................................................
launch 2 evaluate tasks
this best socre: -241.75; best score: -241.75; global score: -208.1; space size: 531441; measure cnt: 72
........................................................................................
launch 1 evaluate tasks
this best socre: -241.75; best score: -241.75; global score: -208.1; space size: 531441; measure cnt: 73
....................................................................
launch 1 evaluate tasks
current thread_i 7
this best socre: -241.75; best score: -241.75; global score: -208.1; space size: 531441; measure cnt: 74
sampler suggest should end sample, break
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategies."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Reward bins where the item fits well
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.7
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins with balanced utilization
        utilization_bonus_weight = 0.6
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining space
        distribution_impact_weight = -0.25
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic weighting based on current bin state
        avg_fill = np.mean(1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8)))
        weight_spatial = 0.6 * (1.0 - avg_fill)
        weight_future = 0.7 * avg_fill
        weight_utilization = 0.6
        weight_distribution = -0.25

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.25 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf

    if np.any(valid):
        # Spatial fit component
        fit_ratio = item / (bins[valid] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        avg_remaining = np.mean(remaining[valid])
        ideal_remaining = 0.2 * bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining[valid] - ideal_remaining) / bins[valid])))

        # Bin similarity component
        avg_load = np.mean(bins - remaining)
        similarity = np.exp(-1.5 * np.abs(fit_ratio - avg_load / bins[valid]))

        # Diversity component
        remaining_scaled = remaining[valid] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Dynamic weights based on current bin state
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.2
        weight_diversity = 0.3

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity
        )

        # Penalty for bins that are too full or too empty
        fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fit_ratio - 0.5))
        total_priority += fullness_penalty

        priorities[valid] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function for online bin-packing.

    This version introduces a novel strategy that dynamically balances spatial fit,
    future potential, and bin utilization while exposing tunable parameters for
    strategic optimization.

    Args:
        item: Size of the item to be placed.
        bins: Array of remaining capacities for each bin.

    Returns:
        Array of priority scores for each bin.
    """
    # Calculate remaining capacity after placing the item
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.5)))

    # Future potential component: Penalize bins that are too full or too empty
    ideal_remaining = 0.1 * bins  # Ideal remaining space as a percentage of bin capacity
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / (np.max(bins) + 1e-6)  # Normalize by max bin capacity
    future_potential = 1 / (1 + np.exp(-20 * (remaining_scaled - ideal_remaining)))

    # Bin utilization penalty: Discourage using too many bins
    num_bins_penalty = 0.2 * 0.5 * len(bins)

    # Combine components with tunable weights
    weight_fit = 0.6
    weight_future = 0.4
    
    total_priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )

    # Normalize priorities to maintain balance
    total_priority = total_priority / (weight_fit + weight_future)

    # Ensure invalid bins have the lowest priority
    total_priority[~valid_bins] = -np.inf

    return total_priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_slope = 30
        spatial_fit_midpoint = 0.6
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_slope = 10
        future_midpoint = 0.3
        future_potential = 1 / (1 + np.exp(-future_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8) - future_midpoint)))

        # Utilization bonus component
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        util_slope = 10
        util_midpoint = 0.5
        utilization_bonus = 1 / (1 + np.exp(-util_slope * (utilization - util_midpoint)))

        # Distribution impact component (using entropy)
        def compute_entropy(capacities):
            if len(capacities) == 0:
                return 0.0
            capacities = capacities / np.sum(capacities)
            capacities = np.clip(capacities, 1e-10, 1.0)
            return -np.sum(capacities * np.log(capacities))

        entropy_before = compute_entropy(remaining_capacity[valid_bins])
        distribution_impact = np.zeros_like(remaining_after)
        for i in range(len(remaining_after)):
            new_remaining = remaining_capacity.copy()
            new_remaining[i] = remaining_after[i]
            valid_new_remaining = new_remaining[valid_bins]
            entropy_after_i = compute_entropy(valid_new_remaining)
            distribution_impact[i] = entropy_after_i - entropy_before

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.5
        weight_util = 0.2
        weight_dist = 0.3

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_util * utilization_bonus +
            weight_dist * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function for online bin-packing considering spatial fit, future potential, bin similarity, and dynamic load balancing."""
    remaining = bins - item
    valid = remaining >= 0
    
    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf
    
    if np.any(valid):
        # Spatial fit component
        fill_ratio = item / (bins[valid] + 1e-6)
        space_utilization = 1 - (remaining[valid] / (bins[valid] + 1e-6))
        spatial_fit = (fill_ratio + space_utilization) / 2
        
        # Future potential component
        ideal_remaining = 0.2 * bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining[valid] - ideal_remaining) / bins[valid])))
        
        # Bin similarity component
        avg_remaining = np.mean(remaining[valid])
        similarity_score = np.exp(-1.0 * np.abs(remaining[valid] - avg_remaining) / (np.max(bins) + 1e-6))
        
        # Diversity score component
        diversity_weight = 0.2
        diversity_score = 1 / (1 + np.exp(-1.5 * (len(bins) - np.count_nonzero(valid))))
        
        # Dynamic load balancing component
        current_loads = bins - remaining
        avg_load = np.mean(current_loads)
        load_diff = np.abs(current_loads[valid] - avg_load)
        load_balance = 1 / (1 + np.exp(-5 * (avg_load - load_diff)))
        
        # Combine components with tunable weights
        weight_spatial = 0.7
        weight_future = 0.4
        weight_similarity = 0.2
        weight_diversity = 0.15
        weight_balance = 0.2
        
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity_score +
            weight_diversity * diversity_score +
            weight_balance * load_balance
        )
        
        # Apply penalties for bins that are too full or too empty
        fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
        total_priority += fullness_penalty
        
        priorities[valid] = total_priority
    
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.3
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.3
        utilization_threshold_low = 0.1
        utilization_threshold_high = 0.7
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.1 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategies."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Reward bins where the item fits well
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.7
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins with balanced utilization
        utilization_bonus_weight = 0.6
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining space
        distribution_impact_weight = -0.25
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic weighting based on current bin state
        avg_fill = np.mean(1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8)))
        weight_spatial = 0.6 * (1.0 - avg_fill)
        weight_future = 0.7 * avg_fill
        weight_utilization = 0.6
        weight_distribution = -0.25

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.25 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Reward bins where the item fits well
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Tunable parameters for spatial fit
        spatial_fit_slope = tunable([10, 15, 20])  # Steepness of fit curve
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])  # Ideal fit ratio
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])  # Weight of spatial fit
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])  # Ideal remaining space fraction
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        # Tunable parameters for future potential
        future_potential_slope = tunable([10, 15, 20])  # Steepness of future potential curve
        future_potential_weight = tunable([0.4, 0.5, 0.6])  # Weight of future potential
        
        future_potential = 1 / (1 + np.exp(-future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins with balanced utilization
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        
        # Tunable parameters for utilization bonus
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])  # Lower utilization threshold
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])  # Upper utilization threshold
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])  # Weight of utilization bonus
        
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining space
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance
        
        # Tunable parameter for distribution impact
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])  # Weight of distribution impact

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 48
-------------------


request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 20
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Fragmentation penalty: Penalize bins that leave too little usable space
        fragmentation_penalty_weight = -0.1
        fragmentation_threshold = 0.1
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.4
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            fragmentation_penalty_weight * fragmentation_penalty +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Novel approach: Consider both fit ratio and remaining space diversity
        spatial_fit_weight = 0.8
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.6
        
        # Use logistic function to create an S-shaped priority curve
        spatial_fit = 1 / (1 + np.exp(
            -spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)
        ))

        # Future potential component: Reward bins with remaining space that matches ideal distribution
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        # Novel approach: Consider both lower and upper bounds for ideal remaining space
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        
        # Use logistic function to create smooth transition between good and bad remaining space
        future_potential = 1 / (1 + np.exp(
            -10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Bin utilization bonus: Reward bins that are well-utilized without being too full
        utilization_bonus_weight = 0.6
        utilization_threshold_low = 0.4
        utilization_threshold_high = 0.9
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Novel approach: Diversity bonus for maintaining diverse bin sizes
        diversity_bonus_weight = 0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        diversity_score = 1.0 / (1.0 + np.exp(
            -10.0 * (np.abs(scaled_remaining - np.mean(scaled_remaining)) / (np.std(scaled_remaining) + 1e-8))
        ))
        diversity_bonus = diversity_score * diversity_bonus_weight

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            diversity_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.4 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

launch 64 evaluate tasks
this best socre: -209.85; best score: -209.85; global score: -208.1; space size: 177147; measure cnt: 64
................................................................................
launch 64 evaluate tasks
this best socre: -209.85; best score: -209.85; global score: -208.1; space size: 177147; measure cnt: 128
..............................................................................................
launch 64 evaluate tasks
current thread_i 7
this best socre: -209.85; best score: -209.85; global score: -208.1; space size: 177147; measure cnt: 192
...............................................................................................................
launch 64 evaluate tasks
current thread_i 0
current thread_i 9
current thread_i 2
current thread_i 6
this best socre: -209.85; best score: -209.85; global score: -208.1; space size: 177147; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Tunable parameters for spatial fit
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        # Enhanced future potential calculation
        future_potential_weight = tunable([0.4, 0.5, 0.6])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 49
-------------------



launch 64 evaluate tasks
current thread_i 8
current thread_i 5
current thread_i 1
this best socre: -212.8; best score: -212.8; global score: -208.1; space size: 11664; measure cnt: 64
.
launch 64 evaluate tasks
current thread_i 4
this best socre: -211.5; best score: -211.5; global score: -208.1; space size: 11664; measure cnt: 128
.......................................................................
launch 64 evaluate tasks
this best socre: -211.5; best score: -211.5; global score: -208.1; space size: 11664; measure cnt: 192
..................
launch 64 evaluate tasks
this best socre: -211.5; best score: -211.5; global score: -208.1; space size: 11664; measure cnt: 256
.........................
launch 64 evaluate tasks
this best socre: -211.5; best score: -211.5; global score: -208.1; space size: 11664; measure cnt: 320
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Penalize bins with too much remaining space
        remaining_after = remaining_capacity[valid_bins]
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        spatial_penalty_weight = tunable([0.8, 1.0, 1.2])
        spatial_penalty_threshold = tunable([0.3, 0.4, 0.5])
        spatial_penalty = np.where(
            remaining_after > spatial_penalty_threshold * bins[valid_bins],
            1.0 - (remaining_after / (bins[valid_bins] + 1e-8)),
            0.0
        )
        spatial_penalty = spatial_penalty_weight * spatial_penalty

        # Future potential component: Reward bins with remaining space that matches future item sizes
        future_window_size = tunable([3, 5, 7])
        future_item_sizes = np.sort(bins)[-future_window_size:]  # Assume future items are similar to current bins
        future_fit = np.zeros_like(remaining_after)
        for future_item in future_item_sizes:
            future_fit += np.exp(-np.abs(remaining_after - future_item) / (np.mean(bins) + 1e-8))
        future_fit /= len(future_item_sizes)
        future_potential_weight = tunable([0.6, 0.7, 0.8])
        future_potential = future_potential_weight * future_fit

        # Utilization bonus: Reward bins with utilization within an optimal range
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus_weight = tunable([0.5, 0.6, 0.7])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            utilization_bonus_weight * (1.0 - np.abs(utilization - 0.5) * 2.0),
            0.0
        )

        # Distribution impact: Penalize creating bins with similar remaining capacities
        distribution_impact_weight = tunable([-0.3, -0.4, -0.5])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_entropy = -np.sum(scaled_remaining * np.log(scaled_remaining + 1e-8)) / np.log(len(scaled_remaining))
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_entropy = -np.sum(new_remaining * np.log(new_remaining + 1e-8)) / np.log(len(new_remaining))
        distribution_impact = distribution_impact_weight * (new_entropy - current_entropy)

        # Fragmentation penalty: Penalize bins that leave too little usable space
        fragmentation_penalty_weight = tunable([-0.1, -0.2, -0.3])
        fragmentation_threshold = tunable([0.1, 0.2])
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0
        fragmentation_penalty *= fragmentation_penalty_weight

        # Combine components with tunable weights
        total_priority = (
            -spatial_penalty +  # Negative because we want to penalize
            future_potential +
            utilization_bonus +
            distribution_impact +
            fragmentation_penalty
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 50
-------------------



launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 104976; measure cnt: 64

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 104976; measure cnt: 128

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 104976; measure cnt: 192
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Reward bins where the item fits well
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.7, 0.8, 0.9])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins with balanced utilization
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating similar remaining capacities
        distribution_impact_weight = tunable([-0.3, -0.25, -0.2])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic weights based on current bin state
        avg_fill = np.mean(1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8)))
        weight_spatial = tunable([0.6, 0.7]) * (1.0 - avg_fill)
        weight_future = tunable([0.7, 0.8]) * avg_fill
        weight_utilization = tunable([0.6, 0.7])
        weight_distribution = tunable([-0.25, -0.3])

        # Combine components with tunable weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.25, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 51
-------------------



launch 64 evaluate tasks
this best socre: -214.85; best score: -214.85; global score: -208.1; space size: 944784; measure cnt: 64

launch 64 evaluate tasks
this best socre: -214.85; best score: -214.85; global score: -208.1; space size: 944784; measure cnt: 128

launch 64 evaluate tasks
this best socre: -214.85; best score: -214.85; global score: -208.1; space size: 944784; measure cnt: 192

launch 64 evaluate tasks
this best socre: -214.55; best score: -214.55; global score: -208.1; space size: 944784; measure cnt: 256

launch 64 evaluate tasks
this best socre: -213.8; best score: -213.8; global score: -208.1; space size: 944784; measure cnt: 320

launch 64 evaluate tasks
this best socre: -213.8; best score: -213.8; global score: -208.1; space size: 944784; measure cnt: 384

launch 64 evaluate tasks
this best socre: -213.8; best score: -213.8; global score: -208.1; space size: 944784; measure cnt: 448

launch 64 evaluate tasks
this best socre: -213.8; best score: -213.8; global score: -208.1; space size: 944784; measure cnt: 512
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategies."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Reward bins where the item fits well
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.7, 0.75, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins with balanced utilization
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.25, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8, 0.85])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating similar remaining capacities
        distribution_impact_weight = tunable([-0.3, -0.25, -0.2])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic weighting based on current bin state
        avg_fill = np.mean(1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8)))
        weight_spatial = tunable([0.6, 0.7]) * (1.0 - avg_fill)
        weight_future = tunable([0.5, 0.6]) * avg_fill
        weight_utilization = tunable([0.4, 0.5])
        weight_distribution = tunable([-0.3, -0.25])

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.25, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 52
-------------------



launch 64 evaluate tasks
this best socre: -214.7; best score: -214.7; global score: -208.1; space size: 944784; measure cnt: 64
.
launch 64 evaluate tasks
this best socre: -214.7; best score: -214.7; global score: -208.1; space size: 944784; measure cnt: 128

launch 64 evaluate tasks
this best socre: -214.55; best score: -214.55; global score: -208.1; space size: 944784; measure cnt: 192

launch 64 evaluate tasks
this best socre: -214.3; best score: -214.3; global score: -208.1; space size: 944784; measure cnt: 256

launch 64 evaluate tasks
this best socre: -214.3; best score: -214.3; global score: -208.1; space size: 944784; measure cnt: 320

launch 64 evaluate tasks
this best socre: -214.3; best score: -214.3; global score: -208.1; space size: 944784; measure cnt: 384

launch 64 evaluate tasks
this best socre: -213.2; best score: -213.2; global score: -208.1; space size: 944784; measure cnt: 448

launch 64 evaluate tasks
this best socre: -213.2; best score: -213.2; global score: -208.1; space size: 944784; measure cnt: 512

launch 64 evaluate tasks
this best socre: -213.2; best score: -213.2; global score: -208.1; space size: 944784; measure cnt: 576

launch 64 evaluate tasks
this best socre: -213.2; best score: -213.2; global score: -208.1; space size: 944784; measure cnt: 640
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    if history is None:
        history = np.array([])
    
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Predict next item size using the history
        next_item_pred = predict_next_item_size(history)
        
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.5, 0.6, 0.7], 0.6)
        spatial_fit_slope = tunable([8, 10, 12], 10)
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8], 0.7)
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space suitable for next predicted item
        ideal_remaining_for_next = next_item_pred * tunable([0.8, 1.0, 1.2], 1.0)
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.4, 0.5, 0.6], 0.5)
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining_for_next) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins with balanced utilization
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5], 0.4)
        utilization_threshold_low = tunable([0.2, 0.3, 0.4], 0.2)
        utilization_threshold_high = tunable([0.7, 0.8, 0.9], 0.8)
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining capacities
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4], -0.3)
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3], -0.2) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 53
-------------------


................................................................
launch 1 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 1.0; measure cnt: 1
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Use sigmoid function for spatial fit
        spatial_fit_slope = tunable([10, 20])
        spatial_fit_midpoint = tunable([0.7, 0.5])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        # Use sigmoid function for future potential
        future_potential_slope = tunable([10, 20])
        future_potential = 1 / (1 + np.exp(-future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = tunable([0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Bin similarity penalty: Penalize increasing variance of remaining capacities
        current_remaining = bins[valid_bins]
        new_remaining = current_remaining - item
        current_variance = np.var(current_remaining)
        new_variance = np.var(new_remaining)
        var_change = new_variance - current_variance
        bin_similarity_weight = tunable([-0.3, -0.4])
        bin_similarity_penalty = bin_similarity_weight * var_change

        # Combine components with tunable weights
        spatial_fit_weight = tunable([0.6, 0.7])
        future_potential_weight = tunable([0.5, 0.6])
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            bin_similarity_penalty
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 54
-------------------


.
launch 64 evaluate tasks
this best socre: -213.2; best score: -213.2; global score: -208.1; space size: 2048; measure cnt: 64
.......
launch 64 evaluate tasks
this best socre: -212.8; best score: -212.8; global score: -208.1; space size: 2048; measure cnt: 128
.......
launch 64 evaluate tasks
this best socre: -212.25; best score: -212.25; global score: -208.1; space size: 2048; measure cnt: 192
......
launch 64 evaluate tasks
this best socre: -212.25; best score: -212.25; global score: -208.1; space size: 2048; measure cnt: 256
.............
launch 64 evaluate tasks
this best socre: -211.85; best score: -211.85; global score: -208.1; space size: 2048; measure cnt: 320
...........
launch 64 evaluate tasks
this best socre: -211.85; best score: -211.85; global score: -208.1; space size: 2048; measure cnt: 384
....................
launch 64 evaluate tasks
this best socre: -211.85; best score: -211.85; global score: -208.1; space size: 2048; measure cnt: 448
.............
launch 64 evaluate tasks
this best socre: -211.85; best score: -211.85; global score: -208.1; space size: 2048; measure cnt: 512
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        ideal_fit_ratio = tunable([0.6, 0.7, 0.8])
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        spatial_fit_slope = tunable([8, 10, 12])
        
        # Use a Gaussian-like function for spatial fit to prefer a specific fit ratio
        spatial_fit = np.exp(
            -spatial_fit_slope * (fit_ratio - ideal_fit_ratio)**2
        )
        
        # Future potential component: Reward bins with remaining space that matches ideal distribution
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        # Use a smooth transition function for future potential
        future_potential_weight = tunable([0.3, 0.4, 0.5])
        future_potential = np.exp(
            -10 * np.abs((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        )
        
        # Lookahead analysis: Simulate placing the item and assess future impact
        lookahead_depth = tunable([2, 3, 4])
        simulated_bins = bins[valid_bins] - item
        future_items = np.random.exponential(
            scale=item / 2,
            size=(lookahead_depth, len(simulated_bins))
        )
        
        # Calculate how well future items fit into the remaining space
        future_fit = np.mean(
            np.clip(future_items / simulated_bins.reshape(1, -1), 0, 1),
            axis=0
        )
        lookahead_weight = tunable([0.2, 0.3, 0.4])
        
        # Item size distribution analysis: Adjust priorities based on typical item sizes
        item_size_quantile = tunable([0.5, 0.6, 0.7])
        sorted_items = np.sort(bins)
        typical_item_size = np.quantile(sorted_items, item_size_quantile)
        distribution_weight = tunable([0.1, 0.2, 0.3])
        
        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            lookahead_weight * future_fit +
            distribution_weight * (typical_item_size / (bins[valid_bins] + 1e-8))
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.3, -0.2, -0.1]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 55
-------------------



launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 59049; measure cnt: 64

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 59049; measure cnt: 128

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 59049; measure cnt: 192
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Component 1: Spatial Fit (How well the item fits in the bin)
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Tunable parameters for spatial fit
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        spatial_fit_slope = tunable([8, 10, 12])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Component 2: Future Packing Potential
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        # Tunable parameters for future potential
        future_potential_weight = tunable([0.4, 0.5, 0.6])
        future_potential_slope = tunable([8, 10, 12])
        
        future_potential = 1 / (1 + np.exp(-future_potential_slope * 
                                          ((remaining_after - ideal_remaining) / 
                                           (bins[valid_bins] + 1e-8))))

        # Component 3: Bin Utilization Balance
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        
        # Tunable parameters for utilization balance
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.25, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & 
            (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Component 4: Distribution Impact
        # Penalize creating bins with similar remaining space
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        
        # Tunable parameter for distribution impact
        distribution_impact_weight = tunable([-0.2, -0.25, -0.3])
        
        distribution_impact = new_variance - current_variance

        # Dynamic weight adjustment based on bin state
        avg_fill = np.mean(1.0 - (remaining_capacity[valid_bins] / 
                                 (bins[valid_bins] + 1e-8)))
        
        # Tunable dynamic weight functions
        weight_spatial = tunable([0.5, 0.6, 0.7]) * (1.0 - avg_fill)
        weight_future = tunable([0.5, 0.6, 0.7]) * avg_fill
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight

        # Combine components with tunable weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Component 5: Bin Count Penalty (Tunable)
        num_bins_penalty = tunable([-0.1, -0.15, -0.2]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 56
-------------------



launch 64 evaluate tasks
this best socre: -212.05; best score: -212.05; global score: -208.1; space size: 1594323; measure cnt: 64
.
launch 64 evaluate tasks
this best socre: -212.05; best score: -212.05; global score: -208.1; space size: 1594323; measure cnt: 128
..
launch 64 evaluate tasks
this best socre: -212.05; best score: -212.05; global score: -208.1; space size: 1594323; measure cnt: 192
.
launch 64 evaluate tasks
this best socre: -212.05; best score: -212.05; global score: -208.1; space size: 1594323; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        valid_bins_mask = valid_bins
        valid_bins_indices = np.where(valid_bins_mask)[0]

        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.5, 0.6, 0.7])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.2, 0.3, 0.4])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.4, 0.5, 0.6])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Utilization bonus component: Reward bins with balanced utilization
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining space
        distribution_impact_weight = tunable([-0.2, -0.3])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = (new_variance - current_variance) * distribution_impact_weight

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities to maintain balance
        if np.max(total_priority) != 0:
            total_priority = total_priority / np.max(total_priority)

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 57
-------------------



launch 64 evaluate tasks
this best socre: -213.35; best score: -213.35; global score: -208.1; space size: 11664; measure cnt: 64
..
launch 64 evaluate tasks
this best socre: -213.35; best score: -213.35; global score: -208.1; space size: 11664; measure cnt: 128
.
launch 64 evaluate tasks
this best socre: -211.25; best score: -211.25; global score: -208.1; space size: 11664; measure cnt: 192
....
launch 64 evaluate tasks
this best socre: -211.25; best score: -211.25; global score: -208.1; space size: 11664; measure cnt: 256
.....
launch 64 evaluate tasks
this best socre: -211.25; best score: -211.25; global score: -208.1; space size: 11664; measure cnt: 320
.........
launch 64 evaluate tasks
this best socre: -211.25; best score: -211.25; global score: -208.1; space size: 11664; measure cnt: 384
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.7, 0.75, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component
        ideal_remaining_fraction = tunable([0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6])
        future_potential_slope = tunable([10, 15])
        future_potential_midpoint = tunable([0.3, 0.4])
        future_potential = 1 / (1 + np.exp(-future_potential_slope * 
                                           ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8) - future_potential_midpoint)))

        # Utilization bonus component
        utilization_bonus_weight = tunable([0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component
        distribution_impact_weight = tunable([-0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 58
-------------------



launch 64 evaluate tasks
this best socre: -218.45; best score: -218.45; global score: -208.1; space size: 13824; measure cnt: 64
...................................................
launch 64 evaluate tasks
this best socre: -218.45; best score: -218.45; global score: -208.1; space size: 13824; measure cnt: 128
...................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -218.45; best score: -218.45; global score: -208.1; space size: 13824; measure cnt: 192
.............................................................................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -218.45; best score: -218.45; global score: -208.1; space size: 13824; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward well-utilized bins
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize similar bins
        distribution_impact_weight = tunable([-0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Fragmentation penalty: Penalize bins leaving too little space
        fragmentation_penalty_weight = tunable([-0.1, -0.2])
        fragmentation_threshold = tunable([0.1, 0.2])
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact +
            fragmentation_penalty_weight * fragmentation_penalty
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 59
-------------------



launch 64 evaluate tasks
this best socre: -209.75; best score: -209.75; global score: -208.1; space size: 46656; measure cnt: 64
..
launch 64 evaluate tasks
this best socre: -209.75; best score: -209.75; global score: -208.1; space size: 46656; measure cnt: 128
.
launch 64 evaluate tasks
this best socre: -209.75; best score: -209.75; global score: -208.1; space size: 46656; measure cnt: 192
.
launch 64 evaluate tasks
this best socre: -209.35; best score: -209.35; global score: -208.1; space size: 46656; measure cnt: 256
.
launch 64 evaluate tasks
this best socre: -209.35; best score: -209.35; global score: -208.1; space size: 46656; measure cnt: 320

launch 64 evaluate tasks
this best socre: -209.35; best score: -209.35; global score: -208.1; space size: 46656; measure cnt: 384

launch 64 evaluate tasks
this best socre: -209.35; best score: -209.35; global score: -208.1; space size: 46656; measure cnt: 448
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.3, 0.4, 0.5])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.4, 0.5, 0.6])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.2, -0.3])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Lookahead component: Simulate next step to evaluate future efficiency
        lookahead_depth = tunable([1, 2, 3])
        future_items_size = tunable([0.3, 0.4, 0.5])  # Average size of future items
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = tunable([0.2, 0.3])

        # Dynamic weights adjustment based on current bin state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / np.max(bins)) if np.max(bins) != 0 else spatial_fit_weight
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 60
-------------------



launch 64 evaluate tasks
this best socre: -211.75; best score: -211.75; global score: -208.1; space size: 209952; measure cnt: 64

launch 64 evaluate tasks
this best socre: -210.1; best score: -210.1; global score: -208.1; space size: 209952; measure cnt: 128
.
launch 64 evaluate tasks
this best socre: -210.1; best score: -210.1; global score: -208.1; space size: 209952; measure cnt: 192
.
launch 64 evaluate tasks
this best socre: -210.1; best score: -210.1; global score: -208.1; space size: 209952; measure cnt: 256
.
launch 64 evaluate tasks
this best socre: -210.1; best score: -210.1; global score: -208.1; space size: 209952; measure cnt: 320
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with innovative strategies and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        valid = valid_bins
        bins_valid = bins[valid]
        remaining = remaining_capacity[valid]

        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins_valid + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins_valid
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining - ideal_remaining) / (bins_valid + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining / (bins_valid + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.3, -0.4])
        scaled_remaining = remaining / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic load balancing component: Prefer bins that help balance the load
        load_balance_weight = tunable([0.3, 0.4])
        current_loads = bins - remaining_capacity
        avg_load = np.mean(current_loads)
        load_diff = np.abs(current_loads[valid] - avg_load)
        load_balance = 1 / (1 + np.exp(-5 * (avg_load - load_diff)))

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact +
            load_balance_weight * load_balance
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities to [0, 1] range
        if len(total_priority) > 0:
            max_p = np.max(total_priority)
            min_p = np.min(total_priority)
            if max_p != min_p:
                total_priority = (total_priority - min_p) / (max_p - min_p)
            else:
                total_priority = np.zeros_like(total_priority)

        priorities[valid] = total_priority

    return priorities

call llm times: 61
-------------------



launch 64 evaluate tasks
this best socre: -214.8; best score: -214.8; global score: -208.1; space size: 23328; measure cnt: 64
.........................................
launch 64 evaluate tasks
this best socre: -214.8; best score: -214.8; global score: -208.1; space size: 23328; measure cnt: 128
.........................................
launch 64 evaluate tasks
this best socre: -214.8; best score: -214.8; global score: -208.1; space size: 23328; measure cnt: 192
....................................................................................................
launch 64 evaluate tasks
this best socre: -214.8; best score: -214.8; global score: -208.1; space size: 23328; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        spatial_fit_slope = tunable([8, 10, 12])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        # Enhanced future potential considering adaptability
        adaptability_mean = tunable([0.5, 0.6, 0.7])  # Typical item size relative to bin capacity
        adaptability_std = tunable([0.1, 0.2, 0.3])
        adaptability_score = np.exp(-((remaining_after / bins[valid_bins] - adaptability_mean) ** 2) / (2 * adaptability_std ** 2))
        
        future_potential_weight = tunable([0.3, 0.4, 0.5])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8)))) * adaptability_score

        # Utilization bonus component: Reward well-utilized bins
        utilization_bonus_weight = tunable([0.2, 0.3, 0.4])
        utilization_threshold_low = tunable([0.1, 0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Diversity impact component: Penalize reducing diversity of remaining capacities
        diversity_impact_weight = tunable([-0.2, -0.3, -0.4])
        current_remaining = remaining_capacity[valid_bins]
        current_scaled = current_remaining / (np.max(bins) + 1e-8)
        current_diversity = -np.sum(current_scaled * np.log(current_scaled + 1e-8))  # Entropy-based diversity
        
        new_remaining = current_remaining - item
        new_scaled = new_remaining / (np.max(bins) + 1e-8)
        new_diversity = -np.sum(new_scaled * np.log(new_scaled + 1e-8))
        diversity_impact = new_diversity - current_diversity

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            diversity_impact_weight * diversity_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 62
-------------------



launch 64 evaluate tasks
this best socre: -212.3; best score: -212.3; global score: -208.1; space size: 531441; measure cnt: 64

launch 64 evaluate tasks
this best socre: -212.3; best score: -212.3; global score: -208.1; space size: 531441; measure cnt: 128

launch 64 evaluate tasks
this best socre: -212.3; best score: -212.3; global score: -208.1; space size: 531441; measure cnt: 192

launch 64 evaluate tasks
this best socre: -212.3; best score: -212.3; global score: -208.1; space size: 531441; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategies and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        valid_remaining = remaining_capacity[valid_bins]
        valid_bins_count = len(valid_remaining)

        # Spatial fit component: Reward bins where the item fits well
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.7, 0.75, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((valid_remaining - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Utilization balance component: Reward bins with balanced utilization
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.25, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        utilization = 1.0 - (valid_remaining / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating similar remaining spaces
        distribution_impact_weight = tunable([-0.3, -0.25, -0.2])
        scaled_remaining = valid_remaining / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic weights based on current bin state
        avg_fill = np.mean(1.0 - (valid_remaining / (bins[valid_bins] + 1e-8)))
        weight_spatial = tunable([0.6, 0.7]) * (1.0 - avg_fill)
        weight_future = tunable([0.7, 0.8]) * avg_fill
        weight_utilization = tunable([0.5, 0.6])
        weight_distribution = distribution_impact_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Look-ahead mechanism: Simulate placing the item and assess future impact
        look_ahead_depth = tunable([2, 3, 4])
        for _ in range(look_ahead_depth):
            # Simulate next item (for demonstration, using the same item)
            next_item = item
            next_remaining = valid_remaining - next_item
            valid_next_bins = next_remaining >= 0
            if np.any(valid_next_bins):
                next_priority = (
                    weight_spatial * (next_item / (bins[valid_bins][valid_next_bins] + 1e-8)) +
                    weight_future * (1 / (1 + np.exp(-10 * ((next_remaining[valid_next_bins] - ideal_remaining[valid_next_bins]) / (bins[valid_bins][valid_next_bins] + 1e-8)))))
                )
                total_priority[valid_next_bins] += tunable([0.1, 0.15, 0.2]) * next_priority

        # Diversity bonus: Penalize similar remaining capacities
        diversity_bonus_weight = tunable([0.1, 0.15, 0.2])
        similarity = np.abs(valid_remaining - np.mean(valid_remaining))
        diversity_bonus = 1.0 / (1.0 + np.exp(-10 * (similarity - tunable([0.1, 0.2, 0.3]))))
        total_priority += diversity_bonus_weight * diversity_bonus

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.25, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 63
-------------------



launch 64 evaluate tasks
this best socre: -215.5; best score: -215.5; global score: -208.1; space size: 38263752; measure cnt: 64

launch 64 evaluate tasks
this best socre: -214.3; best score: -214.3; global score: -208.1; space size: 38263752; measure cnt: 128

launch 64 evaluate tasks
this best socre: -214.3; best score: -214.3; global score: -208.1; space size: 38263752; measure cnt: 192

launch 64 evaluate tasks
this best socre: -214.3; best score: -214.3; global score: -208.1; space size: 38263752; measure cnt: 256

launch 64 evaluate tasks
this best socre: -213.95; best score: -213.95; global score: -208.1; space size: 38263752; measure cnt: 320

launch 64 evaluate tasks
this best socre: -213.95; best score: -213.95; global score: -208.1; space size: 38263752; measure cnt: 384

launch 64 evaluate tasks
this best socre: -213.55; best score: -213.55; global score: -208.1; space size: 38263752; measure cnt: 448

launch 64 evaluate tasks
this best socre: -213.55; best score: -213.55; global score: -208.1; space size: 38263752; measure cnt: 512

launch 64 evaluate tasks
this best socre: -213.55; best score: -213.55; global score: -208.1; space size: 38263752; measure cnt: 576

launch 64 evaluate tasks
this best socre: -213.55; best score: -213.55; global score: -208.1; space size: 38263752; measure cnt: 640
sampler suggest should end sample, break
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function for online bin-packing considering spatial fit, future potential, bin similarity, and dynamic load balancing."""
    remaining = bins - item
    valid = remaining >= 0
    
    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf
    
    if np.any(valid):
        # Spatial fit component
        fill_ratio = item / (bins[valid] + 1e-6)
        space_utilization = 1 - (remaining[valid] / (bins[valid] + 1e-6))
        spatial_fit = (fill_ratio + space_utilization) / 2
        
        # Future potential component
        ideal_remaining = 0.2 * bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining[valid] - ideal_remaining) / bins[valid])))
        
        # Bin similarity component
        avg_remaining = np.mean(remaining[valid])
        similarity_score = np.exp(-1.0 * np.abs(remaining[valid] - avg_remaining) / (np.max(bins) + 1e-6))
        
        # Diversity score component
        diversity_weight = 0.2
        diversity_score = 1 / (1 + np.exp(-1.5 * (len(bins) - np.count_nonzero(valid))))
        
        # Dynamic load balancing component
        current_loads = bins - remaining
        avg_load = np.mean(current_loads)
        load_diff = np.abs(current_loads[valid] - avg_load)
        load_balance = 1 / (1 + np.exp(-5 * (avg_load - load_diff)))
        
        # Combine components with tunable weights
        weight_spatial = 0.7
        weight_future = 0.4
        weight_similarity = 0.2
        weight_diversity = 0.15
        weight_balance = 0.2
        
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity_score +
            weight_diversity * diversity_score +
            weight_balance * load_balance
        )
        
        # Apply penalties for bins that are too full or too empty
        fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
        total_priority += fullness_penalty
        
        priorities[valid] = total_priority
    
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 15
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.7
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward well-utilized bins
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.7
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize similar bins
        distribution_impact_weight = -0.4
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Fragmentation penalty: Penalize bins leaving too little space
        fragmentation_penalty_weight = -0.2
        fragmentation_threshold = 0.2
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact +
            fragmentation_penalty_weight * fragmentation_penalty
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

request...-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.8
        spatial_fit_slope = 15
        spatial_fit_midpoint = 0.6
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.7
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential_slope = 15
        future_potential = 1 / (1 + np.exp(-future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.3
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.3
        utilization_threshold_low = 0.1
        utilization_threshold_high = 0.7
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.1 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Returns priority with which we want to add item to each bin, 
    considering both spatial fit and future packing potential.
    
    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.
        
    Return:
        Array of same size as bins with priority score of each bin.
    """
    # Identify bins that can fit the item
    can_fit = bins >= item
    # Initialize priority array with -inf for bins that cannot fit the item
    priorities = np.full_like(bins, -np.inf, dtype=np.float64)
    
    if np.any(can_fit):
        # Calculate spatial fit component
        ratio = item / bins[can_fit]
        spatial_fit = ratio * (1 - ratio)
        
        # Calculate future potential component
        remaining_ratio = (bins[can_fit] - item) / bins[can_fit]
        decay_rate = 1.0  # Tunable decay rate
        future_potential = remaining_ratio * np.exp(-decay_rate * remaining_ratio)
        
        # Combine components with tunable weights
        weight_spatial = 0.9  # Tunable weight for spatial fit
        weight_future = 0.3    # Tunable weight for future potential
        
        combined_priority = weight_spatial * spatial_fit + weight_future * future_potential
        priorities[can_fit] = combined_priority
    
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf

    if np.any(valid):
        # Spatial fit component
        fit_ratio = item / (bins[valid] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        avg_remaining = np.mean(remaining[valid])
        ideal_remaining = 0.2 * bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining[valid] - ideal_remaining) / bins[valid])))

        # Bin similarity component
        avg_load = np.mean(bins - remaining)
        similarity = np.exp(-1.5 * np.abs(fit_ratio - avg_load / bins[valid]))

        # Diversity component
        remaining_scaled = remaining[valid] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Dynamic weights based on current bin state
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.2
        weight_diversity = 0.3

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity
        )

        # Penalty for bins that are too full or too empty
        fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fit_ratio - 0.5))
        total_priority += fullness_penalty

        priorities[valid] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 20
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.3
        utilization_threshold_high = 0.7
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.2
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Lookahead component: Simulate next step to evaluate future efficiency
        lookahead_depth = 1
        future_items_size = 0.3  # Average size of future items
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current bin state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / np.max(bins)) if np.max(bins) != 0 else spatial_fit_weight
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

request...-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_slope = 30
        spatial_fit_midpoint = 0.6
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_slope = 10
        future_midpoint = 0.3
        future_potential = 1 / (1 + np.exp(-future_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8) - future_midpoint)))

        # Utilization bonus component
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        util_slope = 10
        util_midpoint = 0.5
        utilization_bonus = 1 / (1 + np.exp(-util_slope * (utilization - util_midpoint)))

        # Distribution impact component (using entropy)
        def compute_entropy(capacities):
            if len(capacities) == 0:
                return 0.0
            capacities = capacities / np.sum(capacities)
            capacities = np.clip(capacities, 1e-10, 1.0)
            return -np.sum(capacities * np.log(capacities))

        entropy_before = compute_entropy(remaining_capacity[valid_bins])
        distribution_impact = np.zeros_like(remaining_after)
        for i in range(len(remaining_after)):
            new_remaining = remaining_capacity.copy()
            new_remaining[i] = remaining_after[i]
            valid_new_remaining = new_remaining[valid_bins]
            entropy_after_i = compute_entropy(valid_new_remaining)
            distribution_impact[i] = entropy_after_i - entropy_before

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.5
        weight_util = 0.2
        weight_dist = 0.3

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_util * utilization_bonus +
            weight_dist * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, and distribution awareness."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    fit_ratio = item / (remaining_capacity + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.7)))
    spatial_fit[~valid_bins] = 0

    # Future potential component: Penalize bins with too little or too much remaining space
    ideal_remaining = 0.2  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-20 * (remaining_scaled - ideal_remaining)))
    future_potential[remaining_after < 0] = 0

    # Bin utilization bonus: Reward bins that are moderately filled
    utilization = 1.0 - (remaining_capacity / bins)
    utilization_bonus = np.exp(-0.2 * (utilization - 0.7) ** 2)

    # Fragmentation penalty: Penalize bins that leave too little usable space
    fragmentation_penalty = np.zeros_like(bins, dtype=np.float64)
    fragmentation_threshold = 0.1  # Minimum acceptable remaining space
    fragmentation_penalty[remaining_capacity < fragmentation_threshold] = 0.8

    # Distribution awareness component: Penalize bins with remaining capacity too high compared to others
    mean_remaining = np.mean(remaining_capacity[valid_bins])
    std_remaining = np.std(remaining_capacity[valid_bins])
    distribution_penalty = np.exp(-1.0 * ((remaining_capacity - mean_remaining) / (std_remaining + 1e-6)) ** 2)
    distribution_penalty[~valid_bins] = 0

    # Combine components with tunable weights
    weight_spatial = 0.7
    weight_future = 0.4
    weight_utilization = 0.3
    weight_fragmentation = 0.1
    weight_distribution = 0.2

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus -
        weight_fragmentation * fragmentation_penalty -
        weight_distribution * distribution_penalty
    )

    # Ensure invalid bins have the lowest priority
    priorities[~valid_bins] = -np.inf

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Get valid remaining capacities
        valid_bins_cap = bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]

        # 1. Spatial fit component
        fit_ratio = item / (valid_bins_cap + 1e-8)
        
        # Adaptive spatial fit based on item size distribution
        avg_item_size = tunable([np.mean(bins), 0.5*np.mean(bins), 1.5*np.mean(bins)])
        adaptive_fit_weight = tunable([0.6, 0.7, 0.8])
        
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        
        spatial_fit = 1 / (1 + np.exp(
            -spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)
        ))

        # 2. Future potential component with adaptive ideal remaining
        # Dynamic ideal remaining fraction based on packing phase
        current_fill_ratio = 1.0 - (np.mean(remaining_after) / np.mean(valid_bins_cap))
        adaptive_ideal_fraction = tunable([
            0.5 + 0.5*current_fill_ratio,
            0.6 + 0.4*current_fill_ratio,
            0.7 + 0.3*current_fill_ratio
        ])
        
        ideal_remaining = adaptive_ideal_fraction * valid_bins_cap
        future_potential = 1 / (1 + np.exp(
            -10 * ((remaining_after - ideal_remaining) / (valid_bins_cap + 1e-8))
        ))

        # 3. Bin utilization bonus with hysteresis
        utilization = 1.0 - (remaining_after / (valid_bins_cap + 1e-8))
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & 
            (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # 4. Diversity bonus to maintain spread of bin capacities
        # Scale remaining capacities to [0,1]
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        # Calculate pairwise differences
        diversity_scores = np.zeros_like(scaled_remaining)
        for i in range(len(scaled_remaining)):
            diff = np.abs(scaled_remaining[i] - scaled_remaining)
            diversity_scores[i] = np.mean(diff)
        
        diversity_bonus = diversity_scores / (np.max(diversity_scores) + 1e-8)
        diversity_bonus_weight = tunable([0.3, 0.4, 0.5])

        # 5. Distribution impact component
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance
        distribution_impact_weight = tunable([-0.3, -0.4, -0.5])

        # Combine components with tunable weights
        total_priority = (
            adaptive_fit_weight * spatial_fit +
            future_potential * 0.5 +
            utilization_bonus * 0.4 +
            diversity_bonus_weight * diversity_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 64
-------------------



current thread_i 1
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 19683; measure cnt: 64

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 19683; measure cnt: 128
.
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 19683; measure cnt: 192
sampler suggest should end sample, break
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with adaptive strategies."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_weight_base = 0.6
        spatial_slope = 15
        spatial_midpoint = 0.5
        spatial_fit = 1 / (1 + np.exp(-spatial_slope * (fit_ratio - spatial_midpoint)))
        spatial_weight = spatial_weight_base * (1 + np.exp(-10 * np.abs(fit_ratio - 0.5)))

        # Future potential component
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        ideal_remaining = 0.2 * bins[valid_bins]
        future_slope = 20
        future_potential = 1 / (1 + np.exp(-future_slope * ((remaining_capacity[valid_bins] - ideal_remaining) / (bins[valid_bins] + 1e-6))))

        # Dynamic weight adjustment based on system state
        system_load = np.mean(bins)
        if system_load > 0.7:
            future_weight = 0.7
        else:
            future_weight = 0.3
        
        # Bin similarity component
        similarity_weight = 0.1
        similarity_slope = 10
        similarity = 1 / (1 + np.exp(-similarity_slope * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component
        diversity_weight = 0.2
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity = 1 / (1 + np.exp(-10 * (1 - np.var(scaled_remaining))))

        # Combine components with dynamic weights
        total_priority = (
            spatial_weight * spatial_fit +
            future_weight * future_potential -
            similarity_weight * similarity -
            diversity_weight * diversity
        )

        # Apply normalization if needed
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic ideal remaining space based on item size
        ideal_remaining_fraction = tunable(
            [0.5, 0.7, 0.3],  # Fixed options
            value=0.5 + 0.2 * (1 - item / np.max(bins))  # Dynamic calculation
        )
        
        # Calculate remaining space after placing the item
        remaining_after = remaining_capacity[valid_bins]
        
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.5], value=0.6)
        spatial_fit_slope = tunable([10, 15, 20], value=10)
        spatial_fit_midpoint = tunable([0.7, 0.8, 0.6], value=0.7)
        
        spatial_fit = 1 / (1 + np.exp(
            -spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)
        ))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.4], value=0.5)
        
        # Use percentile-based target instead of fixed difference
        target_remaining = np.percentile(remaining_after, 50)
        future_potential = 1 / (1 + np.exp(
            -10 * ((remaining_after - target_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = tunable([0.4, 0.5, 0.3], value=0.4)
        utilization_threshold_low = tunable([0.2, 0.3], value=0.2)
        utilization_threshold_high = tunable([0.7, 0.8], value=0.7)
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating similar bins
        distribution_impact_weight = tunable([-0.3, -0.4, -0.2], value=-0.3)
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Fragmentation penalty: Penalize bins leaving too little space
        fragmentation_penalty_weight = tunable([-0.2, -0.1, -0.3], value=-0.2)
        fragmentation_threshold = tunable([0.2, 0.3], value=0.2)
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact +
            fragmentation_penalty_weight * fragmentation_penalty
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.1], value=-0.2) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 65
-------------------


................................................................
launch 1 evaluate tasks
current thread_i 5
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 1.0; measure cnt: 1
sampler suggest should end sample, break
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Component 1: Spatial Fit (How well the item fits in the bin)
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Tunable parameters for spatial fit
        spatial_fit_weight = 0.7
        spatial_fit_slope = 12
        spatial_fit_midpoint = 0.6
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Component 2: Future Packing Potential
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        # Tunable parameters for future potential
        future_potential_weight = 0.6
        future_potential_slope = 10
        
        future_potential = 1 / (1 + np.exp(-future_potential_slope * 
                                          ((remaining_after - ideal_remaining) / 
                                           (bins[valid_bins] + 1e-8))))

        # Component 3: Bin Utilization Balance
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        
        # Tunable parameters for utilization balance
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.3
        utilization_threshold_high = 0.7
        
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & 
            (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Component 4: Distribution Impact
        # Penalize creating bins with similar remaining space
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        
        # Tunable parameter for distribution impact
        distribution_impact_weight = -0.2
        
        distribution_impact = new_variance - current_variance

        # Dynamic weight adjustment based on bin state
        avg_fill = np.mean(1.0 - (remaining_capacity[valid_bins] / 
                                 (bins[valid_bins] + 1e-8)))
        
        # Tunable dynamic weight functions
        weight_spatial = 0.6 * (1.0 - avg_fill)
        weight_future = 0.7 * avg_fill
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight

        # Combine components with tunable weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Component 5: Bin Count Penalty (Tunable)
        num_bins_penalty = -0.15 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fill_ratio = item / (bins[valid_bins] + 1e-8)
        space_utilization = 1 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8))
        spatial_fit = (fill_ratio + space_utilization) / 2
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_capacity[valid_bins] - ideal_remaining) / (bins[valid_bins] + 1e-8))))
        future_potential_weight = tunable([0.4, 0.5])

        # Bin congestion component: Penalize bins that are too full or too empty
        congestion_threshold_low = tunable([0.2, 0.3])
        congestion_threshold_high = tunable([0.8, 0.9])
        congestion_penalty = np.where(
            (space_utilization < congestion_threshold_low) | (space_utilization > congestion_threshold_high),
            tunable([-0.3, -0.4]),
            0.0
        )
        congestion_weight = tunable([0.3, 0.4])

        # Load balancing component: Distribute items evenly
        current_loads = bins - remaining_capacity
        avg_load = np.mean(current_loads)
        load_diff = np.abs(current_loads[valid_bins] - avg_load)
        load_balance = 1 / (1 + np.exp(-5 * (avg_load - load_diff)))
        load_balance_weight = tunable([0.2, 0.3])

        # Item size context component: Consider relative size of the item
        item_size_weight = tunable([0.1, 0.15])
        avg_item_size = np.mean([item] + list(bins))  # Simplified context
        size_context = 1 / (1 + np.exp(-2 * (item / avg_item_size - 0.5)))

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            congestion_weight * congestion_penalty +
            load_balance_weight * load_balance +
            item_size_weight * size_context
        )

        # Apply overall normalization
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 66
-------------------


current thread_i 8
....
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 768; measure cnt: 64
......
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 768; measure cnt: 128
...................
launch 64 evaluate tasks
current thread_i 7
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 768; measure cnt: 192
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_slope = tunable([10, 20, 30])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component
        ideal_remaining_fraction = tunable([0.3, 0.5, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_slope = tunable([5, 10, 15])
        future_potential = 1 / (1 + np.exp(-future_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Utilization bonus component
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        util_slope = tunable([5, 10, 15])
        util_midpoint = tunable([0.4, 0.5, 0.6])
        utilization_bonus = 1 / (1 + np.exp(-util_slope * (utilization - util_midpoint)))

        # Distribution impact component
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Bin similarity component
        similarity_penalty = 0.0
        if len(scaled_remaining) > 1:
            similarity = np.mean(np.abs(scaled_remaining - np.mean(scaled_remaining)))
            similarity_penalty = -similarity

        # Combine components with tunable weights
        weight_spatial = tunable([0.5, 0.6, 0.7])
        weight_future = tunable([0.4, 0.5, 0.6])
        weight_util = tunable([0.3, 0.4, 0.5])
        weight_dist = tunable([-0.2, -0.3, -0.4])
        weight_similarity = tunable([-0.1, -0.2, -0.3])

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_util * utilization_bonus +
            weight_dist * distribution_impact +
            weight_similarity * similarity_penalty
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 67
-------------------



launch 64 evaluate tasks
current thread_i 4
current thread_i 2
current thread_i 0
current thread_i 6
current thread_i 9
this best socre: -236.6; best score: -236.6; global score: -208.1; space size: 531441; measure cnt: 64
..........................................................................................................................................................................................................................................................................................................................................................current thread_i 5
...........................................................................................................................................................................................................................................................................................
launch 44 evaluate tasks
this best socre: -236.6; best score: -236.6; global score: -208.1; space size: 531441; measure cnt: 108
........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
launch 17 evaluate tasks
current thread_i 1
this best socre: -236.6; best score: -236.6; global score: -208.1; space size: 531441; measure cnt: 125
.............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
launch 33 evaluate tasks
this best socre: -236.6; best score: -236.6; global score: -208.1; space size: 531441; measure cnt: 158
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        spatial_fit_slope = tunable([8, 10, 12])
        spatial_fit_midpoint = tunable([0.7, 0.8, 0.9])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        # Dynamic ideal remaining fraction based on item size relative to average bin
        avg_bin = np.mean(bins) if len(bins) > 0 else 1.0
        item_rel_size = item / avg_bin
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.4, 0.5, 0.6])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Enhanced future potential considering item size impact
        future_potential = future_potential * (1 + tunable([0.0, 0.1, 0.2]) * item_rel_size)

        # Utilization bonus component: Reward well-utilized bins
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins using entropy
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_entropy = -np.sum(scaled_remaining * np.log(scaled_remaining + 1e-8)) / np.log(len(scaled_remaining))
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_entropy = -np.sum(new_remaining * np.log(new_remaining + 1e-8)) / np.log(len(new_remaining))
        distribution_impact = new_entropy - current_entropy

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins with tunable factor
        num_bins_penalty = tunable([-0.1, -0.15, -0.2]) * len(bins)
        total_priority += num_bins_penalty

        # Adaptive normalization based on current state
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 68
-------------------



launch 64 evaluate tasks
this best socre: -212.45; best score: -212.45; global score: -208.1; space size: 177147; measure cnt: 64

launch 64 evaluate tasks
this best socre: -212.45; best score: -212.45; global score: -208.1; space size: 177147; measure cnt: 128

launch 64 evaluate tasks
this best socre: -212.45; best score: -212.45; global score: -208.1; space size: 177147; measure cnt: 192

launch 64 evaluate tasks
this best socre: -212.45; best score: -212.45; global score: -208.1; space size: 177147; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.7, 0.75, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Lookahead component: Simulate next step to evaluate future efficiency
        lookahead_depth = tunable([1, 2, 3])
        future_items_size = tunable([0.3, 0.4, 0.5])  # Average size of future items
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = tunable([0.1, 0.2, 0.3])

        # Dynamic weights adjustment based on current bin state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 69
-------------------



launch 64 evaluate tasks
this best socre: -210.35; best score: -210.35; global score: -208.1; space size: 1594323; measure cnt: 64

launch 64 evaluate tasks
this best socre: -210.3; best score: -210.3; global score: -208.1; space size: 1594323; measure cnt: 128

launch 64 evaluate tasks
this best socre: -210.3; best score: -210.3; global score: -208.1; space size: 1594323; measure cnt: 192

launch 64 evaluate tasks
this best socre: -210.0; best score: -210.0; global score: -208.1; space size: 1594323; measure cnt: 256

launch 64 evaluate tasks
this best socre: -210.0; best score: -210.0; global score: -208.1; space size: 1594323; measure cnt: 320

launch 64 evaluate tasks
this best socre: -209.85; best score: -209.85; global score: -208.1; space size: 1594323; measure cnt: 384

launch 64 evaluate tasks
this best socre: -209.85; best score: -209.85; global score: -208.1; space size: 1594323; measure cnt: 448

launch 64 evaluate tasks
this best socre: -209.0; best score: -209.0; global score: -208.1; space size: 1594323; measure cnt: 512

launch 64 evaluate tasks
this best socre: -209.0; best score: -209.0; global score: -208.1; space size: 1594323; measure cnt: 576

launch 64 evaluate tasks
this best socre: -209.0; best score: -209.0; global score: -208.1; space size: 1594323; measure cnt: 640

launch 64 evaluate tasks
this best socre: -209.0; best score: -209.0; global score: -208.1; space size: 1594323; measure cnt: 704
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        spatial_fit_slope = tunable([5, 10, 15])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component
        ideal_remaining_fraction = tunable([0.3, 0.4, 0.5])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.3, 0.4, 0.5])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus
        utilization_bonus_weight = tunable([0.2, 0.3, 0.4])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component
        distribution_impact_weight = tunable([-0.1, -0.2, -0.3])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 70
-------------------



launch 64 evaluate tasks
this best socre: -213.6; best score: -213.6; global score: -208.1; space size: 26244; measure cnt: 64
...
launch 64 evaluate tasks
this best socre: -212.15; best score: -212.15; global score: -208.1; space size: 26244; measure cnt: 128
.........................
launch 64 evaluate tasks
this best socre: -212.15; best score: -212.15; global score: -208.1; space size: 26244; measure cnt: 192
.............
launch 64 evaluate tasks
this best socre: -211.45; best score: -211.45; global score: -208.1; space size: 26244; measure cnt: 256
................
launch 64 evaluate tasks
this best socre: -211.45; best score: -211.45; global score: -208.1; space size: 26244; measure cnt: 320
...........
launch 64 evaluate tasks
this best socre: -211.45; best score: -211.45; global score: -208.1; space size: 26244; measure cnt: 384
.....
launch 64 evaluate tasks
this best socre: -211.45; best score: -211.45; global score: -208.1; space size: 26244; measure cnt: 448
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Fragmentation penalty component: Penalize bins with too little remaining space
        fragmentation_penalty_weight = tunable([-0.1, -0.2])
        fragmentation_threshold = tunable([0.1, 0.2])
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact +
            fragmentation_penalty_weight * fragmentation_penalty
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities to [0, 1] range
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 71
-------------------



launch 64 evaluate tasks
this best socre: -210.15; best score: -210.15; global score: -208.1; space size: 69984; measure cnt: 64
.
launch 64 evaluate tasks
this best socre: -210.15; best score: -210.15; global score: -208.1; space size: 69984; measure cnt: 128

launch 64 evaluate tasks
this best socre: -210.15; best score: -210.15; global score: -208.1; space size: 69984; measure cnt: 192

launch 64 evaluate tasks
this best socre: -210.15; best score: -210.15; global score: -208.1; space size: 69984; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        valid = valid_bins
        # Spatial fit component
        fit_ratio = item / (bins[valid] + 1e-8)
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component
        ideal_remaining_fraction = tunable([0.3, 0.4, 0.5])
        ideal_remaining = ideal_remaining_fraction * bins[valid]
        future_potential_slope = tunable([10, 15, 20])
        future_potential = 1 / (1 + np.exp(-future_potential_slope * ((remaining_capacity[valid] - ideal_remaining) / (bins[valid] + 1e-8))))

        # Utilization bonus
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_capacity[valid] / (bins[valid] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            utilization_bonus_weight,
            0.0
        )

        # Distribution impact component
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_capacity[valid] / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = distribution_impact_weight * (new_variance - current_variance)

        # Dynamic weights based on current bin state
        avg_remaining = np.mean(remaining_capacity[valid])
        weight_spatial = tunable([0.6, 0.7]) if avg_remaining < tunable([0.4, 0.5]) else tunable([0.5, 0.6])
        weight_future = tunable([0.4, 0.5]) if avg_remaining < tunable([0.4, 0.5]) else tunable([0.6, 0.7])

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            utilization_bonus +
            distribution_impact
        )

        # Penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid] = total_priority

    return priorities

call llm times: 72
-------------------



launch 64 evaluate tasks
this best socre: -211.2; best score: -211.2; global score: -208.1; space size: 373248; measure cnt: 64

launch 64 evaluate tasks
this best socre: -210.75; best score: -210.75; global score: -208.1; space size: 373248; measure cnt: 128

launch 64 evaluate tasks
this best socre: -210.75; best score: -210.75; global score: -208.1; space size: 373248; measure cnt: 192

launch 64 evaluate tasks
this best socre: -210.75; best score: -210.75; global score: -208.1; space size: 373248; measure cnt: 256

launch 64 evaluate tasks
this best socre: -209.7; best score: -209.7; global score: -208.1; space size: 373248; measure cnt: 320

launch 64 evaluate tasks
this best socre: -209.65; best score: -209.65; global score: -208.1; space size: 373248; measure cnt: 384

launch 64 evaluate tasks
this best socre: -209.65; best score: -209.65; global score: -208.1; space size: 373248; measure cnt: 448

launch 64 evaluate tasks
this best socre: -209.65; best score: -209.65; global score: -208.1; space size: 373248; measure cnt: 512

launch 64 evaluate tasks
this best socre: -209.65; best score: -209.65; global score: -208.1; space size: 373248; measure cnt: 576
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial Fit Component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        spatial_fit_slope = tunable([8, 10, 12])
        spatial_fit_midpoint = tunable([0.5, 0.6, 0.7])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future Potential Component
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.4, 0.5, 0.6])
        future_potential_slope = tunable([8, 10, 12])
        future_potential = 1 / (1 + np.exp(-future_potential_slope * 
                                          ((remaining_after - ideal_remaining) / 
                                           (bins[valid_bins] + 1e-8))))

        # Utilization Bonus Component
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.6, 0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & 
            (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution Impact Component
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.15, -0.2, -0.25]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 73
-------------------



launch 64 evaluate tasks
this best socre: -211.6; best score: -211.6; global score: -208.1; space size: 177147; measure cnt: 64
.....
launch 64 evaluate tasks
this best socre: -211.6; best score: -211.6; global score: -208.1; space size: 177147; measure cnt: 128
...
launch 64 evaluate tasks
this best socre: -211.6; best score: -211.6; global score: -208.1; space size: 177147; measure cnt: 192

launch 64 evaluate tasks
this best socre: -211.6; best score: -211.6; global score: -208.1; space size: 177147; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating similar remaining capacities
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic weight adjustment based on system state
        system_load = np.mean(bins)
        if system_load > tunable([0.7, 0.8]):
            future_potential_weight *= tunable([1.5, 2.0])
            utilization_bonus_weight *= tunable([1.2, 1.5])
        else:
            spatial_fit_weight *= tunable([1.2, 1.5])

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 74
-------------------



launch 64 evaluate tasks
this best socre: -210.15; best score: -210.15; global score: -208.1; space size: 419904; measure cnt: 64
............
launch 64 evaluate tasks
this best socre: -210.15; best score: -210.15; global score: -208.1; space size: 419904; measure cnt: 128
..............
launch 64 evaluate tasks
this best socre: -210.15; best score: -210.15; global score: -208.1; space size: 419904; measure cnt: 192
...........
launch 64 evaluate tasks
this best socre: -209.9; best score: -209.9; global score: -208.1; space size: 419904; measure cnt: 256
...
launch 64 evaluate tasks
this best socre: -209.9; best score: -209.9; global score: -208.1; space size: 419904; measure cnt: 320
.....
launch 64 evaluate tasks
this best socre: -209.9; best score: -209.9; global score: -208.1; space size: 419904; measure cnt: 384
..
launch 64 evaluate tasks
this best socre: -209.9; best score: -209.9; global score: -208.1; space size: 419904; measure cnt: 448
sampler suggest should end sample, break
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.8
        spatial_fit_slope = 20
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.7
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Lookahead component: Simulate next step to evaluate future efficiency
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current bin state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.8
        spatial_fit_slope = 20
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.7
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Lookahead component: Simulate next step to evaluate future efficiency
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current bin state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with dynamic weights and adaptive parameters."""
    remaining = bins - item
    valid = remaining >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf

    if np.any(valid):
        # Spatial fit component
        fit_ratio = item / (bins[valid] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        avg_remaining = np.mean(remaining[valid])
        ideal_remaining = 0.1 * bins[valid]  # Adaptive ideal remaining space
        remaining_scaled = (remaining[valid] - ideal_remaining) / bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - -0.2)))

        # Bin similarity component
        avg_load = np.mean(bins[valid] - remaining[valid])
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load / bins[valid]))

        # Diversity component
        remaining_scaled_div = remaining[valid] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled_div))))

        # Dynamic weights based on current state
        avg_fill = np.mean((bins[valid] - remaining[valid]) / bins[valid])
        weight_spatial = 0.7 * (1 - avg_fill)
        weight_future = 0.4 * avg_fill
        weight_similarity = 0.2
        weight_diversity = 0.2

        # Penalty for imbalanced bins
        max_rem = np.max(remaining[valid])
        min_rem = np.min(remaining[valid])
        imbalance_penalty = 0.1 * (max_rem - min_rem) / np.mean(bins)

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            imbalance_penalty
        )

        priorities[valid] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.1
        weight_diversity = 0.2
        penalty = 0.05 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...request...

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        valid_bins_mask = valid_bins
        valid_bins_indices = np.where(valid_bins_mask)[0]

        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 15
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.3
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Utilization bonus component: Reward bins with balanced utilization
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.7
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining space
        distribution_impact_weight = -0.2
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = (new_variance - current_variance) * distribution_impact_weight

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities to maintain balance
        if np.max(total_priority) != 0:
            total_priority = total_priority / np.max(total_priority)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 20
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.3
        utilization_threshold_high = 0.7
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.2
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Lookahead component: Simulate next step to evaluate future efficiency
        lookahead_depth = 1
        future_items_size = 0.3  # Average size of future items
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current bin state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / np.max(bins)) if np.max(bins) != 0 else spatial_fit_weight
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, and distribution awareness."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    fit_ratio = item / (remaining_capacity + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.7)))
    spatial_fit[~valid_bins] = 0

    # Future potential component: Penalize bins with too little or too much remaining space
    ideal_remaining = 0.2  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-20 * (remaining_scaled - ideal_remaining)))
    future_potential[remaining_after < 0] = 0

    # Bin utilization bonus: Reward bins that are moderately filled
    utilization = 1.0 - (remaining_capacity / bins)
    utilization_bonus = np.exp(-0.2 * (utilization - 0.7) ** 2)

    # Fragmentation penalty: Penalize bins that leave too little usable space
    fragmentation_penalty = np.zeros_like(bins, dtype=np.float64)
    fragmentation_threshold = 0.1  # Minimum acceptable remaining space
    fragmentation_penalty[remaining_capacity < fragmentation_threshold] = 0.8

    # Distribution awareness component: Penalize bins with remaining capacity too high compared to others
    mean_remaining = np.mean(remaining_capacity[valid_bins])
    std_remaining = np.std(remaining_capacity[valid_bins])
    distribution_penalty = np.exp(-1.0 * ((remaining_capacity - mean_remaining) / (std_remaining + 1e-6)) ** 2)
    distribution_penalty[~valid_bins] = 0

    # Combine components with tunable weights
    weight_spatial = 0.7
    weight_future = 0.4
    weight_utilization = 0.3
    weight_fragmentation = 0.1
    weight_distribution = 0.2

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus -
        weight_fragmentation * fragmentation_penalty -
        weight_distribution * distribution_penalty
    )

    # Ensure invalid bins have the lowest priority
    priorities[~valid_bins] = -np.inf

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: How well the item fits into the bin
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Likelihood of fitting future items
        future_item_estimate = 0.8 * item  # Heuristic based on current item size
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.1 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin utilization history component: Bins that have been consistently filled well
        utilization_history = bins[valid_bins] - remaining_capacity[valid_bins]
        utilization_score = utilization_history / bins[valid_bins]
        utilization_score = 1 / (1 + np.exp(-10 * (utilization_score - 0.8)))

        # Combine components with tunable weights
        weight_spatial = 0.7
        weight_future = 0.4
        weight_history = 0.2
        penalty = 0.1 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_history * utilization_score -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, and distribution awareness."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    fit_ratio = item / (remaining_capacity + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.7)))
    spatial_fit[~valid_bins] = 0

    # Future potential component: Penalize bins with too little or too much remaining space
    ideal_remaining = 0.2  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-20 * (remaining_scaled - ideal_remaining)))
    future_potential[remaining_after < 0] = 0

    # Bin utilization bonus: Reward bins that are moderately filled
    utilization = 1.0 - (remaining_capacity / bins)
    utilization_bonus = np.exp(-0.2 * (utilization - 0.7) ** 2)

    # Fragmentation penalty: Penalize bins that leave too little usable space
    fragmentation_penalty = np.zeros_like(bins, dtype=np.float64)
    fragmentation_threshold = 0.1  # Minimum acceptable remaining space
    fragmentation_penalty[remaining_capacity < fragmentation_threshold] = 0.8

    # Distribution awareness component: Penalize bins with remaining capacity too high compared to others
    mean_remaining = np.mean(remaining_capacity[valid_bins])
    std_remaining = np.std(remaining_capacity[valid_bins])
    distribution_penalty = np.exp(-1.0 * ((remaining_capacity - mean_remaining) / (std_remaining + 1e-6)) ** 2)
    distribution_penalty[~valid_bins] = 0

    # Combine components with tunable weights
    weight_spatial = 0.7
    weight_future = 0.4
    weight_utilization = 0.3
    weight_fragmentation = 0.1
    weight_distribution = 0.2

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus -
        weight_fragmentation * fragmentation_penalty -
        weight_distribution * distribution_penalty
    )

    # Ensure invalid bins have the lowest priority
    priorities[~valid_bins] = -np.inf

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic weight adjustment based on current bin state
        avg_load = np.mean(bins - remaining_capacity)
        max_capacity = np.max(bins) + 1e-8
        
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Utilization bonus component
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component
        distribution_impact_weight = tunable([-0.3, -0.25, -0.2])
        scaled_remaining = remaining_after / max_capacity
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / max_capacity)
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead component
        lookahead_depth = tunable([2, 3])
        future_items_sizes = np.random.normal(item, item/2, lookahead_depth)
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins[:, None] - future_items_sizes
        future_valid = future_remaining >= 0
        lookahead_bonus = np.mean(np.any(future_valid, axis=1))
        lookahead_weight = tunable([0.2, 0.25, 0.3])

        # Combine components with dynamic weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact +
            lookahead_weight * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.25, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 75
-------------------



current thread_i 1
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 157464; measure cnt: 64

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 157464; measure cnt: 128

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 157464; measure cnt: 192
sampler suggest should end sample, break
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function for online bin-packing considering spatial fit, future potential, bin similarity, and dynamic load balancing."""
    remaining = bins - item
    valid = remaining >= 0
    
    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf
    
    if np.any(valid):
        # Spatial fit component
        fill_ratio = item / (bins[valid] + 1e-6)
        space_utilization = 1 - (remaining[valid] / (bins[valid] + 1e-6))
        spatial_fit = (fill_ratio + space_utilization) / 2
        
        # Future potential component
        ideal_remaining = 0.2 * bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining[valid] - ideal_remaining) / bins[valid])))
        
        # Bin similarity component
        avg_remaining = np.mean(remaining[valid])
        similarity_score = np.exp(-1.0 * np.abs(remaining[valid] - avg_remaining) / (np.max(bins) + 1e-6))
        
        # Diversity score component
        diversity_weight = 0.2
        diversity_score = 1 / (1 + np.exp(-1.5 * (len(bins) - np.count_nonzero(valid))))
        
        # Dynamic load balancing component
        current_loads = bins - remaining
        avg_load = np.mean(current_loads)
        load_diff = np.abs(current_loads[valid] - avg_load)
        load_balance = 1 / (1 + np.exp(-5 * (avg_load - load_diff)))
        
        # Combine components with tunable weights
        weight_spatial = 0.7
        weight_future = 0.4
        weight_similarity = 0.2
        weight_diversity = 0.15
        weight_balance = 0.2
        
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity_score +
            weight_diversity * diversity_score +
            weight_balance * load_balance
        )
        
        # Apply penalties for bins that are too full or too empty
        fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fill_ratio - 0.5))
        total_priority += fullness_penalty
        
        priorities[valid] = total_priority
    
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.5, 0.6, 0.7])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization history component: Reward bins that have been consistently filled well
        utilization_history_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold = tunable([0.7, 0.8, 0.9])
        utilization_score = np.where(
            (bins[valid_bins] - remaining_after) / bins[valid_bins] >= utilization_threshold,
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_history_weight * utilization_score +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 76
-------------------



current thread_i 6
launch 64 evaluate tasks
current thread_i 5
this best socre: -218.4; best score: -218.4; global score: -208.1; space size: 19683; measure cnt: 64
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -218.4; global score: -208.1; space size: 19683; measure cnt: 64
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -218.4; global score: -208.1; space size: 19683; measure cnt: 64
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -218.4; global score: -208.1; space size: 19683; measure cnt: 64
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to dynamic ideal
        avg_load = np.mean(bins - remaining_capacity)
        dynamic_ideal_fraction = 0.5 + 0.3 * (1 - avg_load / (np.max(bins) + 1e-8))
        ideal_remaining = dynamic_ideal_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Utilization bonus with S-curve
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        
        # S-curve for utilization bonus
        utilization_bonus = 1 / (1 + np.exp(-10 * ((utilization - utilization_threshold_low) / (utilization_threshold_high - utilization_threshold_low))))

        # Bin diversity impact: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.3, -0.2])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic weights adjustment based on current bin state
        weight_spatial = tunable([0.6, 0.7]) * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = tunable([0.5, 0.6]) * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight

        # Lookahead with multiple future item sizes
        lookahead_depth = tunable([2, 3])
        future_items_sizes = [0.4, 0.6, 0.8]  # Multiple sizes to consider
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_valid_counts = []
        
        for size in future_items_sizes:
            future_remaining = future_bins - size
            future_valid = future_remaining >= 0
            future_valid_counts.append(np.sum(future_valid))
        
        lookahead_bonus = np.mean(future_valid_counts) / len(future_valid_counts) if len(future_valid_counts) > 0 else 0
        lookahead_weight = tunable([0.2, 0.3])

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            lookahead_weight * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 77
-------------------



launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 20736; measure cnt: 64
.
launch 64 evaluate tasks
current thread_i 0
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 20736; measure cnt: 128

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 20736; measure cnt: 192
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Adaptive parameters based on context
        avg_item_size = tunable([np.mean(bins) * 0.5, np.mean(bins) * 0.7])
        item_count = tunable([len(bins), len(bins) + 10])
        weight_decay = tunable([0.01, 0.05]) * item_count

        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7])
        spatial_fit_slope = tunable([10, 15])
        spatial_fit_midpoint = tunable([0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component
        ideal_remaining_fraction = tunable([0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        future_item_estimate = tunable([avg_item_size * 0.8, avg_item_size * 1.2])
        remaining_after = remaining_capacity[valid_bins] - future_item_estimate
        future_potential_weight = tunable([0.5, 0.6])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Utilization bonus
        utilization_bonus_weight = tunable([0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.8, 0.9])
        utilization = 1.0 - (remaining_capacity[valid_bins] / bins[valid_bins])
        utilization_bonus = np.exp(-0.2 * (utilization - 0.7) ** 2)

        # Fragmentation penalty
        fragmentation_penalty_weight = tunable([0.1, 0.2])
        fragmentation_threshold = tunable([0.1, 0.2]) * bins[valid_bins]
        fragmentation_penalty = np.where(remaining_capacity[valid_bins] < fragmentation_threshold, 0.8, 0.0)

        # Distribution impact component
        distribution_impact_weight = tunable([-0.3, -0.4])
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with adaptive weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            fragmentation_penalty_weight * fragmentation_penalty +
            distribution_impact_weight * distribution_impact
        )

        # Apply adaptive weight decay
        total_priority *= np.exp(-weight_decay * item_count)

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority        priorities[valid_bins] = total_priority

    return priorities

call llm times: 78
-------------------



launch 64 evaluate tasks
current thread_i 4
current thread_i 9
current thread_i 8
this best socre: -212.75; best score: -212.75; global score: -208.1; space size: 32768; measure cnt: 64

launch 64 evaluate tasks
current thread_i 2
this best socre: -212.75; best score: -212.75; global score: -208.1; space size: 32768; measure cnt: 128

launch 64 evaluate tasks
current thread_i 7
this best socre: -212.75; best score: -212.75; global score: -208.1; space size: 32768; measure cnt: 192

launch 64 evaluate tasks
this best socre: -212.75; best score: -212.75; global score: -208.1; space size: 32768; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Prioritize bins with optimal item-to-bin size ratio
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Simulate adding the item and evaluate future packing efficiency
        future_items_sizes = tunable([np.array([0.2, 0.3, 0.4]), np.array([0.3, 0.4, 0.5])])
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins[:, None] - future_items_sizes
        future_valid = (future_remaining >= 0).mean(axis=1)
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = future_valid[valid_bins]

        # Bin utilization bonus: Reward bins with balanced remaining capacity
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )
        utilization_bonus_weight = tunable([0.4, 0.5])

        # Distribution impact component: Penalize uniform remaining capacities
        distribution_impact_weight = tunable([-0.3, -0.2])
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Lookahead component: Simulate next steps to evaluate future efficiency
        lookahead_depth = tunable([1, 2])
        future_items_size = tunable([0.3, 0.4])  # Average size of future items
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = tunable([0.2, 0.3])

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact +
            lookahead_weight * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.15]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 79
-------------------



launch 64 evaluate tasks
this best socre: -212.75; best score: -212.75; global score: -208.1; space size: 62208; measure cnt: 64

launch 64 evaluate tasks
this best socre: -212.75; best score: -212.75; global score: -208.1; space size: 62208; measure cnt: 128

launch 64 evaluate tasks
this best socre: -212.75; best score: -212.75; global score: -208.1; space size: 62208; measure cnt: 192

launch 64 evaluate tasks
this best socre: -212.75; best score: -212.75; global score: -208.1; space size: 62208; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.7, 0.8, 0.9])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold = tunable([0.7, 0.75, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.exp(-5 * (utilization - utilization_threshold) ** 2)

        # Fragmentation penalty: Penalize bins with too little remaining space
        fragmentation_penalty_weight = tunable([-0.1, -0.15, -0.2])
        fragmentation_threshold = tunable([0.1, 0.15, 0.2])
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        below_threshold = remaining_after < fragmentation_threshold * bins[valid_bins]
        fragmentation_penalty[below_threshold] = 1.0 / (1 + np.exp(-20 * (remaining_after[below_threshold] - fragmentation_threshold)))

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            fragmentation_penalty_weight * fragmentation_penalty +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.25, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 80
-------------------



launch 64 evaluate tasks
this best socre: -214.75; best score: -214.75; global score: -208.1; space size: 177147; measure cnt: 64
........................................................................................................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -214.2; best score: -214.2; global score: -208.1; space size: 177147; measure cnt: 128
........
launch 64 evaluate tasks
this best socre: -214.2; best score: -214.2; global score: -208.1; space size: 177147; measure cnt: 192
......
launch 64 evaluate tasks
this best socre: -214.1; best score: -214.1; global score: -208.1; space size: 177147; measure cnt: 256
...........
launch 64 evaluate tasks
this best socre: -214.1; best score: -214.1; global score: -208.1; space size: 177147; measure cnt: 320
.......
launch 64 evaluate tasks
current thread_i 1
this best socre: -214.1; best score: -214.1; global score: -208.1; space size: 177147; measure cnt: 384
.............
launch 64 evaluate tasks
this best socre: -214.1; best score: -214.1; global score: -208.1; space size: 177147; measure cnt: 448
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategies and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.4, 0.5, 0.6])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_threshold = tunable([0.2, 0.3, 0.4])
        utilization_bonus = np.where(
            utilization >= utilization_threshold,
            1.0,
            0.0
        )

        # Distribution impact component
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic penalty for bin creation
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact +
            num_bins_penalty
        )

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 81
-------------------



launch 64 evaluate tasks
this best socre: -227.55; best score: -227.55; global score: -208.1; space size: 19683; measure cnt: 64
.........................................................................
launch 64 evaluate tasks
this best socre: -227.55; best score: -227.55; global score: -208.1; space size: 19683; measure cnt: 128
...........................................................................................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -227.55; best score: -227.55; global score: -208.1; space size: 19683; measure cnt: 192
.........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -227.55; best score: -227.55; global score: -208.1; space size: 19683; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        valid_bins_mask = valid_bins
        valid_bins_indices = np.where(valid_bins_mask)[0]

        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Utilization bonus component: Reward bins with balanced utilization
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining space
        distribution_impact_weight = tunable([-0.2, -0.3])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = (new_variance - current_variance) * distribution_impact_weight

        # Bin diversity component: Reward bins with unique remaining capacities
        diversity_weight = tunable([0.1, 0.2])
        remaining_diff = np.abs(scaled_remaining[:, np.newaxis] - scaled_remaining)
        avg_diff = np.mean(remaining_diff, axis=1)
        diversity_bonus = 1 / (1 + np.exp(-5 * (avg_diff - 0.5)))  # S-shaped curve
        bin_diversity = diversity_weight * diversity_bonus

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact +
            bin_diversity
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities to maintain balance
        if np.max(total_priority) != 0:
            total_priority = total_priority / np.max(total_priority)

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 82
-------------------



launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 23328; measure cnt: 64
.
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 23328; measure cnt: 128
.
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 23328; measure cnt: 192
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.5, 0.6, 0.7])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Utilization bonus: Reward bins with balanced utilization
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact: Penalize similar remaining capacities
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Apply penalty for imbalance in remaining capacities
        imbalance_penalty_weight = tunable([-0.1, -0.15, -0.2])
        max_rem = np.max(remaining_after)
        min_rem = np.min(remaining_after)
        imbalance = max_rem - min_rem
        total_priority += imbalance_penalty_weight * imbalance

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 83
-------------------



launch 64 evaluate tasks
this best socre: -210.2; best score: -210.2; global score: -208.1; space size: 78732; measure cnt: 64
..
launch 64 evaluate tasks
this best socre: -210.2; best score: -210.2; global score: -208.1; space size: 78732; measure cnt: 128
...
launch 64 evaluate tasks
this best socre: -209.45; best score: -209.45; global score: -208.1; space size: 78732; measure cnt: 192
.
launch 64 evaluate tasks
this best socre: -209.45; best score: -209.45; global score: -208.1; space size: 78732; measure cnt: 256

launch 64 evaluate tasks
this best socre: -209.45; best score: -209.45; global score: -208.1; space size: 78732; measure cnt: 320
.
launch 64 evaluate tasks
this best socre: -209.45; best score: -209.45; global score: -208.1; space size: 78732; measure cnt: 384
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategies and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.5, 0.6, 0.7])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space suitable for future items
        avg_item_size = np.mean([item] + [b - r for b, r in zip(bins, remaining_capacity) if r >= 0])
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin diversity component: Penalize creating too many similar bins
        diversity_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        diversity_score = new_variance - current_variance

        # Dynamic load balancing component: Balance the load across bins
        load_balance_weight = tunable([0.2, 0.3, 0.4])
        current_loads = bins - remaining_capacity
        avg_load = np.mean(current_loads)
        load_diff = np.abs(current_loads[valid_bins] - avg_load)
        load_balance = 1 / (1 + np.exp(-5 * (avg_load - load_diff)))

        # Utilization bonus component: Reward well-utilized bins
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            load_balance_weight * load_balance +
            utilization_bonus_weight * utilization_bonus +
            diversity_weight * diversity_score
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 84
-------------------



launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 78732; measure cnt: 64

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 78732; measure cnt: 128

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -208.1; space size: 78732; measure cnt: 192
sampler suggest should end sample, break
request...
-----------------------request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with novel item-bin matching strategy."""
    remaining = bins - item
    valid = remaining >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf

    if np.any(valid):
        # Spatial fit component
        fit_ratio = item / (bins[valid] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        avg_remaining = np.mean(remaining[valid])
        ideal_remaining = 0.2 * bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * ((remaining[valid] - ideal_remaining) / bins[valid])))

        # Bin similarity component
        avg_load = np.mean(bins - remaining)
        similarity = np.exp(-1.5 * np.abs(fit_ratio - avg_load / bins[valid]))

        # Diversity component
        remaining_scaled = remaining[valid] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Dynamic weights based on current bin state
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.2
        weight_diversity = 0.3

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity
        )

        # Penalty for bins that are too full or too empty
        fullness_penalty = 0.2 * np.exp(-1.0 * np.abs(fit_ratio - 0.5))
        total_priority += fullness_penalty

        priorities[valid] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.


import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.8
        spatial_fit_slope = 20
        spatial_fit_midpoint = 0.8
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.7
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Lookahead component: Simulate next step to evaluate future efficiency
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current bin state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------

-----------------------
request...request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Reward bins where the item fits well
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Tunable parameters for spatial fit
        spatial_fit_slope = 15  # Steepness of fit curve
        spatial_fit_midpoint = 0.8  # Ideal fit ratio
        spatial_fit_weight = 0.7  # Weight of spatial fit
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.6  # Ideal remaining space fraction
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        # Tunable parameters for future potential
        future_potential_slope = 10  # Steepness of future potential curve
        future_potential_weight = 0.5  # Weight of future potential
        
        future_potential = 1 / (1 + np.exp(-future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins with balanced utilization
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        
        # Tunable parameters for utilization bonus
        utilization_threshold_low = 0.4  # Lower utilization threshold
        utilization_threshold_high = 0.8  # Upper utilization threshold
        utilization_bonus_weight = 0.5  # Weight of utilization bonus
        
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining space
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance
        
        # Tunable parameter for distribution impact
        distribution_impact_weight = -0.4  # Weight of distribution impact

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, bin similarity, and diversity."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        ideal_remaining = 0.2 * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins] - 0.2 * item
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / bins[valid_bins])))

        # Bin similarity component (assuming we have access to the items in each bin)
        # For simplicity, we'll use the average bin load as a proxy
        avg_load = bins - remaining_capacity
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load[valid_bins] / bins[valid_bins]))

        # Bin diversity component
        # Calculate the variance of remaining capacities
        remaining_scaled = remaining_capacity[valid_bins] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled))))

        # Combine components with tunable weights
        weight_spatial = 0.6
        weight_future = 0.3
        weight_similarity = 0.1
        weight_diversity = 0.2
        penalty = 0.05 * len(bins)

        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            penalty
        )

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

request...
-----------------------

request...
-----------------------
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.8
        spatial_fit_slope = 15
        spatial_fit_midpoint = 0.6
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.7
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential_slope = 15
        future_potential = 1 / (1 + np.exp(-future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function for online bin-packing.

    This version introduces a novel strategy that dynamically balances spatial fit,
    future potential, and bin utilization while exposing tunable parameters for
    strategic optimization.

    Args:
        item: Size of the item to be placed.
        bins: Array of remaining capacities for each bin.

    Returns:
        Array of priority scores for each bin.
    """
    # Calculate remaining capacity after placing the item
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    fit_ratio = item / (bins + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.5)))

    # Future potential component: Penalize bins that are too full or too empty
    ideal_remaining = 0.1 * bins  # Ideal remaining space as a percentage of bin capacity
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / (np.max(bins) + 1e-6)  # Normalize by max bin capacity
    future_potential = 1 / (1 + np.exp(-20 * (remaining_scaled - ideal_remaining)))

    # Bin utilization penalty: Discourage using too many bins
    num_bins_penalty = 0.2 * 0.5 * len(bins)

    # Combine components with tunable weights
    weight_fit = 0.6
    weight_future = 0.4
    
    total_priority = (
        weight_fit * spatial_fit +
        weight_future * future_potential -
        num_bins_penalty
    )

    # Normalize priorities to maintain balance
    total_priority = total_priority / (weight_fit + weight_future)

    # Ensure invalid bins have the lowest priority
    total_priority[~valid_bins] = -np.inf

    return total_priority


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters"""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial-temporal fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Novel spatial-temporal fit calculation
        spatial_weight = 0.7
        temporal_weight = 0.4
        
        # Immediate spatial fit
        spatial_fit = 1 / (1 + np.exp(-10 * 
                                      (fit_ratio - 0.6)))
        
        # Future temporal fit estimate
        future_fill_prob = 0.95
        expected_remaining = remaining_capacity[valid_bins] * future_fill_prob
        temporal_fit = 1 / (1 + np.exp(-15 *
                                       (expected_remaining - 0.3 * bins[valid_bins])))
        
        # Combine spatial and temporal fit
        spatiotemporal_fit = (spatial_weight * spatial_fit +
                              temporal_weight * temporal_fit)

        # Bin diversity score
        diversity_bonus_weight = 0.2
        bin_usage_freq = np.zeros_like(bins, dtype=np.float64)
        bin_usage_freq[valid_bins] = 1.0 / (np.log(len(bins)) + np.bincount(np.argsort(bins)))
        diversity_bonus = diversity_bonus_weight * bin_usage_freq[valid_bins]

        # Adaptive utilization bonus
        utilization_weight = 0.3
        utilization = 1.0 - (remaining_capacity[valid_bins] / (bins[valid_bins] + 1e-8))
        utilization_threshold = 0.25
        utilization_bonus = utilization_weight * np.where(
            utilization >= utilization_threshold,
            1.0,
            0.0
        )

        # Distribution impact penalty
        distribution_weight = -0.3
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = distribution_weight * (new_variance - current_variance)

        # Combine all components
        total_priority = (
            spatiotemporal_fit +
            diversity_bonus +
            utilization_bonus +
            distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.1 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Component 1: Spatial Fit (How well the item fits in the bin)
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Tunable parameters for spatial fit
        spatial_fit_weight = 0.7
        spatial_fit_slope = 12
        spatial_fit_midpoint = 0.6
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Component 2: Future Packing Potential
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        # Tunable parameters for future potential
        future_potential_weight = 0.6
        future_potential_slope = 10
        
        future_potential = 1 / (1 + np.exp(-future_potential_slope * 
                                          ((remaining_after - ideal_remaining) / 
                                           (bins[valid_bins] + 1e-8))))

        # Component 3: Bin Utilization Balance
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        
        # Tunable parameters for utilization balance
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.3
        utilization_threshold_high = 0.7
        
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & 
            (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Component 4: Distribution Impact
        # Penalize creating bins with similar remaining space
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        
        # Tunable parameter for distribution impact
        distribution_impact_weight = -0.2
        
        distribution_impact = new_variance - current_variance

        # Dynamic weight adjustment based on bin state
        avg_fill = np.mean(1.0 - (remaining_capacity[valid_bins] / 
                                 (bins[valid_bins] + 1e-8)))
        
        # Tunable dynamic weight functions
        weight_spatial = 0.6 * (1.0 - avg_fill)
        weight_future = 0.7 * avg_fill
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight

        # Combine components with tunable weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Component 5: Bin Count Penalty (Tunable)
        num_bins_penalty = -0.15 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
-----------------------
-----------------------

request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 15
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.4
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.6
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.3
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.4
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Fragmentation penalty component: Penalize bins with too little remaining space
        fragmentation_penalty_weight = -0.2
        fragmentation_threshold = 0.2
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact +
            fragmentation_penalty_weight * fragmentation_penalty
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities to [0, 1] range
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.5
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins that are well-utilized
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.2
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
    """Advanced priority function for online bin-packing with tunable parameters"""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: How well the item fits in the bin
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Tunable spatial fit parameters
        spatial_fit = 1 / (1 + np.exp(
            -tunable([10, 15, 20]) * (fit_ratio - tunable([0.6, 0.7, 0.8]))
        ))

        # Future packing potential component
        # Estimates how likely the remaining space will be useful for future items
        ideal_remaining_fraction = tunable([0.3, 0.5, 0.7])
        remaining_after = remaining_capacity[valid_bins]
        future_utility = 1 / (1 + np.exp(
            -tunable([8, 12, 16]) * (
                (remaining_after / (bins[valid_bins] + 1e-8)) - ideal_remaining_fraction
            )
        ))

        # Bin utilization balance component
        # Encourages using bins that are either very empty or very full
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_score = np.where(
            utilization < tunable([0.2, 0.3, 0.4]),
            1.0,
            np.where(
                utilization > tunable([0.7, 0.8, 0.9]),
                1.0,
                0.0
            )
        )

        # Dynamic capacity distribution component
        # Penalizes creating bins with capacities that are too similar to others
        capacity_variance = np.var(bins[valid_bins])
        new_capacity_variance = np.var(bins[valid_bins] - item)
        distribution_impact = tunable([-0.2, -0.3, -0.4]) * (
            new_capacity_variance - capacity_variance
        )

        # Combine components with tunable weights
        total_priority = (
            tunable([0.5, 0.6, 0.7]) * spatial_fit +
            tunable([0.4, 0.5, 0.6]) * future_utility +
            tunable([0.3, 0.4, 0.5]) * utilization_score +
            distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.15, -0.2]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 85
-------------------


current thread_i 4

launch 64 evaluate tasks
current thread_i 6
current thread_i 7
current thread_i 1
this best socre: -220.0; best score: -220.0; global score: -208.1; space size: 177147; measure cnt: 64
.....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
launch 51 evaluate tasks
current thread_i 9
current thread_i 5
this best socre: -220.0; best score: -220.0; global score: -208.1; space size: 177147; measure cnt: 115
................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
launch 17 evaluate tasks
this best socre: -220.0; best score: -220.0; global score: -208.1; space size: 177147; measure cnt: 132
...............................................................................................................................................................................................................................................................................................................................................
launch 17 evaluate tasks
this best socre: -220.0; best score: -220.0; global score: -208.1; space size: 177147; measure cnt: 149
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategies and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.3, 0.4, 0.5])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Utilization bonus component: Reward well-utilized bins
        utilization_bonus_weight = tunable([0.1, 0.2, 0.3])
        utilization_threshold_low = tunable([0.2, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8])
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins
        distribution_impact_weight = tunable([-0.2, -0.1, 0.0])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Bin diversity component: Encourage diverse remaining capacities
        bin_diversity_weight = tunable([0.1, 0.2])
        diversity_score = 1.0 / (1.0 + np.exp(-5.0 * (1.0 - np.std(scaled_remaining))))
        bin_diversity = diversity_score

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact +
            bin_diversity_weight * bin_diversity
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.1]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        if np.max(total_priority) != 0:
            total_priority /= np.max(total_priority)

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 86
-------------------



launch 64 evaluate tasks
current thread_i 2
this best socre: -221.25; best score: -221.25; global score: -208.1; space size: 34992; measure cnt: 64
...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -221.25; best score: -221.25; global score: -208.1; space size: 34992; measure cnt: 128
...........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
launch 58 evaluate tasks
this best socre: -219.5; best score: -219.5; global score: -208.1; space size: 34992; measure cnt: 186
....................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -219.5; best score: -219.5; global score: -208.1; space size: 34992; measure cnt: 250
........................................................................................................................................................................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -219.5; best score: -219.5; global score: -208.1; space size: 34992; measure cnt: 314
.....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -219.5; best score: -219.5; global score: -208.1; space size: 34992; measure cnt: 378
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategies."""
    remaining = bins - item
    valid = remaining >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf

    if np.any(valid):
        # Spatial fit component: Reward bins where item size is a significant but not overwhelming fraction of bin capacity
        fit_ratio = item / (bins[valid] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])  # Weight for spatial fit component
        spatial_fit_slope = tunable([8, 10, 12])  # Steepness of spatial fit curve
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])  # Ideal fit ratio
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space suitable for future items
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])  # Ideal fraction of bin capacity to leave for future items
        ideal_remaining = ideal_remaining_fraction * bins[valid]
        future_potential_weight = tunable([0.5, 0.6, 0.7])  # Weight for future potential component
        future_potential = 1 / (1 + np.exp(-10 * ((remaining[valid] - ideal_remaining) / (bins[valid] + 1e-8))))

        # Bin utilization bonus: Reward bins that are neither too empty nor too full
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])  # Weight for utilization bonus
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])  # Lower bound for ideal utilization
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])  # Upper bound for ideal utilization
        utilization = 1.0 - (remaining[valid] / (bins[valid] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating bins with similar remaining capacities
        distribution_impact_weight = tunable([-0.3, -0.4, -0.5])  # Weight for distribution impact
        scaled_remaining = remaining[valid] / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid] = total_priority

    return priorities

call llm times: 87
-------------------



launch 64 evaluate tasks
this best socre: -210.25; best score: -210.25; global score: -208.1; space size: 59049; measure cnt: 64
..
launch 64 evaluate tasks
this best socre: -210.25; best score: -210.25; global score: -208.1; space size: 59049; measure cnt: 128
...
launch 64 evaluate tasks
this best socre: -209.85; best score: -209.85; global score: -208.1; space size: 59049; measure cnt: 192

launch 64 evaluate tasks
current thread_i 0
this best socre: -209.85; best score: -209.85; global score: -208.1; space size: 59049; measure cnt: 256

launch 64 evaluate tasks
this best socre: -209.85; best score: -209.85; global score: -208.1; space size: 59049; measure cnt: 320
.
launch 64 evaluate tasks
this best socre: -209.85; best score: -209.85; global score: -208.1; space size: 59049; measure cnt: 384
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.5, 0.6, 0.7])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward remaining space close to ideal
        ideal_remaining_fraction = tunable([0.3, 0.5, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = tunable([0.3, 0.4, 0.5])
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Distribution impact component: Penalize increasing variance of remaining capacities
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance
        distribution_impact_weight = tunable([-0.1, -0.2, -0.3])

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 88
-------------------


.
launch 64 evaluate tasks
this best socre: -262.45; best score: -262.45; global score: -208.1; space size: 2187; measure cnt: 64
.......................................................................................................................................................................................................................................
launch 7 evaluate tasks
this best socre: -262.45; best score: -262.45; global score: -208.1; space size: 2187; measure cnt: 71
.........................................................................................................................................
launch 5 evaluate tasks
this best socre: -262.45; best score: -262.45; global score: -208.1; space size: 2187; measure cnt: 76
....................................................................................................................
launch 2 evaluate tasks
this best socre: -262.45; best score: -262.45; global score: -208.1; space size: 2187; measure cnt: 78
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Component 1: Spatial Fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        spatial_fit_slope = tunable([10, 12, 15])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Component 2: Future Potential
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_slope = tunable([8, 10, 12])
        future_potential = 1 / (1 + np.exp(-future_potential_slope * 
                                          ((remaining_after - ideal_remaining) / 
                                           (bins[valid_bins] + 1e-8))))

        # Component 3: Utilization Bonus
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & 
            (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Component 4: Distribution Impact
        distribution_impact_weight = tunable([-0.3, -0.2, -0.1])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic weight adjustment based on bin state
        avg_fill = np.mean(1.0 - (remaining_capacity[valid_bins] / 
                                 (bins[valid_bins] + 1e-8)))
        
        # Adjust weights dynamically
        base_spatial_weight = tunable([0.5, 0.6, 0.7])
        base_future_weight = tunable([0.4, 0.5, 0.6])
        weight_spatial = base_spatial_weight * (1.0 - avg_fill)
        weight_future = base_future_weight * avg_fill
        weight_utilization = tunable([0.3, 0.4, 0.5])
        weight_distribution = distribution_impact_weight

        # Combine components with tunable weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.15, -0.1]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 89
-------------------



launch 64 evaluate tasks
this best socre: -213.1; best score: -213.1; global score: -208.1; space size: 177147; measure cnt: 64
.............
launch 64 evaluate tasks
this best socre: -213.1; best score: -213.1; global score: -208.1; space size: 177147; measure cnt: 128
......................
launch 64 evaluate tasks
this best socre: -213.1; best score: -213.1; global score: -208.1; space size: 177147; measure cnt: 192
.........
launch 64 evaluate tasks
current thread_i 8
this best socre: -213.1; best score: -213.1; global score: -208.1; space size: 177147; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit based on item size relative to average bin capacity
        avg_bin_capacity = np.mean(bins) if len(bins) > 0 else 1.0
        item_size_ratio = item / avg_bin_capacity
        spatial_fit_weight = tunable([0.7, 0.8, 0.9])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Enhanced future potential considering bin variance impact
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential_slope = tunable([10, 15, 20])
        future_potential = 1 / (1 + np.exp(-future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))
        
        # Utilization bonus for optimal bin usage
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact considering variance change
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins, adjusted based on bin count
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 90
-------------------



launch 64 evaluate tasks
this best socre: -212.6; best score: -212.6; global score: -208.1; space size: 177147; measure cnt: 64
.............
launch 64 evaluate tasks
this best socre: -210.75; best score: -210.75; global score: -208.1; space size: 177147; measure cnt: 128
......................................................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -210.75; best score: -210.75; global score: -208.1; space size: 177147; measure cnt: 192
.......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................
launch 64 evaluate tasks
this best socre: -210.75; best score: -210.75; global score: -208.1; space size: 177147; measure cnt: 256
....................................................
launch 64 evaluate tasks
this best socre: -210.5; best score: -210.5; global score: -208.1; space size: 177147; measure cnt: 320
.................................
launch 64 evaluate tasks
this best socre: -210.4; best score: -210.4; global score: -208.1; space size: 177147; measure cnt: 384
...............
launch 64 evaluate tasks
this best socre: -210.4; best score: -210.4; global score: -208.1; space size: 177147; measure cnt: 448
.....................................
launch 64 evaluate tasks
this best socre: -210.1; best score: -210.1; global score: -208.1; space size: 177147; measure cnt: 512
...........................
launch 64 evaluate tasks
this best socre: -210.1; best score: -210.1; global score: -208.1; space size: 177147; measure cnt: 576
..........................
launch 64 evaluate tasks
this best socre: -210.1; best score: -210.1; global score: -208.1; space size: 177147; measure cnt: 640
.......................
launch 64 evaluate tasks
this best socre: -210.1; best score: -210.1; global score: -208.1; space size: 177147; measure cnt: 704
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential_slope = tunable([8, 10, 12])
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = tunable([0.3, 0.4, 0.5])
        utilization_threshold_low = tunable([0.15, 0.2, 0.25])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = tunable([-0.25, -0.3, -0.35])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = tunable([2, 3, 4])
        future_items_size = tunable([0.4, 0.5, 0.6])  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = tunable([0.15, 0.2, 0.25])

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.25, -0.3, -0.35]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 91
-------------------



launch 64 evaluate tasks
this best socre: -208.95; best score: -208.95; global score: -208.1; space size: 4782969; measure cnt: 64

launch 64 evaluate tasks
this best socre: -208.95; best score: -208.95; global score: -208.1; space size: 4782969; measure cnt: 128

launch 64 evaluate tasks
this best socre: -208.95; best score: -208.95; global score: -208.1; space size: 4782969; measure cnt: 192

launch 64 evaluate tasks
this best socre: -208.55; best score: -208.55; global score: -208.1; space size: 4782969; measure cnt: 256

launch 64 evaluate tasks
this best socre: -208.55; best score: -208.55; global score: -208.1; space size: 4782969; measure cnt: 320

launch 64 evaluate tasks
this best socre: -208.55; best score: -208.55; global score: -208.1; space size: 4782969; measure cnt: 384

launch 64 evaluate tasks
this best socre: -208.15; best score: -208.15; global score: -208.1; space size: 4782969; measure cnt: 448

launch 64 evaluate tasks
this best socre: -208.15; best score: -208.15; global score: -208.1; space size: 4782969; measure cnt: 512

launch 64 evaluate tasks
this best socre: -207.75; best score: -207.75; global score: -207.75; space size: 4782969; measure cnt: 576

launch 64 evaluate tasks
this best socre: -207.75; best score: -207.75; global score: -207.75; space size: 4782969; measure cnt: 640

launch 64 evaluate tasks
this best socre: -207.75; best score: -207.75; global score: -207.75; space size: 4782969; measure cnt: 704

launch 64 evaluate tasks
this best socre: -207.75; best score: -207.75; global score: -207.75; space size: 4782969; measure cnt: 768
sampler suggest should end sample, break
INFO:absl:Best score increased to -207.75
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Reward bins where the item fits well
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Tunable parameters for spatial fit
        spatial_fit_slope = tunable([10, 15, 20])  # Steepness of fit curve
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])  # Ideal fit ratio
        spatial_fit_weight = tunable([0.5, 0.6, 0.7])  # Weight of spatial fit
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])  # Ideal remaining space fraction
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        # Tunable parameters for future potential
        future_potential_slope = tunable([10, 15, 20])  # Steepness of future potential curve
        future_potential_weight = tunable([0.3, 0.4, 0.5])  # Weight of future potential
        
        future_potential = 1 / (1 + np.exp(-future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus: Reward bins with balanced utilization
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        
        # Tunable parameters for utilization bonus
        utilization_bonus_slope = tunable([10, 15, 20])  # Steepness of utilization bonus curve
        utilization_bonus_weight = tunable([0.2, 0.3, 0.4])  # Weight of utilization bonus
        
        utilization_bonus = 1 / (1 + np.exp(-utilization_bonus_slope * (utilization - 0.5)))

        # Distribution impact component: Penalize creating bins with similar remaining space
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance
        
        # Tunable parameter for distribution impact
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])  # Weight of distribution impact

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 92
-------------------



launch 64 evaluate tasks
this best socre: -236.75; best score: -236.75; global score: -207.75; space size: 59049; measure cnt: 64
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -236.75; global score: -207.75; space size: 59049; measure cnt: 64
..............................................................................................................................................................
launch 3 evaluate tasks
this best socre: -236.75; best score: -236.75; global score: -207.75; space size: 59049; measure cnt: 67
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -236.75; global score: -207.75; space size: 59049; measure cnt: 67
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Spatial fit component
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_strategy = tunable(['quadratic', 'sigmoid'])
        if spatial_fit_strategy == 'quadratic':
            midpoint = tunable([0.6, 0.7, 0.8])
            spatial_fit = - (fit_ratio - midpoint)**2 + 1
        else:
            slope = tunable([10, 15, 20])
            midpoint = tunable([0.6, 0.7, 0.8])
            spatial_fit = 1 / (1 + np.exp(-slope * (fit_ratio - midpoint)))
        
        # Future potential component
        ideal_remaining_fraction = tunable([0.4, 0.5, 0.6])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_strategy = tunable(['quadratic', 'sigmoid'])
        if future_potential_strategy == 'quadratic':
            future_potential = - ((remaining_after - ideal_remaining) / bins[valid_bins])**2 + 1
        else:
            slope = tunable([10, 15, 20])
            future_potential = 1 / (1 + np.exp(-slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))
        
        # Utilization bonus component
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus_strategy = tunable(['quadratic', 'sigmoid'])
        if utilization_bonus_strategy == 'quadratic':
            midpoint = tunable([0.6, 0.7, 0.8])
            utilization_bonus = - (utilization - midpoint)**2 + 1
        else:
            low = tunable([0.2, 0.3, 0.4])
            high = tunable([0.7, 0.8, 0.9])
            utilization_bonus = np.where(
                (utilization >= low) & (utilization <= high),
                1.0,
                0.0
            )
        
        # Diversity impact component
        current_remaining = remaining_after.copy()
        current_mean = np.mean(current_remaining)
        current_sad = np.sum(np.abs(current_remaining - current_mean))
        
        diversity_impact = np.zeros_like(remaining_after, dtype=np.float64)
        for i in range(len(remaining_after)):
            new_remaining = current_remaining.copy()
            new_remaining[i] -= item
            new_mean = np.mean(new_remaining)
            new_sad = np.sum(np.abs(new_remaining - new_mean))
            sad_impact = new_sad - current_sad
            diversity_impact[i] = sad_impact
        
        diversity_impact_weight = tunable([0.3, 0.4, 0.5])
        
        # Fragmentation penalty component
        fragmentation_threshold = tunable([0.2, 0.3, 0.4])
        fragmentation_penalty = np.zeros_like(remaining_after, dtype=np.float64)
        fragmentation_penalty[remaining_after < fragmentation_threshold * bins[valid_bins]] = 1.0
        fragmentation_penalty_weight = tunable([-0.2, -0.3, -0.4])
        
        # Combine components
        total_priority = (
            spatial_fit_weight * spatial_fit +
            tunable([0.5, 0.6, 0.7]) * future_potential +
            tunable([0.4, 0.5, 0.6]) * utilization_bonus +
            diversity_impact_weight * diversity_impact +
            fragmentation_penalty_weight * fragmentation_penalty
        )
        
        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty
        
        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority
        
        priorities[valid_bins] = total_priority

    return priorities

call llm times: 93
-------------------



launch 64 evaluate tasks
this best socre: -361.25; best score: -361.25; global score: -207.75; space size: 114791256; measure cnt: 64
.....................................................................
launch 1 evaluate tasks
this best socre: -361.25; best score: -361.25; global score: -207.75; space size: 114791256; measure cnt: 65
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -361.25; global score: -207.75; space size: 114791256; measure cnt: 65
................................................................
launch 0 evaluate tasks
this best socre: -10000000000.0; best score: -361.25; global score: -207.75; space size: 114791256; measure cnt: 65
sampler suggest should end sample, break
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Returns priority with which we want to add item to each bin.

    This version improves upon priority_v0 by considering both the spatial fit of the item
    in the bin and the future potential for packing additional items. It introduces tunable
    parameters to allow strategic innovation and optimization.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of remaining capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    # Avoid division by zero and ensure item fits in the bin
    valid = (bins > 0) & (item <= bins)
    
    # Initialize priorities to zero
    priorities = np.zeros_like(bins, dtype=np.float64)
    
    # Compute for valid bins
    if np.any(valid):
        ratio = item / bins[valid]
        
        # Spatial fit component: Higher when the item is a larger proportion of the bin's remaining capacity
        # The fit is scaled to prevent very large values when the ratio is small
        spatial_fit = 1.0 / (ratio + 1e-8)  # Adding a small epsilon to avoid division by zero
        
        # Future potential component: Higher when remaining capacity after adding the item is above a tunable threshold
        remaining_after = bins[valid] - item
        threshold = 0.5  # Tunable parameter for minimum remaining capacity
        future_potential = np.maximum(0, remaining_after - threshold)
        
        # Combine components with tunable weights
        spatial_weight = 0.9  # Tunable parameter for spatial fit weight
        future_weight = 0.1   # Tunable parameter for future potential weight
        
        total_priority = spatial_weight * spatial_fit + future_weight * future_potential
        
        # Apply a normalization to ensure priorities are on a similar scale
        # This helps in maintaining a balance between the components
        total_priority = total_priority / (spatial_weight + future_weight)
        
        priorities[valid] = total_priority
    
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = 0.7
        future_potential_slope = 12
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.7
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------request...
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit and future packing potential."""
    remaining = bins - item
    valid = remaining > 0  # Only consider bins where the item fits
    
    # Spatial fit: How well the item fits into the bin
    spatial_fit = np.zeros_like(bins, dtype=np.float64)
    spatial_fit[valid] = 1.0 / (1.0 + np.exp(-0.5 * (bins[valid] - item)))
    
    # Future potential: Remaining space after adding the item
    future_potential = np.zeros_like(bins, dtype=np.float64)
    future_potential[valid] = 1.0 * (remaining[valid] > 0.1)
    
    # Combine the scores with tunable weights
    spatial_weight = 0.7
    future_weight = 0.3
    priorities = spatial_weight * spatial_fit + future_weight * future_potential
    
    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = 0.7
        future_potential_slope = 12
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.7
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.


-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.9
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component: Reward bins with remaining space close to ideal
        # Dynamic ideal remaining fraction based on item size relative to average bin
        avg_bin = np.mean(bins) if len(bins) > 0 else 1.0
        item_rel_size = item / avg_bin
        ideal_remaining_fraction = 0.7
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.4
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Enhanced future potential considering item size impact
        future_potential = future_potential * (1 + 0.2 * item_rel_size)

        # Utilization bonus component: Reward well-utilized bins
        utilization_bonus_weight = 0.3
        utilization_threshold_low = 0.4
        utilization_threshold_high = 0.7
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact component: Penalize creating too many similar bins using entropy
        distribution_impact_weight = -0.2
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_entropy = -np.sum(scaled_remaining * np.log(scaled_remaining + 1e-8)) / np.log(len(scaled_remaining))
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_entropy = -np.sum(new_remaining * np.log(new_remaining + 1e-8)) / np.log(len(new_remaining))
        distribution_impact = new_entropy - current_entropy

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact
        )

        # Apply penalty for creating too many bins with tunable factor
        num_bins_penalty = -0.15 * len(bins)
        total_priority += num_bins_penalty

        # Adaptive normalization based on current state
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = 0.7
        future_potential_slope = 12
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.7
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
request...
-----------------------

-----------------------
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function considering spatial fit, future potential, and distribution awareness."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    # Spatial fit component: Higher priority for better fit
    fit_ratio = item / (remaining_capacity + 1e-6)  # Avoid division by zero
    spatial_fit = 1 / (1 + np.exp(-5 * (fit_ratio - 0.7)))
    spatial_fit[~valid_bins] = 0

    # Future potential component: Penalize bins with too little or too much remaining space
    ideal_remaining = 0.2  # Ideal remaining space after placing the item
    remaining_after = remaining_capacity - 0.1 * item  # Account for fragmentation
    remaining_scaled = remaining_after / np.max(bins)  # Normalize by bin capacity
    future_potential = 1 / (1 + np.exp(-20 * (remaining_scaled - ideal_remaining)))
    future_potential[remaining_after < 0] = 0

    # Bin utilization bonus: Reward bins that are moderately filled
    utilization = 1.0 - (remaining_capacity / bins)
    utilization_bonus = np.exp(-0.2 * (utilization - 0.7) ** 2)

    # Fragmentation penalty: Penalize bins that leave too little usable space
    fragmentation_penalty = np.zeros_like(bins, dtype=np.float64)
    fragmentation_threshold = 0.1  # Minimum acceptable remaining space
    fragmentation_penalty[remaining_capacity < fragmentation_threshold] = 0.8

    # Distribution awareness component: Penalize bins with remaining capacity too high compared to others
    mean_remaining = np.mean(remaining_capacity[valid_bins])
    std_remaining = np.std(remaining_capacity[valid_bins])
    distribution_penalty = np.exp(-1.0 * ((remaining_capacity - mean_remaining) / (std_remaining + 1e-6)) ** 2)
    distribution_penalty[~valid_bins] = 0

    # Combine components with tunable weights
    weight_spatial = 0.7
    weight_future = 0.4
    weight_utilization = 0.3
    weight_fragmentation = 0.1
    weight_distribution = 0.2

    priorities = (
        weight_spatial * spatial_fit +
        weight_future * future_potential +
        weight_utilization * utilization_bonus -
        weight_fragmentation * fragmentation_penalty -
        weight_distribution * distribution_penalty
    )

    # Ensure invalid bins have the lowest priority
    priorities[~valid_bins] = -np.inf

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = 0.7
        future_potential_slope = 12
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.7
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters"""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: How well the item fits in the bin
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Tunable spatial fit parameters
        spatial_fit = 1 / (1 + np.exp(
            -15 * (fit_ratio - 0.6)
        ))

        # Future packing potential component
        # Estimates how likely the remaining space will be useful for future items
        ideal_remaining_fraction = 0.3
        remaining_after = remaining_capacity[valid_bins]
        future_utility = 1 / (1 + np.exp(
            -12 * (
                (remaining_after / (bins[valid_bins] + 1e-8)) - ideal_remaining_fraction
            )
        ))

        # Bin utilization balance component
        # Encourages using bins that are either very empty or very full
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_score = np.where(
            utilization < 0.4,
            1.0,
            np.where(
                utilization > 0.9,
                1.0,
                0.0
            )
        )

        # Dynamic capacity distribution component
        # Penalizes creating bins with capacities that are too similar to others
        capacity_variance = np.var(bins[valid_bins])
        new_capacity_variance = np.var(bins[valid_bins] - item)
        distribution_impact = -0.2 * (
            new_capacity_variance - capacity_variance
        )

        # Combine components with tunable weights
        total_priority = (
            0.7 * spatial_fit +
            0.4 * future_utility +
            0.3 * utilization_score +
            distribution_impact
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.2 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = 0.7
        future_potential_slope = 12
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.7
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Improved priority function with dynamic weights and adaptive parameters."""
    remaining = bins - item
    valid = remaining >= 0

    # Initialize priorities with a very low value for invalid bins
    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid] = -np.inf

    if np.any(valid):
        # Spatial fit component
        fit_ratio = item / (bins[valid] + 1e-6)
        spatial_fit = 1 / (1 + np.exp(-10 * (fit_ratio - 0.6)))

        # Future potential component
        avg_remaining = np.mean(remaining[valid])
        ideal_remaining = 0.1 * bins[valid]  # Adaptive ideal remaining space
        remaining_scaled = (remaining[valid] - ideal_remaining) / bins[valid]
        future_potential = 1 / (1 + np.exp(-10 * (remaining_scaled - -0.2)))

        # Bin similarity component
        avg_load = np.mean(bins[valid] - remaining[valid])
        similarity = np.exp(-1.0 * np.abs(fit_ratio - avg_load / bins[valid]))

        # Diversity component
        remaining_scaled_div = remaining[valid] / np.max(bins)
        diversity = 1 / (1 + np.exp(-5 * (1 - np.var(remaining_scaled_div))))

        # Dynamic weights based on current state
        avg_fill = np.mean((bins[valid] - remaining[valid]) / bins[valid])
        weight_spatial = 0.7 * (1 - avg_fill)
        weight_future = 0.4 * avg_fill
        weight_similarity = 0.2
        weight_diversity = 0.2

        # Penalty for imbalanced bins
        max_rem = np.max(remaining[valid])
        min_rem = np.min(remaining[valid])
        imbalance_penalty = 0.1 * (max_rem - min_rem) / np.mean(bins)

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_similarity * similarity +
            weight_diversity * diversity -
            imbalance_penalty
        )

        priorities[valid] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = 0.7
        future_potential_slope = 12
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.7
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        valid = valid_bins
        # Spatial fit component
        fit_ratio = item / (bins[valid] + 1e-8)
        spatial_fit_slope = 20
        spatial_fit_midpoint = 0.6
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component
        ideal_remaining_fraction = 0.5
        ideal_remaining = ideal_remaining_fraction * bins[valid]
        future_potential_slope = 10
        future_potential = 1 / (1 + np.exp(-future_potential_slope * ((remaining_capacity[valid] - ideal_remaining) / (bins[valid] + 1e-8))))

        # Utilization bonus
        utilization_bonus_weight = 0.4
        utilization_threshold_low = 0.3
        utilization_threshold_high = 0.8
        utilization = 1.0 - (remaining_capacity[valid] / (bins[valid] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            utilization_bonus_weight,
            0.0
        )

        # Distribution impact component
        distribution_impact_weight = -0.2
        scaled_remaining = remaining_capacity[valid] / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = distribution_impact_weight * (new_variance - current_variance)

        # Dynamic weights based on current bin state
        avg_remaining = np.mean(remaining_capacity[valid])
        weight_spatial = 0.7 if avg_remaining < 0.4 else 0.5
        weight_future = 0.4 if avg_remaining < 0.5 else 0.6

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            utilization_bonus +
            distribution_impact
        )

        # Penalty for creating too many bins
        num_bins_penalty = -0.1 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = 0.7
        future_potential_slope = 12
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.7
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategies and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = 0.6
        spatial_fit_slope = 15
        spatial_fit_midpoint = 0.7
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential component
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        future_potential_weight = 0.4
        future_potential = 1 / (1 + np.exp(-10 * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))))

        # Bin utilization bonus
        utilization_bonus_weight = 0.4
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_threshold = 0.3
        utilization_bonus = np.where(
            utilization >= utilization_threshold,
            1.0,
            0.0
        )

        # Distribution impact component
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Dynamic penalty for bin creation
        num_bins_penalty = -0.3 * len(bins)
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_bonus_weight * utilization_bonus +
            distribution_impact_weight * distribution_impact +
            num_bins_penalty
        )

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = 0.7
        future_potential_slope = 12
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.7
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.
request...
-----------------------

-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Prefer bins where the item occupies a significant portion
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.6
        spatial_fit = 1 / (1 + np.exp(-20 * (fit_ratio - 0.7)))

        # Future potential component: Consider future item likelihood based on past statistics
        item_stats = {
            'avg': 0.5,
            'std': 0.1,
            'min': 0.2,
            'max': 0.9
        }
        remaining_scaled = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        future_likelihood = np.exp(-((remaining_scaled - item_stats['avg']) ** 2) / (2 * (item_stats['std'] ** 2)))
        future_potential_weight = 0.4
        future_potential = future_likelihood

        # Bin similarity and diversity components
        similarity_weight = 0.2
        diversity_weight = 0.3
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        std_remaining = np.std(remaining_capacity[valid_bins])
        similarity = 1 / (1 + np.exp(-20 * (np.abs(remaining_capacity[valid_bins] - avg_remaining) / (std_remaining + 1e-6))))
        diversity = 1 / (1 + np.exp(-15 * (1 - np.var(remaining_scaled))))

        # Adaptive weights based on current bin state
        current_utilization = 1 - (np.mean(remaining_capacity) / (np.max(bins) + 1e-6))
        weight_spatial = spatial_fit_weight * (1 - current_utilization)
        weight_future = future_potential_weight * (1 + current_utilization)
        weight_similarity = similarity_weight * (1 + len(bins) / 10)
        weight_diversity = diversity_weight * (1 + len(bins) / 10)

        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential -
            weight_similarity * similarity -
            weight_diversity * diversity
        )

        # Normalize priorities
        total_priority = total_priority / (weight_spatial + weight_future + weight_similarity + weight_diversity)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = 0.7
        future_potential_slope = 12
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.7
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        valid = valid_bins
        bins_valid = bins[valid]
        remaining_valid = remaining_capacity[valid]

        # Spatial fit component with ideal remaining space
        ideal_remaining_space = tunable([0.3, 0.5, 0.7]) * bins_valid
        spatial_fit_weight = tunable([0.6, 0.7, 0.8])
        spatial_fit_slope = tunable([15, 20, 25])
        
        spatial_fit = np.exp(-spatial_fit_slope * np.abs(remaining_valid - ideal_remaining_space))
        
        # Future potential with multi-step lookahead
        lookahead_depth = tunable([2, 3, 4])
        future_item_size = tunable([0.4, 0.5, 0.6])  # Average expected size
        
        future_bins = bins_valid.copy()
        future_remaining = future_bins - item
        for _ in range(lookahead_depth):
            future_remaining -= future_item_size
            future_remaining = np.maximum(future_remaining, 0)
        
        future_potential_weight = tunable([0.5, 0.6, 0.7])
        future_potential = np.exp(-spatial_fit_slope * np.abs(future_remaining - ideal_remaining_space))
        
        # Distribution balance component
        distribution_balance_weight = tunable([0.3, 0.4, 0.5])
        scaled_remaining = remaining_valid / np.max(bins)
        entropy = -np.sum(scaled_remaining * np.log(scaled_remaining + 1e-8))
        entropy_threshold = tunable([1.5, 2.0, 2.5])
        distribution_balance = np.where(entropy >= entropy_threshold, 1.0, 0.0)
        
        # Dynamic weights based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_distribution = distribution_balance_weight
        
        # Combine components
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_distribution * distribution_balance
        )
        
        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty
        
        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority
        
        priorities[valid] = total_priority

    return priorities

call llm times: 94
-------------------


current thread_i 5

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -207.75; space size: 19683; measure cnt: 64
.
launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -207.75; space size: 19683; measure cnt: 128

launch 64 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -207.75; space size: 19683; measure cnt: 192
sampler suggest should end sample, break
request...
-----------------------

import numpy as np


def priority_v0(item: float, bins: np.ndarray) -> np.ndarray:
    """Returns priority with which we want to add item to each bin.

    Args:
        item: Size of item to be added to the bin.
        bins: Array of capacities for each bin.

    Return:
        Array of same size as bins with priority score of each bin.
    """
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-6)
        spatial_fit_weight = 0.8
        spatial_fit = 1 / (1 + np.exp(-15 * (fit_ratio - 0.6)))

        # Future potential component: Estimate based on current item and average
        future_item_estimate = 0.8 * item
        remaining_after = remaining_capacity[valid_bins] - 0.1 * item
        ideal_remaining = 0.3 * bins[valid_bins]
        future_potential_weight = 0.7
        future_potential = 1 / (1 + np.exp(-15 * ((remaining_after - future_item_estimate) / (bins[valid_bins] + 1e-6))))

        # Bin utilization history component: Prefer well-utilized bins
        utilization_history = (bins[valid_bins] - remaining_capacity[valid_bins]) / bins[valid_bins]
        utilization_weight = 0.3
        utilization_score = 1 / (1 + np.exp(-15 * (utilization_history - 0.9)))

        # Bin similarity component: Prefer bins with similar remaining capacities
        avg_remaining = np.mean(remaining_capacity[valid_bins])
        similarity_weight = 0.15
        similarity = 1 / (1 + np.exp(-20 * (1 - np.abs(remaining_capacity[valid_bins] - avg_remaining) / (avg_remaining + 1e-6))))

        # Bin diversity component: Encourage diverse remaining capacities
        scaled_remaining = remaining_capacity[valid_bins] / (np.max(bins) + 1e-6)
        diversity_weight = 0.15
        diversity = 1 / (1 + np.exp(-15 * (1 - np.var(scaled_remaining))))

        # Combine components with tunable weights
        total_priority = (
            spatial_fit_weight * spatial_fit +
            future_potential_weight * future_potential +
            utilization_weight * utilization_score -
            similarity_weight * similarity -
            diversity_weight * diversity -
            0.1 * len(bins)
        )

        # Normalize priorities to a 0-1 scale
        if np.any(total_priority):
            total_priority = (total_priority - np.min(total_priority)) / (np.max(total_priority) - np.min(total_priority) + 1e-6)

        priorities[valid_bins] = total_priority

    return priorities


def priority_v1(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v0`."""
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = 0.7
        spatial_fit_slope = 10
        spatial_fit_midpoint = 0.7
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = 0.6
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = 0.7
        future_potential_slope = 12
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = 0.5
        utilization_threshold_low = 0.25
        utilization_threshold_high = 0.7
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = -0.3
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = 2
        future_items_size = 0.5  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = 0.2

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = -0.3 * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities


def priority_v2(item: float, bins: np.ndarray) -> np.ndarray:
    """Improved version of `priority_v1`."""



Create an improved Python function for online bin-packing that demonstrates:
Novel priority strategy: Propose a smarter item-bin matching approach considering both spatial fit and future packing potential
Parameter tuning points: Clearly mark tuning parameters using tunable([option1, option2, ...]) wrapper. Example:
`if remaining_capacity > tunable([0.2, 0.5]):`
`sorted(items, key=lambda x: tunable([x.size, x.weight]))`
Focus first on strategic innovation, then expose tuning parameters through tunable([option1, option2, ...]) calls. Keep implementation practical but non-trivial.
Things you should also focus on:
1.You can try a lot of functions and check the answers, however, the final functions you provide for me should be the best ones.
2.You can break the traditional thinking and try new ideas. To achieve this goal, you can note the disadvantages of existing traditional algorithms, and try to improve them in the functions you generate.
3.You can break the problem down into iteratively optimized submodules, then try to improve the performance of each submodule.
4.You can merge the strategies of multiple algorithms, and try to improve the performance of the functions you generate by combining the advantages of multiple algorithms.
You can try any possible methods as long as they are correct and reasonable.

-----------------------
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation with tunable parameters
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.7, 0.8, 0.9])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = tunable([0.6, 0.7, 0.8])
        future_potential_slope = tunable([12, 15, 18])
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.25, 0.3])
        utilization_threshold_high = tunable([0.65, 0.7, 0.75])
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = tunable([-0.2, -0.25, -0.3])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Lookahead with multiple future scenarios
        lookahead_depth = tunable([2, 3, 4])
        future_items_size = tunable([0.4, 0.5, 0.6])  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = tunable([0.15, 0.2, 0.25])

        # Dynamic weights adjustment based on current state
        avg_fill = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_fill / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_fill))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.25, -0.3, -0.35]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        if len(total_priority) > 0:
            max_priority = np.max(total_priority)
            if max_priority != 0:
                total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 95
-------------------



current thread_i 9
launch 64 evaluate tasks
this best socre: -213.95; best score: -213.95; global score: -207.75; space size: 4782969; measure cnt: 64

launch 64 evaluate tasks
this best socre: -213.65; best score: -213.65; global score: -207.75; space size: 4782969; measure cnt: 128

launch 64 evaluate tasks
this best socre: -213.65; best score: -213.65; global score: -207.75; space size: 4782969; measure cnt: 192

launch 64 evaluate tasks
current thread_i 1
current thread_i 6
current thread_i 0
this best socre: -213.65; best score: -213.65; global score: -207.75; space size: 4782969; measure cnt: 256

launch 64 evaluate tasks
current thread_i 5
current thread_i 7
current thread_i 2
this best socre: -213.65; best score: -213.65; global score: -207.75; space size: 4782969; measure cnt: 320
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategies and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit with adaptive thresholds
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit = 1 / (1 + np.exp(
            -tunable([10, 15, 20]) * (fit_ratio - tunable([0.6, 0.7, 0.8]))
        ))

        # Future potential with item size distribution awareness
        ideal_remaining = tunable([0.2, 0.3, 0.4]) * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential = 1 / (1 + np.exp(
            -tunable([12, 15, 18]) * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Smart utilization bonus with dynamic range
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= tunable([0.25, 0.3, 0.35])) & 
            (utilization <= tunable([0.65, 0.7, 0.75])),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = tunable([2, 3, 4])
        future_items_size = tunable([0.4, 0.5, 0.6])  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = tunable([0.6, 0.7, 0.8]) * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = tunable([0.6, 0.7, 0.8]) * (1 + np.exp(-5 * avg_load))
        weight_utilization = tunable([0.4, 0.5, 0.6])
        weight_distribution = tunable([-0.2, -0.3, -0.4])
        weight_lookahead = tunable([0.1, 0.2, 0.3])

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 96
-------------------



launch 64 evaluate tasks
current thread_i 8
this best socre: -210.85; best score: -210.85; global score: -207.75; space size: 4782969; measure cnt: 64

launch 64 evaluate tasks
current thread_i 4
this best socre: -210.85; best score: -210.85; global score: -207.75; space size: 4782969; measure cnt: 128

launch 64 evaluate tasks
this best socre: -210.85; best score: -210.85; global score: -207.75; space size: 4782969; measure cnt: 192

launch 64 evaluate tasks
this best socre: -210.25; best score: -210.25; global score: -207.75; space size: 4782969; measure cnt: 256

launch 64 evaluate tasks
this best socre: -210.25; best score: -210.25; global score: -207.75; space size: 4782969; measure cnt: 320

launch 64 evaluate tasks
this best socre: -209.85; best score: -209.85; global score: -207.75; space size: 4782969; measure cnt: 384

launch 64 evaluate tasks
this best socre: -209.85; best score: -209.85; global score: -207.75; space size: 4782969; measure cnt: 448

launch 64 evaluate tasks
this best socre: -209.85; best score: -209.85; global score: -207.75; space size: 4782969; measure cnt: 512

launch 64 evaluate tasks
this best socre: -209.85; best score: -209.85; global score: -207.75; space size: 4782969; measure cnt: 576
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        valid = valid_bins
        valid_indices = np.where(valid)[0]
        valid_bins = bins[valid]
        remaining_after = remaining_capacity[valid]

        # Spatial fit component
        fit_ratio = item / (valid_bins + 1e-8)
        spatial_fit = 1.0 / (fit_ratio + 1e-8)
        spatial_weight = tunable([0.8, 0.9, 1.0])

        # Future potential component
        threshold = tunable([0.2, 0.5, 0.8]) * valid_bins
        future_potential = np.maximum(0, remaining_after - threshold)
        future_weight = tunable([0.2, 0.3, 0.4])

        # Utilization bonus
        utilization = 1.0 - (remaining_after / (valid_bins + 1e-8))
        utilization_bonus = np.where(
            (utilization >= tunable([0.2, 0.3])) & 
            (utilization <= tunable([0.7, 0.8])),
            1.0,
            0.0
        )
        utilization_weight = tunable([0.1, 0.2, 0.3])

        # Distribution impact
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance
        distribution_weight = tunable([-0.1, -0.2, -0.3])

        # Lookahead mechanism
        lookahead_depth = tunable([1, 2, 3])
        future_item_size = tunable([0.3, 0.5, 0.7]) * item
        future_bins = bins.copy()
        future_bins[valid] -= item
        future_remaining = future_bins - future_item_size
        future_valid = future_remaining >= 0
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = tunable([0.1, 0.2, 0.3])

        # Combine components with dynamic weights
        total_priority = (
            spatial_weight * spatial_fit +
            future_weight * future_potential +
            utilization_weight * utilization_bonus +
            distribution_weight * distribution_impact +
            lookahead_weight * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.1, -0.2, -0.3]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid] = total_priority

    return priorities

call llm times: 97
-------------------



launch 64 evaluate tasks
this best socre: -212.0; best score: -212.0; global score: -207.75; space size: 78732; measure cnt: 64

launch 64 evaluate tasks
this best socre: -212.0; best score: -212.0; global score: -207.75; space size: 78732; measure cnt: 128

launch 64 evaluate tasks
this best socre: -212.0; best score: -212.0; global score: -207.75; space size: 78732; measure cnt: 192

launch 64 evaluate tasks
this best socre: -212.0; best score: -212.0; global score: -207.75; space size: 78732; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation with tunable parameters
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_weight = tunable([0.7, 0.8, 0.9])
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.7, 0.8, 0.9])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Enhanced future potential with adaptive ideal remaining space
        avg_bin = np.mean(bins) if len(bins) > 0 else 1.0
        item_rel_size = item / avg_bin
        ideal_remaining_fraction = tunable([0.6, 0.7, 0.8])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = tunable([0.7, 0.8, 0.9])
        future_potential_slope = tunable([12, 15, 18])
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))
        
        # Adaptive future potential scaling based on item size
        future_potential = future_potential * (1 + tunable([0.2, 0.3, 0.4]) * item_rel_size)

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = tunable([0.5, 0.6, 0.7])
        utilization_threshold_low = tunable([0.25, 0.3, 0.35])
        utilization_threshold_high = tunable([0.7, 0.75, 0.8])
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive variance penalty
        distribution_impact_weight = tunable([-0.3, -0.4, -0.5])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = tunable([2, 3, 4])
        future_items_size = tunable([0.5, 0.6, 0.7])  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = tunable([0.2, 0.3, 0.4])

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.3, -0.4, -0.5]) * len(bins)
        total_priority += num_bins_penalty

        # Adaptive normalization based on current state
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 98
-------------------



launch 64 evaluate tasks
this best socre: -212.2; best score: -212.2; global score: -207.75; space size: 14348907; measure cnt: 64

launch 64 evaluate tasks
this best socre: -211.65; best score: -211.65; global score: -207.75; space size: 14348907; measure cnt: 128

launch 64 evaluate tasks
this best socre: -211.65; best score: -211.65; global score: -207.75; space size: 14348907; measure cnt: 192

launch 64 evaluate tasks
this best socre: -211.65; best score: -211.65; global score: -207.75; space size: 14348907; measure cnt: 256

launch 64 evaluate tasks
this best socre: -211.65; best score: -211.65; global score: -207.75; space size: 14348907; measure cnt: 320
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with novel strategy and tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Spatial fit component: Higher priority for better fit
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_threshold = tunable([0.6, 0.7, 0.8])
        spatial_fit_weight = tunable([0.7, 0.8, 0.9])
        spatial_fit_slope = tunable([10, 15, 20])
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_threshold)))

        # Future potential component: Estimate based on current item and average
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = tunable([0.6, 0.7, 0.8])
        future_potential_slope = tunable([12, 15, 18])
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization history component: Prefer well-utilized bins within a tunable range
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])

        # Distribution impact component: Prefer bins that help maintain diverse remaining capacities
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        
        distribution_impact = new_variance - current_variance
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        distribution_scale = tunable([1.0, 1.5, 2.0])
        distribution_impact *= distribution_scale

        # Lookahead component: Simulate future placements to inform current decision
        lookahead_depth = tunable([2, 3, 4])
        future_items_size = tunable([0.5, 0.6, 0.7])  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = tunable([0.15, 0.2, 0.25])

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities to a 0-1 scale
        if np.any(total_priority):
            total_priority = (total_priority - np.min(total_priority)) / (np.max(total_priority) - np.min(total_priority) + 1e-8)

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 99
-------------------



launch 64 evaluate tasks
this best socre: -217.0; best score: -217.0; global score: -207.75; space size: 14348907; measure cnt: 64

launch 64 evaluate tasks
this best socre: -217.0; best score: -217.0; global score: -207.75; space size: 14348907; measure cnt: 128

launch 64 evaluate tasks
this best socre: -217.0; best score: -217.0; global score: -207.75; space size: 14348907; measure cnt: 192

launch 64 evaluate tasks
this best socre: -217.0; best score: -217.0; global score: -207.75; space size: 14348907; measure cnt: 256
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with dynamic parameter tuning."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation with tunable parameters
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        spatial_fit_slope = tunable([10, 15, 20])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential with tunable ideal remaining space
        ideal_remaining_fraction = tunable([0.5, 0.6, 0.7])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_slope = tunable([12, 15, 18])
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with tunable thresholds
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_threshold_low = tunable([0.2, 0.3, 0.4])
        utilization_threshold_high = tunable([0.6, 0.7, 0.8])
        
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with tunable penalty
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with tunable parameters
        lookahead_depth = tunable([2, 3, 4])
        future_items_size = tunable([0.5, 0.6, 0.7])  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = tunable([0.6, 0.7, 0.8]) * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = tunable([0.5, 0.6, 0.7]) * (1 + np.exp(-5 * avg_load))
        weight_utilization = tunable([0.4, 0.5, 0.6])
        weight_distribution = tunable([-0.2, -0.3, -0.4])
        weight_lookahead = tunable([0.1, 0.2, 0.3])

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins with tunable factor
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 100
-------------------



launch 64 evaluate tasks
this best socre: -212.3; best score: -212.3; global score: -207.75; space size: 4782969; measure cnt: 64

launch 64 evaluate tasks
this best socre: -212.15; best score: -212.15; global score: -207.75; space size: 4782969; measure cnt: 128

launch 64 evaluate tasks
this best socre: -211.1; best score: -211.1; global score: -207.75; space size: 4782969; measure cnt: 192

launch 64 evaluate tasks
this best socre: -210.8; best score: -210.8; global score: -207.75; space size: 4782969; measure cnt: 256

launch 64 evaluate tasks
this best socre: -210.45; best score: -210.45; global score: -207.75; space size: 4782969; measure cnt: 320

launch 64 evaluate tasks
this best socre: -210.45; best score: -210.45; global score: -207.75; space size: 4782969; measure cnt: 384

launch 64 evaluate tasks
this best socre: -210.45; best score: -210.45; global score: -207.75; space size: 4782969; measure cnt: 448

launch 64 evaluate tasks
this best socre: -210.45; best score: -210.45; global score: -207.75; space size: 4782969; measure cnt: 512
sampler suggest should end sample, break
-------------------
                item_stats: Dict[str, Any], 
                tunables: Dict[str, tunable]) -> np.ndarray:
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        valid_remaining = remaining_capacity[valid_bins]
        valid_bins_count = len(valid_remaining)

        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = tunables['spatial_fit_weight'].get()
        spatial_fit_slope = tunables['spatial_fit_slope'].get()
        spatial_fit_midpoint = tunables['spatial_fit_midpoint'].get()
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))

        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = tunables['ideal_remaining_fraction'].get()
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = valid_remaining
        
        future_potential_weight = tunables['future_potential_weight'].get()
        future_potential_slope = tunables['future_potential_slope'].get()
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = tunables['utilization_bonus_weight'].get()
        utilization_threshold_low = tunables['utilization_threshold_low'].get()
        utilization_threshold_high = tunables['utilization_threshold_high'].get()
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = tunables['distribution_impact_weight'].get()
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with probabilistic future items
        lookahead_depth = tunables['lookahead_depth'].get()
        future_items_size = item_stats['avg']  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = tunables['lookahead_weight'].get()

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunables['num_bins_penalty'].get() * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 101
-------------------


................................................................
launch 1 evaluate tasks
this best socre: -10000000000.0; best score: -10000000000.0; global score: -207.75; space size: 1.0; measure cnt: 1
sampler suggest should end sample, break
-------------------
    """Advanced priority function for online bin-packing with tunable parameters."""
    remaining_capacity = bins - item
    valid_bins = remaining_capacity >= 0

    priorities = np.zeros_like(bins, dtype=np.float64)
    priorities[~valid_bins] = -np.inf

    if np.any(valid_bins):
        # Dynamic spatial fit calculation
        fit_ratio = item / (bins[valid_bins] + 1e-8)
        
        # Smart spatial fit with adaptive thresholds
        spatial_fit_weight = tunable([0.7, 0.8, 0.9])
        spatial_fit_slope = tunable([10, 12, 15])
        spatial_fit_midpoint = tunable([0.6, 0.7, 0.8])
        
        spatial_fit = 1 / (1 + np.exp(-spatial_fit_slope * (fit_ratio - spatial_fit_midpoint)))
        
        # Future potential with adaptive ideal remaining space
        ideal_remaining_fraction = tunable([0.3, 0.4, 0.5])
        ideal_remaining = ideal_remaining_fraction * bins[valid_bins]
        
        remaining_after = remaining_capacity[valid_bins]
        
        future_potential_weight = tunable([0.6, 0.7, 0.8])
        future_potential_slope = tunable([12, 14, 16])
        
        future_potential = 1 / (1 + np.exp(
            -future_potential_slope * ((remaining_after - ideal_remaining) / (bins[valid_bins] + 1e-8))
        ))

        # Utilization bonus with dynamic thresholds
        utilization_bonus_weight = tunable([0.4, 0.5, 0.6])
        utilization_threshold_low = tunable([0.2, 0.25, 0.3])
        utilization_threshold_high = tunable([0.7, 0.8, 0.9])
        
        utilization = 1.0 - (remaining_after / (bins[valid_bins] + 1e-8))
        utilization_bonus = np.where(
            (utilization >= utilization_threshold_low) & (utilization <= utilization_threshold_high),
            1.0,
            0.0
        )

        # Distribution impact with adaptive penalties
        distribution_impact_weight = tunable([-0.2, -0.3, -0.4])
        scaled_remaining = remaining_after / (np.max(bins) + 1e-8)
        current_variance = np.var(scaled_remaining)
        new_remaining = scaled_remaining - (item / (np.max(bins) + 1e-8))
        new_variance = np.var(new_remaining)
        distribution_impact = new_variance - current_variance

        # Enhanced lookahead with multiple future scenarios
        lookahead_depth = tunable([2, 3, 4])
        future_items_size = tunable([0.4, 0.5, 0.6])  # Average size of future items
        
        future_bins = bins.copy()
        future_bins[valid_bins] -= item
        future_remaining = future_bins - future_items_size
        future_valid = future_remaining >= 0
        
        lookahead_bonus = np.sum(future_valid) / len(future_valid) if len(future_valid) > 0 else 0
        lookahead_weight = tunable([0.1, 0.2, 0.3])

        # Dynamic weights adjustment based on current state
        avg_load = np.mean(bins - remaining_capacity)
        weight_spatial = spatial_fit_weight * (1 - avg_load / (np.max(bins) + 1e-8))
        weight_future = future_potential_weight * (1 + np.exp(-5 * avg_load))
        weight_utilization = utilization_bonus_weight
        weight_distribution = distribution_impact_weight
        weight_lookahead = lookahead_weight

        # Combine components with dynamic weights
        total_priority = (
            weight_spatial * spatial_fit +
            weight_future * future_potential +
            weight_utilization * utilization_bonus +
            weight_distribution * distribution_impact +
            weight_lookahead * lookahead_bonus
        )

        # Apply penalty for creating too many bins
        num_bins_penalty = tunable([-0.2, -0.3, -0.4]) * len(bins)
        total_priority += num_bins_penalty

        # Normalize priorities
        max_priority = np.max(total_priority)
        if max_priority != 0:
            total_priority /= max_priority

        priorities[valid_bins] = total_priority

    return priorities

call llm times: 102
-------------------



launch 64 evaluate tasks
this best socre: -210.65; best score: -210.65; global score: -207.75; space size: 4782969; measure cnt: 64

launch 64 evaluate tasks
